{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 12464,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0016047500601781273,
      "grad_norm": 0.3481806814670563,
      "learning_rate": 3.5650623885918005e-07,
      "loss": 2.0275,
      "step": 10
    },
    {
      "epoch": 0.0032095001203562546,
      "grad_norm": 0.27435800433158875,
      "learning_rate": 7.130124777183601e-07,
      "loss": 1.7784,
      "step": 20
    },
    {
      "epoch": 0.004814250180534382,
      "grad_norm": 0.2910098433494568,
      "learning_rate": 1.0695187165775401e-06,
      "loss": 1.7868,
      "step": 30
    },
    {
      "epoch": 0.006419000240712509,
      "grad_norm": 0.3374997675418854,
      "learning_rate": 1.4260249554367202e-06,
      "loss": 1.7637,
      "step": 40
    },
    {
      "epoch": 0.008023750300890637,
      "grad_norm": 0.5533764362335205,
      "learning_rate": 1.7825311942959003e-06,
      "loss": 1.7994,
      "step": 50
    },
    {
      "epoch": 0.009628500361068763,
      "grad_norm": 0.3769804835319519,
      "learning_rate": 2.1390374331550802e-06,
      "loss": 1.8867,
      "step": 60
    },
    {
      "epoch": 0.01123325042124689,
      "grad_norm": 0.3294832408428192,
      "learning_rate": 2.4955436720142603e-06,
      "loss": 1.8388,
      "step": 70
    },
    {
      "epoch": 0.012838000481425018,
      "grad_norm": 0.28214165568351746,
      "learning_rate": 2.8520499108734404e-06,
      "loss": 1.6355,
      "step": 80
    },
    {
      "epoch": 0.014442750541603145,
      "grad_norm": 0.28274163603782654,
      "learning_rate": 3.2085561497326205e-06,
      "loss": 1.7754,
      "step": 90
    },
    {
      "epoch": 0.016047500601781273,
      "grad_norm": 0.3549898862838745,
      "learning_rate": 3.5650623885918006e-06,
      "loss": 1.6496,
      "step": 100
    },
    {
      "epoch": 0.0176522506619594,
      "grad_norm": 0.2647390365600586,
      "learning_rate": 3.92156862745098e-06,
      "loss": 1.5751,
      "step": 110
    },
    {
      "epoch": 0.019257000722137527,
      "grad_norm": 0.3015369772911072,
      "learning_rate": 4.2780748663101604e-06,
      "loss": 1.8334,
      "step": 120
    },
    {
      "epoch": 0.020861750782315655,
      "grad_norm": 0.2643004357814789,
      "learning_rate": 4.6345811051693405e-06,
      "loss": 1.8201,
      "step": 130
    },
    {
      "epoch": 0.02246650084249378,
      "grad_norm": 0.4140813946723938,
      "learning_rate": 4.991087344028521e-06,
      "loss": 1.7839,
      "step": 140
    },
    {
      "epoch": 0.02407125090267191,
      "grad_norm": 0.3582390248775482,
      "learning_rate": 5.347593582887702e-06,
      "loss": 1.668,
      "step": 150
    },
    {
      "epoch": 0.025676000962850037,
      "grad_norm": 0.5730404853820801,
      "learning_rate": 5.704099821746881e-06,
      "loss": 1.9012,
      "step": 160
    },
    {
      "epoch": 0.027280751023028165,
      "grad_norm": 0.46824926137924194,
      "learning_rate": 6.060606060606061e-06,
      "loss": 1.8621,
      "step": 170
    },
    {
      "epoch": 0.02888550108320629,
      "grad_norm": 0.46423736214637756,
      "learning_rate": 6.417112299465241e-06,
      "loss": 1.8651,
      "step": 180
    },
    {
      "epoch": 0.03049025114338442,
      "grad_norm": 0.34394699335098267,
      "learning_rate": 6.773618538324421e-06,
      "loss": 1.9437,
      "step": 190
    },
    {
      "epoch": 0.03209500120356255,
      "grad_norm": 0.5196558833122253,
      "learning_rate": 7.130124777183601e-06,
      "loss": 1.9508,
      "step": 200
    },
    {
      "epoch": 0.033699751263740675,
      "grad_norm": 0.8910748958587646,
      "learning_rate": 7.486631016042781e-06,
      "loss": 1.9862,
      "step": 210
    },
    {
      "epoch": 0.0353045013239188,
      "grad_norm": 0.6707438826560974,
      "learning_rate": 7.84313725490196e-06,
      "loss": 1.6518,
      "step": 220
    },
    {
      "epoch": 0.036909251384096925,
      "grad_norm": 0.428229957818985,
      "learning_rate": 8.19964349376114e-06,
      "loss": 1.5906,
      "step": 230
    },
    {
      "epoch": 0.03851400144427505,
      "grad_norm": 0.39312443137168884,
      "learning_rate": 8.556149732620321e-06,
      "loss": 1.7584,
      "step": 240
    },
    {
      "epoch": 0.04011875150445318,
      "grad_norm": 0.42399024963378906,
      "learning_rate": 8.912655971479501e-06,
      "loss": 1.6653,
      "step": 250
    },
    {
      "epoch": 0.04172350156463131,
      "grad_norm": 0.44612210988998413,
      "learning_rate": 9.269162210338681e-06,
      "loss": 1.8681,
      "step": 260
    },
    {
      "epoch": 0.04332825162480944,
      "grad_norm": 0.7041329741477966,
      "learning_rate": 9.625668449197861e-06,
      "loss": 1.6439,
      "step": 270
    },
    {
      "epoch": 0.04493300168498756,
      "grad_norm": 0.7503124475479126,
      "learning_rate": 9.982174688057041e-06,
      "loss": 1.6185,
      "step": 280
    },
    {
      "epoch": 0.04653775174516569,
      "grad_norm": 0.5278136134147644,
      "learning_rate": 1.0338680926916223e-05,
      "loss": 1.8324,
      "step": 290
    },
    {
      "epoch": 0.04814250180534382,
      "grad_norm": 0.42845892906188965,
      "learning_rate": 1.0695187165775403e-05,
      "loss": 1.7182,
      "step": 300
    },
    {
      "epoch": 0.049747251865521945,
      "grad_norm": 0.32218316197395325,
      "learning_rate": 1.1051693404634583e-05,
      "loss": 1.9951,
      "step": 310
    },
    {
      "epoch": 0.05135200192570007,
      "grad_norm": 0.21394136548042297,
      "learning_rate": 1.1408199643493762e-05,
      "loss": 1.648,
      "step": 320
    },
    {
      "epoch": 0.0529567519858782,
      "grad_norm": 0.2552504241466522,
      "learning_rate": 1.1764705882352942e-05,
      "loss": 1.6926,
      "step": 330
    },
    {
      "epoch": 0.05456150204605633,
      "grad_norm": 0.43248167634010315,
      "learning_rate": 1.2121212121212122e-05,
      "loss": 1.863,
      "step": 340
    },
    {
      "epoch": 0.05616625210623445,
      "grad_norm": 0.28484341502189636,
      "learning_rate": 1.2477718360071302e-05,
      "loss": 1.7311,
      "step": 350
    },
    {
      "epoch": 0.05777100216641258,
      "grad_norm": 0.18368053436279297,
      "learning_rate": 1.2834224598930482e-05,
      "loss": 1.6479,
      "step": 360
    },
    {
      "epoch": 0.05937575222659071,
      "grad_norm": 0.17929795384407043,
      "learning_rate": 1.3190730837789662e-05,
      "loss": 1.6374,
      "step": 370
    },
    {
      "epoch": 0.06098050228676884,
      "grad_norm": 0.14017082750797272,
      "learning_rate": 1.3547237076648842e-05,
      "loss": 1.7078,
      "step": 380
    },
    {
      "epoch": 0.06258525234694697,
      "grad_norm": 0.22329741716384888,
      "learning_rate": 1.3903743315508022e-05,
      "loss": 1.6731,
      "step": 390
    },
    {
      "epoch": 0.0641900024071251,
      "grad_norm": 0.14382880926132202,
      "learning_rate": 1.4260249554367203e-05,
      "loss": 1.5604,
      "step": 400
    },
    {
      "epoch": 0.06579475246730322,
      "grad_norm": 0.3925539553165436,
      "learning_rate": 1.4616755793226383e-05,
      "loss": 1.53,
      "step": 410
    },
    {
      "epoch": 0.06739950252748135,
      "grad_norm": 0.27906155586242676,
      "learning_rate": 1.4973262032085563e-05,
      "loss": 1.5849,
      "step": 420
    },
    {
      "epoch": 0.06900425258765948,
      "grad_norm": 0.18232017755508423,
      "learning_rate": 1.532976827094474e-05,
      "loss": 1.3326,
      "step": 430
    },
    {
      "epoch": 0.0706090026478376,
      "grad_norm": 0.23918840289115906,
      "learning_rate": 1.568627450980392e-05,
      "loss": 1.5074,
      "step": 440
    },
    {
      "epoch": 0.07221375270801572,
      "grad_norm": 0.2625289261341095,
      "learning_rate": 1.60427807486631e-05,
      "loss": 1.6655,
      "step": 450
    },
    {
      "epoch": 0.07381850276819385,
      "grad_norm": 0.3620847165584564,
      "learning_rate": 1.639928698752228e-05,
      "loss": 1.66,
      "step": 460
    },
    {
      "epoch": 0.07542325282837198,
      "grad_norm": 0.23106391727924347,
      "learning_rate": 1.675579322638146e-05,
      "loss": 1.4607,
      "step": 470
    },
    {
      "epoch": 0.0770280028885501,
      "grad_norm": 0.3901979327201843,
      "learning_rate": 1.7112299465240642e-05,
      "loss": 1.4881,
      "step": 480
    },
    {
      "epoch": 0.07863275294872824,
      "grad_norm": 0.23092664778232574,
      "learning_rate": 1.7468805704099822e-05,
      "loss": 1.6274,
      "step": 490
    },
    {
      "epoch": 0.08023750300890636,
      "grad_norm": 0.23557554185390472,
      "learning_rate": 1.7825311942959002e-05,
      "loss": 1.4452,
      "step": 500
    },
    {
      "epoch": 0.08184225306908449,
      "grad_norm": 0.3031589090824127,
      "learning_rate": 1.8181818181818182e-05,
      "loss": 1.5062,
      "step": 510
    },
    {
      "epoch": 0.08344700312926262,
      "grad_norm": 0.3062126338481903,
      "learning_rate": 1.8538324420677362e-05,
      "loss": 1.4598,
      "step": 520
    },
    {
      "epoch": 0.08505175318944075,
      "grad_norm": 0.34174180030822754,
      "learning_rate": 1.8894830659536542e-05,
      "loss": 1.4588,
      "step": 530
    },
    {
      "epoch": 0.08665650324961888,
      "grad_norm": 0.24502912163734436,
      "learning_rate": 1.9251336898395722e-05,
      "loss": 1.5626,
      "step": 540
    },
    {
      "epoch": 0.088261253309797,
      "grad_norm": 0.2255953699350357,
      "learning_rate": 1.9607843137254903e-05,
      "loss": 1.4311,
      "step": 550
    },
    {
      "epoch": 0.08986600336997512,
      "grad_norm": 0.31927159428596497,
      "learning_rate": 1.9964349376114083e-05,
      "loss": 1.558,
      "step": 560
    },
    {
      "epoch": 0.09147075343015325,
      "grad_norm": 0.2991087734699249,
      "learning_rate": 1.9999987841968625e-05,
      "loss": 1.4276,
      "step": 570
    },
    {
      "epoch": 0.09307550349033138,
      "grad_norm": 0.21444474160671234,
      "learning_rate": 1.9999945814243798e-05,
      "loss": 1.4296,
      "step": 580
    },
    {
      "epoch": 0.0946802535505095,
      "grad_norm": 0.27173665165901184,
      "learning_rate": 1.9999873766852508e-05,
      "loss": 1.5291,
      "step": 590
    },
    {
      "epoch": 0.09628500361068763,
      "grad_norm": 0.2554818093776703,
      "learning_rate": 1.999977170001103e-05,
      "loss": 1.4119,
      "step": 600
    },
    {
      "epoch": 0.09788975367086576,
      "grad_norm": 0.5347756743431091,
      "learning_rate": 1.999963961402578e-05,
      "loss": 1.5833,
      "step": 610
    },
    {
      "epoch": 0.09949450373104389,
      "grad_norm": 0.2503623962402344,
      "learning_rate": 1.999947750929327e-05,
      "loss": 1.5966,
      "step": 620
    },
    {
      "epoch": 0.10109925379122202,
      "grad_norm": 0.24172484874725342,
      "learning_rate": 1.9999285386300132e-05,
      "loss": 1.5476,
      "step": 630
    },
    {
      "epoch": 0.10270400385140015,
      "grad_norm": 0.44592422246932983,
      "learning_rate": 1.9999063245623124e-05,
      "loss": 1.5053,
      "step": 640
    },
    {
      "epoch": 0.10430875391157828,
      "grad_norm": 0.29498621821403503,
      "learning_rate": 1.9998811087929107e-05,
      "loss": 1.5095,
      "step": 650
    },
    {
      "epoch": 0.1059135039717564,
      "grad_norm": 0.22031773626804352,
      "learning_rate": 1.999852891397505e-05,
      "loss": 1.5511,
      "step": 660
    },
    {
      "epoch": 0.10751825403193453,
      "grad_norm": 0.2750484347343445,
      "learning_rate": 1.9998216724608038e-05,
      "loss": 1.4374,
      "step": 670
    },
    {
      "epoch": 0.10912300409211266,
      "grad_norm": 0.16369891166687012,
      "learning_rate": 1.9997874520765257e-05,
      "loss": 1.4311,
      "step": 680
    },
    {
      "epoch": 0.11072775415229077,
      "grad_norm": 0.30632859468460083,
      "learning_rate": 1.9997502303473997e-05,
      "loss": 1.3998,
      "step": 690
    },
    {
      "epoch": 0.1123325042124689,
      "grad_norm": 0.2544844448566437,
      "learning_rate": 1.999710007385165e-05,
      "loss": 1.4906,
      "step": 700
    },
    {
      "epoch": 0.11393725427264703,
      "grad_norm": 0.27073752880096436,
      "learning_rate": 1.9996667833105697e-05,
      "loss": 1.5101,
      "step": 710
    },
    {
      "epoch": 0.11554200433282516,
      "grad_norm": 0.2245398908853531,
      "learning_rate": 1.9996205582533723e-05,
      "loss": 1.3774,
      "step": 720
    },
    {
      "epoch": 0.11714675439300329,
      "grad_norm": 0.19440914690494537,
      "learning_rate": 1.9995713323523395e-05,
      "loss": 1.3311,
      "step": 730
    },
    {
      "epoch": 0.11875150445318142,
      "grad_norm": 0.3126305639743805,
      "learning_rate": 1.9995191057552463e-05,
      "loss": 1.3695,
      "step": 740
    },
    {
      "epoch": 0.12035625451335955,
      "grad_norm": 0.23222993314266205,
      "learning_rate": 1.9994638786188765e-05,
      "loss": 1.2686,
      "step": 750
    },
    {
      "epoch": 0.12196100457353767,
      "grad_norm": 0.21145564317703247,
      "learning_rate": 1.9994056511090206e-05,
      "loss": 1.4826,
      "step": 760
    },
    {
      "epoch": 0.1235657546337158,
      "grad_norm": 0.3231908679008484,
      "learning_rate": 1.999344423400477e-05,
      "loss": 1.4589,
      "step": 770
    },
    {
      "epoch": 0.12517050469389393,
      "grad_norm": 0.3717208802700043,
      "learning_rate": 1.99928019567705e-05,
      "loss": 1.3377,
      "step": 780
    },
    {
      "epoch": 0.12677525475407206,
      "grad_norm": 0.43220949172973633,
      "learning_rate": 1.99921296813155e-05,
      "loss": 1.5013,
      "step": 790
    },
    {
      "epoch": 0.1283800048142502,
      "grad_norm": 0.3270035982131958,
      "learning_rate": 1.9991427409657927e-05,
      "loss": 1.3934,
      "step": 800
    },
    {
      "epoch": 0.12998475487442832,
      "grad_norm": 0.30780377984046936,
      "learning_rate": 1.9990695143906e-05,
      "loss": 1.2953,
      "step": 810
    },
    {
      "epoch": 0.13158950493460644,
      "grad_norm": 0.33227553963661194,
      "learning_rate": 1.9989932886257956e-05,
      "loss": 1.439,
      "step": 820
    },
    {
      "epoch": 0.13319425499478457,
      "grad_norm": 0.28366976976394653,
      "learning_rate": 1.9989140639002087e-05,
      "loss": 1.3491,
      "step": 830
    },
    {
      "epoch": 0.1347990050549627,
      "grad_norm": 0.26644396781921387,
      "learning_rate": 1.9988318404516704e-05,
      "loss": 1.511,
      "step": 840
    },
    {
      "epoch": 0.13640375511514083,
      "grad_norm": 0.4942858815193176,
      "learning_rate": 1.9987466185270136e-05,
      "loss": 1.357,
      "step": 850
    },
    {
      "epoch": 0.13800850517531896,
      "grad_norm": 0.3311348557472229,
      "learning_rate": 1.9986583983820735e-05,
      "loss": 1.3618,
      "step": 860
    },
    {
      "epoch": 0.13961325523549706,
      "grad_norm": 0.31968429684638977,
      "learning_rate": 1.9985671802816856e-05,
      "loss": 1.4922,
      "step": 870
    },
    {
      "epoch": 0.1412180052956752,
      "grad_norm": 0.3222774267196655,
      "learning_rate": 1.9984729644996847e-05,
      "loss": 1.4004,
      "step": 880
    },
    {
      "epoch": 0.14282275535585331,
      "grad_norm": 0.18249015510082245,
      "learning_rate": 1.9983757513189052e-05,
      "loss": 1.5577,
      "step": 890
    },
    {
      "epoch": 0.14442750541603144,
      "grad_norm": 0.42832791805267334,
      "learning_rate": 1.9982755410311797e-05,
      "loss": 1.5892,
      "step": 900
    },
    {
      "epoch": 0.14603225547620957,
      "grad_norm": 0.18397381901741028,
      "learning_rate": 1.9981723339373368e-05,
      "loss": 1.3315,
      "step": 910
    },
    {
      "epoch": 0.1476370055363877,
      "grad_norm": 0.3339751064777374,
      "learning_rate": 1.9980661303472037e-05,
      "loss": 1.5259,
      "step": 920
    },
    {
      "epoch": 0.14924175559656583,
      "grad_norm": 0.3031497001647949,
      "learning_rate": 1.9979569305796007e-05,
      "loss": 1.4001,
      "step": 930
    },
    {
      "epoch": 0.15084650565674396,
      "grad_norm": 0.405518114566803,
      "learning_rate": 1.997844734962344e-05,
      "loss": 1.3445,
      "step": 940
    },
    {
      "epoch": 0.15245125571692208,
      "grad_norm": 0.47668471932411194,
      "learning_rate": 1.9977295438322436e-05,
      "loss": 1.5786,
      "step": 950
    },
    {
      "epoch": 0.1540560057771002,
      "grad_norm": 0.3258664011955261,
      "learning_rate": 1.9976113575351e-05,
      "loss": 1.4733,
      "step": 960
    },
    {
      "epoch": 0.15566075583727834,
      "grad_norm": 0.3526577651500702,
      "learning_rate": 1.9974901764257076e-05,
      "loss": 1.4762,
      "step": 970
    },
    {
      "epoch": 0.15726550589745647,
      "grad_norm": 0.46706467866897583,
      "learning_rate": 1.9973660008678495e-05,
      "loss": 1.3709,
      "step": 980
    },
    {
      "epoch": 0.1588702559576346,
      "grad_norm": 0.21115006506443024,
      "learning_rate": 1.9972388312342985e-05,
      "loss": 1.2211,
      "step": 990
    },
    {
      "epoch": 0.16047500601781273,
      "grad_norm": 0.3447129428386688,
      "learning_rate": 1.9971086679068158e-05,
      "loss": 1.4605,
      "step": 1000
    },
    {
      "epoch": 0.16207975607799086,
      "grad_norm": 0.4207737445831299,
      "learning_rate": 1.9969755112761498e-05,
      "loss": 1.4411,
      "step": 1010
    },
    {
      "epoch": 0.16368450613816898,
      "grad_norm": 0.2579144835472107,
      "learning_rate": 1.9968393617420338e-05,
      "loss": 1.64,
      "step": 1020
    },
    {
      "epoch": 0.1652892561983471,
      "grad_norm": 0.344101220369339,
      "learning_rate": 1.996700219713187e-05,
      "loss": 1.4166,
      "step": 1030
    },
    {
      "epoch": 0.16689400625852524,
      "grad_norm": 0.23667895793914795,
      "learning_rate": 1.996558085607311e-05,
      "loss": 1.3532,
      "step": 1040
    },
    {
      "epoch": 0.16849875631870337,
      "grad_norm": 0.21985171735286713,
      "learning_rate": 1.99641295985109e-05,
      "loss": 1.243,
      "step": 1050
    },
    {
      "epoch": 0.1701035063788815,
      "grad_norm": 0.27326464653015137,
      "learning_rate": 1.996264842880189e-05,
      "loss": 1.3649,
      "step": 1060
    },
    {
      "epoch": 0.17170825643905963,
      "grad_norm": 0.4023990035057068,
      "learning_rate": 1.996113735139253e-05,
      "loss": 1.3713,
      "step": 1070
    },
    {
      "epoch": 0.17331300649923775,
      "grad_norm": 0.3184084892272949,
      "learning_rate": 1.9959596370819044e-05,
      "loss": 1.6325,
      "step": 1080
    },
    {
      "epoch": 0.17491775655941588,
      "grad_norm": 0.26201358437538147,
      "learning_rate": 1.9958025491707433e-05,
      "loss": 1.3561,
      "step": 1090
    },
    {
      "epoch": 0.176522506619594,
      "grad_norm": 0.26962459087371826,
      "learning_rate": 1.9956424718773446e-05,
      "loss": 1.3779,
      "step": 1100
    },
    {
      "epoch": 0.17812725667977214,
      "grad_norm": 0.4136592149734497,
      "learning_rate": 1.995479405682258e-05,
      "loss": 1.3318,
      "step": 1110
    },
    {
      "epoch": 0.17973200673995024,
      "grad_norm": 0.270411878824234,
      "learning_rate": 1.995313351075005e-05,
      "loss": 1.4766,
      "step": 1120
    },
    {
      "epoch": 0.18133675680012837,
      "grad_norm": 0.29305052757263184,
      "learning_rate": 1.9951443085540788e-05,
      "loss": 1.2422,
      "step": 1130
    },
    {
      "epoch": 0.1829415068603065,
      "grad_norm": 0.19487319886684418,
      "learning_rate": 1.9949722786269423e-05,
      "loss": 1.1858,
      "step": 1140
    },
    {
      "epoch": 0.18454625692048462,
      "grad_norm": 0.3168809413909912,
      "learning_rate": 1.9947972618100263e-05,
      "loss": 1.3227,
      "step": 1150
    },
    {
      "epoch": 0.18615100698066275,
      "grad_norm": 0.2984825074672699,
      "learning_rate": 1.9946192586287282e-05,
      "loss": 1.3995,
      "step": 1160
    },
    {
      "epoch": 0.18775575704084088,
      "grad_norm": 0.3263907730579376,
      "learning_rate": 1.994438269617411e-05,
      "loss": 1.3973,
      "step": 1170
    },
    {
      "epoch": 0.189360507101019,
      "grad_norm": 0.44990864396095276,
      "learning_rate": 1.9942542953193998e-05,
      "loss": 1.5862,
      "step": 1180
    },
    {
      "epoch": 0.19096525716119714,
      "grad_norm": 0.2634500563144684,
      "learning_rate": 1.994067336286983e-05,
      "loss": 1.3844,
      "step": 1190
    },
    {
      "epoch": 0.19257000722137527,
      "grad_norm": 0.24371641874313354,
      "learning_rate": 1.993877393081408e-05,
      "loss": 1.4164,
      "step": 1200
    },
    {
      "epoch": 0.1941747572815534,
      "grad_norm": 0.3149561882019043,
      "learning_rate": 1.9936844662728812e-05,
      "loss": 1.4246,
      "step": 1210
    },
    {
      "epoch": 0.19577950734173152,
      "grad_norm": 0.4185996353626251,
      "learning_rate": 1.993488556440566e-05,
      "loss": 1.4373,
      "step": 1220
    },
    {
      "epoch": 0.19738425740190965,
      "grad_norm": 0.22970063984394073,
      "learning_rate": 1.9932896641725797e-05,
      "loss": 1.3437,
      "step": 1230
    },
    {
      "epoch": 0.19898900746208778,
      "grad_norm": 0.2679067850112915,
      "learning_rate": 1.9930877900659938e-05,
      "loss": 1.3521,
      "step": 1240
    },
    {
      "epoch": 0.2005937575222659,
      "grad_norm": 0.2405499666929245,
      "learning_rate": 1.992882934726831e-05,
      "loss": 1.5418,
      "step": 1250
    },
    {
      "epoch": 0.20219850758244404,
      "grad_norm": 0.28226134181022644,
      "learning_rate": 1.992675098770063e-05,
      "loss": 1.3583,
      "step": 1260
    },
    {
      "epoch": 0.20380325764262217,
      "grad_norm": 0.2068435102701187,
      "learning_rate": 1.9924642828196107e-05,
      "loss": 1.3112,
      "step": 1270
    },
    {
      "epoch": 0.2054080077028003,
      "grad_norm": 0.40549182891845703,
      "learning_rate": 1.9922504875083394e-05,
      "loss": 1.4267,
      "step": 1280
    },
    {
      "epoch": 0.20701275776297842,
      "grad_norm": 0.38925135135650635,
      "learning_rate": 1.9920337134780588e-05,
      "loss": 1.3663,
      "step": 1290
    },
    {
      "epoch": 0.20861750782315655,
      "grad_norm": 0.3278457224369049,
      "learning_rate": 1.9918139613795217e-05,
      "loss": 1.4885,
      "step": 1300
    },
    {
      "epoch": 0.21022225788333468,
      "grad_norm": 0.25548163056373596,
      "learning_rate": 1.991591231872419e-05,
      "loss": 1.3177,
      "step": 1310
    },
    {
      "epoch": 0.2118270079435128,
      "grad_norm": 0.2191590666770935,
      "learning_rate": 1.9913655256253815e-05,
      "loss": 1.3191,
      "step": 1320
    },
    {
      "epoch": 0.21343175800369094,
      "grad_norm": 0.3952718675136566,
      "learning_rate": 1.9911368433159754e-05,
      "loss": 1.4215,
      "step": 1330
    },
    {
      "epoch": 0.21503650806386906,
      "grad_norm": 0.40167179703712463,
      "learning_rate": 1.990905185630701e-05,
      "loss": 1.5291,
      "step": 1340
    },
    {
      "epoch": 0.2166412581240472,
      "grad_norm": 0.44336745142936707,
      "learning_rate": 1.990670553264991e-05,
      "loss": 1.37,
      "step": 1350
    },
    {
      "epoch": 0.21824600818422532,
      "grad_norm": 0.4026157557964325,
      "learning_rate": 1.9904329469232076e-05,
      "loss": 1.4131,
      "step": 1360
    },
    {
      "epoch": 0.21985075824440342,
      "grad_norm": 0.33255305886268616,
      "learning_rate": 1.990192367318641e-05,
      "loss": 1.4972,
      "step": 1370
    },
    {
      "epoch": 0.22145550830458155,
      "grad_norm": 0.28011998534202576,
      "learning_rate": 1.989948815173507e-05,
      "loss": 1.3647,
      "step": 1380
    },
    {
      "epoch": 0.22306025836475968,
      "grad_norm": 0.23420965671539307,
      "learning_rate": 1.9897022912189445e-05,
      "loss": 1.3953,
      "step": 1390
    },
    {
      "epoch": 0.2246650084249378,
      "grad_norm": 0.386967271566391,
      "learning_rate": 1.989452796195015e-05,
      "loss": 1.3783,
      "step": 1400
    },
    {
      "epoch": 0.22626975848511593,
      "grad_norm": 0.26505544781684875,
      "learning_rate": 1.989200330850698e-05,
      "loss": 1.4478,
      "step": 1410
    },
    {
      "epoch": 0.22787450854529406,
      "grad_norm": 0.22895698249340057,
      "learning_rate": 1.9889448959438903e-05,
      "loss": 1.4864,
      "step": 1420
    },
    {
      "epoch": 0.2294792586054722,
      "grad_norm": 0.27550992369651794,
      "learning_rate": 1.988686492241403e-05,
      "loss": 1.4158,
      "step": 1430
    },
    {
      "epoch": 0.23108400866565032,
      "grad_norm": 0.4306904375553131,
      "learning_rate": 1.9884251205189593e-05,
      "loss": 1.3682,
      "step": 1440
    },
    {
      "epoch": 0.23268875872582845,
      "grad_norm": 0.21296507120132446,
      "learning_rate": 1.9881607815611927e-05,
      "loss": 1.3884,
      "step": 1450
    },
    {
      "epoch": 0.23429350878600658,
      "grad_norm": 0.24282608926296234,
      "learning_rate": 1.9878934761616447e-05,
      "loss": 1.2864,
      "step": 1460
    },
    {
      "epoch": 0.2358982588461847,
      "grad_norm": 0.36954039335250854,
      "learning_rate": 1.9876232051227613e-05,
      "loss": 1.4983,
      "step": 1470
    },
    {
      "epoch": 0.23750300890636283,
      "grad_norm": 0.34447595477104187,
      "learning_rate": 1.9873499692558914e-05,
      "loss": 1.4084,
      "step": 1480
    },
    {
      "epoch": 0.23910775896654096,
      "grad_norm": 0.423593133687973,
      "learning_rate": 1.9870737693812846e-05,
      "loss": 1.35,
      "step": 1490
    },
    {
      "epoch": 0.2407125090267191,
      "grad_norm": 0.38388440012931824,
      "learning_rate": 1.9867946063280882e-05,
      "loss": 1.389,
      "step": 1500
    },
    {
      "epoch": 0.24231725908689722,
      "grad_norm": 0.3835993707180023,
      "learning_rate": 1.9865124809343447e-05,
      "loss": 1.2998,
      "step": 1510
    },
    {
      "epoch": 0.24392200914707535,
      "grad_norm": 0.6537964344024658,
      "learning_rate": 1.9862273940469898e-05,
      "loss": 1.3418,
      "step": 1520
    },
    {
      "epoch": 0.24552675920725348,
      "grad_norm": 0.29857540130615234,
      "learning_rate": 1.9859393465218497e-05,
      "loss": 1.4264,
      "step": 1530
    },
    {
      "epoch": 0.2471315092674316,
      "grad_norm": 0.36309733986854553,
      "learning_rate": 1.985648339223638e-05,
      "loss": 1.4351,
      "step": 1540
    },
    {
      "epoch": 0.24873625932760973,
      "grad_norm": 0.30575835704803467,
      "learning_rate": 1.9853543730259535e-05,
      "loss": 1.4307,
      "step": 1550
    },
    {
      "epoch": 0.25034100938778786,
      "grad_norm": 0.286000519990921,
      "learning_rate": 1.9850574488112776e-05,
      "loss": 1.3838,
      "step": 1560
    },
    {
      "epoch": 0.251945759447966,
      "grad_norm": 0.2919764220714569,
      "learning_rate": 1.9847575674709723e-05,
      "loss": 1.3995,
      "step": 1570
    },
    {
      "epoch": 0.2535505095081441,
      "grad_norm": 0.30116719007492065,
      "learning_rate": 1.9844547299052756e-05,
      "loss": 1.3908,
      "step": 1580
    },
    {
      "epoch": 0.25515525956832225,
      "grad_norm": 0.3683610260486603,
      "learning_rate": 1.9841489370233012e-05,
      "loss": 1.3468,
      "step": 1590
    },
    {
      "epoch": 0.2567600096285004,
      "grad_norm": 0.32669150829315186,
      "learning_rate": 1.9838401897430336e-05,
      "loss": 1.2323,
      "step": 1600
    },
    {
      "epoch": 0.2583647596886785,
      "grad_norm": 0.3483133316040039,
      "learning_rate": 1.9835284889913275e-05,
      "loss": 1.3231,
      "step": 1610
    },
    {
      "epoch": 0.25996950974885663,
      "grad_norm": 0.3334028422832489,
      "learning_rate": 1.9832138357039024e-05,
      "loss": 1.3346,
      "step": 1620
    },
    {
      "epoch": 0.26157425980903476,
      "grad_norm": 0.2740734815597534,
      "learning_rate": 1.982896230825343e-05,
      "loss": 1.275,
      "step": 1630
    },
    {
      "epoch": 0.2631790098692129,
      "grad_norm": 0.21739724278450012,
      "learning_rate": 1.982575675309093e-05,
      "loss": 1.3771,
      "step": 1640
    },
    {
      "epoch": 0.264783759929391,
      "grad_norm": 0.3791095018386841,
      "learning_rate": 1.982252170117455e-05,
      "loss": 1.3938,
      "step": 1650
    },
    {
      "epoch": 0.26638850998956914,
      "grad_norm": 0.4676331579685211,
      "learning_rate": 1.981925716221586e-05,
      "loss": 1.4098,
      "step": 1660
    },
    {
      "epoch": 0.2679932600497473,
      "grad_norm": 0.42060697078704834,
      "learning_rate": 1.9815963146014948e-05,
      "loss": 1.489,
      "step": 1670
    },
    {
      "epoch": 0.2695980101099254,
      "grad_norm": 0.3207416534423828,
      "learning_rate": 1.9812639662460396e-05,
      "loss": 1.5135,
      "step": 1680
    },
    {
      "epoch": 0.27120276017010353,
      "grad_norm": 0.19730353355407715,
      "learning_rate": 1.9809286721529246e-05,
      "loss": 1.5137,
      "step": 1690
    },
    {
      "epoch": 0.27280751023028166,
      "grad_norm": 0.22617162764072418,
      "learning_rate": 1.980590433328697e-05,
      "loss": 1.4917,
      "step": 1700
    },
    {
      "epoch": 0.2744122602904598,
      "grad_norm": 0.3663794994354248,
      "learning_rate": 1.9802492507887434e-05,
      "loss": 1.3597,
      "step": 1710
    },
    {
      "epoch": 0.2760170103506379,
      "grad_norm": 0.3326999843120575,
      "learning_rate": 1.9799051255572884e-05,
      "loss": 1.2681,
      "step": 1720
    },
    {
      "epoch": 0.27762176041081604,
      "grad_norm": 0.3930642008781433,
      "learning_rate": 1.97955805866739e-05,
      "loss": 1.501,
      "step": 1730
    },
    {
      "epoch": 0.2792265104709941,
      "grad_norm": 0.34715524315834045,
      "learning_rate": 1.9792080511609372e-05,
      "loss": 1.3983,
      "step": 1740
    },
    {
      "epoch": 0.28083126053117224,
      "grad_norm": 0.36794325709342957,
      "learning_rate": 1.9788551040886465e-05,
      "loss": 1.378,
      "step": 1750
    },
    {
      "epoch": 0.2824360105913504,
      "grad_norm": 0.2995903193950653,
      "learning_rate": 1.9784992185100585e-05,
      "loss": 1.4939,
      "step": 1760
    },
    {
      "epoch": 0.2840407606515285,
      "grad_norm": 0.2723531723022461,
      "learning_rate": 1.9781403954935365e-05,
      "loss": 1.4785,
      "step": 1770
    },
    {
      "epoch": 0.28564551071170663,
      "grad_norm": 0.3530333638191223,
      "learning_rate": 1.97777863611626e-05,
      "loss": 1.4255,
      "step": 1780
    },
    {
      "epoch": 0.28725026077188476,
      "grad_norm": 0.3557887077331543,
      "learning_rate": 1.9774139414642256e-05,
      "loss": 1.381,
      "step": 1790
    },
    {
      "epoch": 0.2888550108320629,
      "grad_norm": 0.3029628098011017,
      "learning_rate": 1.9770463126322396e-05,
      "loss": 1.3856,
      "step": 1800
    },
    {
      "epoch": 0.290459760892241,
      "grad_norm": 0.30022427439689636,
      "learning_rate": 1.976675750723918e-05,
      "loss": 1.2598,
      "step": 1810
    },
    {
      "epoch": 0.29206451095241914,
      "grad_norm": 0.25942111015319824,
      "learning_rate": 1.976302256851681e-05,
      "loss": 1.369,
      "step": 1820
    },
    {
      "epoch": 0.29366926101259727,
      "grad_norm": 0.39943525195121765,
      "learning_rate": 1.9759258321367506e-05,
      "loss": 1.2573,
      "step": 1830
    },
    {
      "epoch": 0.2952740110727754,
      "grad_norm": 0.28279179334640503,
      "learning_rate": 1.9755464777091477e-05,
      "loss": 1.4102,
      "step": 1840
    },
    {
      "epoch": 0.29687876113295353,
      "grad_norm": 0.31728804111480713,
      "learning_rate": 1.9751641947076877e-05,
      "loss": 1.3843,
      "step": 1850
    },
    {
      "epoch": 0.29848351119313166,
      "grad_norm": 0.39161691069602966,
      "learning_rate": 1.974778984279978e-05,
      "loss": 1.3455,
      "step": 1860
    },
    {
      "epoch": 0.3000882612533098,
      "grad_norm": 0.40414389967918396,
      "learning_rate": 1.9743908475824134e-05,
      "loss": 1.3299,
      "step": 1870
    },
    {
      "epoch": 0.3016930113134879,
      "grad_norm": 0.3219362497329712,
      "learning_rate": 1.9739997857801737e-05,
      "loss": 1.3351,
      "step": 1880
    },
    {
      "epoch": 0.30329776137366604,
      "grad_norm": 0.4149847626686096,
      "learning_rate": 1.9736058000472195e-05,
      "loss": 1.2271,
      "step": 1890
    },
    {
      "epoch": 0.30490251143384417,
      "grad_norm": 0.2929013967514038,
      "learning_rate": 1.9732088915662895e-05,
      "loss": 1.2845,
      "step": 1900
    },
    {
      "epoch": 0.3065072614940223,
      "grad_norm": 0.23451751470565796,
      "learning_rate": 1.972809061528896e-05,
      "loss": 1.5366,
      "step": 1910
    },
    {
      "epoch": 0.3081120115542004,
      "grad_norm": 0.46130135655403137,
      "learning_rate": 1.972406311135322e-05,
      "loss": 1.338,
      "step": 1920
    },
    {
      "epoch": 0.30971676161437856,
      "grad_norm": 0.2804974615573883,
      "learning_rate": 1.9720006415946175e-05,
      "loss": 1.4128,
      "step": 1930
    },
    {
      "epoch": 0.3113215116745567,
      "grad_norm": 0.36125385761260986,
      "learning_rate": 1.9715920541245956e-05,
      "loss": 1.3309,
      "step": 1940
    },
    {
      "epoch": 0.3129262617347348,
      "grad_norm": 0.40560418367385864,
      "learning_rate": 1.9711805499518287e-05,
      "loss": 1.5499,
      "step": 1950
    },
    {
      "epoch": 0.31453101179491294,
      "grad_norm": 0.17646387219429016,
      "learning_rate": 1.970766130311645e-05,
      "loss": 1.5559,
      "step": 1960
    },
    {
      "epoch": 0.31613576185509107,
      "grad_norm": 0.3691346049308777,
      "learning_rate": 1.9703487964481255e-05,
      "loss": 1.3178,
      "step": 1970
    },
    {
      "epoch": 0.3177405119152692,
      "grad_norm": 0.2070036679506302,
      "learning_rate": 1.9699285496140992e-05,
      "loss": 1.3373,
      "step": 1980
    },
    {
      "epoch": 0.3193452619754473,
      "grad_norm": 0.5338124632835388,
      "learning_rate": 1.9695053910711402e-05,
      "loss": 1.4328,
      "step": 1990
    },
    {
      "epoch": 0.32095001203562545,
      "grad_norm": 0.2903488874435425,
      "learning_rate": 1.969079322089563e-05,
      "loss": 1.4666,
      "step": 2000
    },
    {
      "epoch": 0.3225547620958036,
      "grad_norm": 0.3406471312046051,
      "learning_rate": 1.9686503439484193e-05,
      "loss": 1.522,
      "step": 2010
    },
    {
      "epoch": 0.3241595121559817,
      "grad_norm": 0.3346569836139679,
      "learning_rate": 1.9682184579354943e-05,
      "loss": 1.2533,
      "step": 2020
    },
    {
      "epoch": 0.32576426221615984,
      "grad_norm": 0.467851847410202,
      "learning_rate": 1.9677836653473025e-05,
      "loss": 1.2884,
      "step": 2030
    },
    {
      "epoch": 0.32736901227633797,
      "grad_norm": 0.25201156735420227,
      "learning_rate": 1.967345967489084e-05,
      "loss": 1.2345,
      "step": 2040
    },
    {
      "epoch": 0.3289737623365161,
      "grad_norm": 0.292625367641449,
      "learning_rate": 1.9669053656747998e-05,
      "loss": 1.2452,
      "step": 2050
    },
    {
      "epoch": 0.3305785123966942,
      "grad_norm": 0.3019048571586609,
      "learning_rate": 1.9664618612271292e-05,
      "loss": 1.4723,
      "step": 2060
    },
    {
      "epoch": 0.33218326245687235,
      "grad_norm": 0.28457310795783997,
      "learning_rate": 1.966015455477465e-05,
      "loss": 1.5676,
      "step": 2070
    },
    {
      "epoch": 0.3337880125170505,
      "grad_norm": 0.2934150695800781,
      "learning_rate": 1.9655661497659096e-05,
      "loss": 1.5,
      "step": 2080
    },
    {
      "epoch": 0.3353927625772286,
      "grad_norm": 0.2713722884654999,
      "learning_rate": 1.9651139454412707e-05,
      "loss": 1.3849,
      "step": 2090
    },
    {
      "epoch": 0.33699751263740674,
      "grad_norm": 0.35259222984313965,
      "learning_rate": 1.964658843861059e-05,
      "loss": 1.3197,
      "step": 2100
    },
    {
      "epoch": 0.33860226269758487,
      "grad_norm": 0.23005594313144684,
      "learning_rate": 1.9642008463914807e-05,
      "loss": 1.3221,
      "step": 2110
    },
    {
      "epoch": 0.340207012757763,
      "grad_norm": 0.30540376901626587,
      "learning_rate": 1.9637399544074368e-05,
      "loss": 1.4508,
      "step": 2120
    },
    {
      "epoch": 0.3418117628179411,
      "grad_norm": 0.40802201628685,
      "learning_rate": 1.963276169292517e-05,
      "loss": 1.3976,
      "step": 2130
    },
    {
      "epoch": 0.34341651287811925,
      "grad_norm": 0.42711758613586426,
      "learning_rate": 1.962809492438997e-05,
      "loss": 1.3909,
      "step": 2140
    },
    {
      "epoch": 0.3450212629382974,
      "grad_norm": 0.26663872599601746,
      "learning_rate": 1.9623399252478316e-05,
      "loss": 1.3637,
      "step": 2150
    },
    {
      "epoch": 0.3466260129984755,
      "grad_norm": 0.49782994389533997,
      "learning_rate": 1.9618674691286537e-05,
      "loss": 1.3991,
      "step": 2160
    },
    {
      "epoch": 0.34823076305865364,
      "grad_norm": 0.34774404764175415,
      "learning_rate": 1.961392125499769e-05,
      "loss": 1.4745,
      "step": 2170
    },
    {
      "epoch": 0.34983551311883176,
      "grad_norm": 0.4350658059120178,
      "learning_rate": 1.960913895788151e-05,
      "loss": 1.3528,
      "step": 2180
    },
    {
      "epoch": 0.3514402631790099,
      "grad_norm": 0.30385681986808777,
      "learning_rate": 1.9604327814294363e-05,
      "loss": 1.2378,
      "step": 2190
    },
    {
      "epoch": 0.353045013239188,
      "grad_norm": 0.2511212229728699,
      "learning_rate": 1.959948783867923e-05,
      "loss": 1.2355,
      "step": 2200
    },
    {
      "epoch": 0.35464976329936615,
      "grad_norm": 0.30395057797431946,
      "learning_rate": 1.959461904556563e-05,
      "loss": 1.2358,
      "step": 2210
    },
    {
      "epoch": 0.3562545133595443,
      "grad_norm": 0.457220196723938,
      "learning_rate": 1.9589721449569595e-05,
      "loss": 1.2964,
      "step": 2220
    },
    {
      "epoch": 0.35785926341972235,
      "grad_norm": 0.272195965051651,
      "learning_rate": 1.9584795065393633e-05,
      "loss": 1.2718,
      "step": 2230
    },
    {
      "epoch": 0.3594640134799005,
      "grad_norm": 0.3350317180156708,
      "learning_rate": 1.9579839907826655e-05,
      "loss": 1.2571,
      "step": 2240
    },
    {
      "epoch": 0.3610687635400786,
      "grad_norm": 0.351938933134079,
      "learning_rate": 1.957485599174396e-05,
      "loss": 1.3015,
      "step": 2250
    },
    {
      "epoch": 0.36267351360025674,
      "grad_norm": 0.37047067284584045,
      "learning_rate": 1.9569843332107186e-05,
      "loss": 1.2551,
      "step": 2260
    },
    {
      "epoch": 0.36427826366043486,
      "grad_norm": 0.2948170304298401,
      "learning_rate": 1.9564801943964246e-05,
      "loss": 1.3673,
      "step": 2270
    },
    {
      "epoch": 0.365883013720613,
      "grad_norm": 0.4895157516002655,
      "learning_rate": 1.9559731842449303e-05,
      "loss": 1.4032,
      "step": 2280
    },
    {
      "epoch": 0.3674877637807911,
      "grad_norm": 0.29684463143348694,
      "learning_rate": 1.9554633042782717e-05,
      "loss": 1.356,
      "step": 2290
    },
    {
      "epoch": 0.36909251384096925,
      "grad_norm": 0.3872864246368408,
      "learning_rate": 1.9549505560270993e-05,
      "loss": 1.3124,
      "step": 2300
    },
    {
      "epoch": 0.3706972639011474,
      "grad_norm": 0.39776426553726196,
      "learning_rate": 1.954434941030675e-05,
      "loss": 1.3806,
      "step": 2310
    },
    {
      "epoch": 0.3723020139613255,
      "grad_norm": 0.2617858648300171,
      "learning_rate": 1.9539164608368657e-05,
      "loss": 1.3603,
      "step": 2320
    },
    {
      "epoch": 0.37390676402150363,
      "grad_norm": 0.38514503836631775,
      "learning_rate": 1.953395117002141e-05,
      "loss": 1.4355,
      "step": 2330
    },
    {
      "epoch": 0.37551151408168176,
      "grad_norm": 0.30052679777145386,
      "learning_rate": 1.952870911091565e-05,
      "loss": 1.3452,
      "step": 2340
    },
    {
      "epoch": 0.3771162641418599,
      "grad_norm": 0.3276200592517853,
      "learning_rate": 1.952343844678796e-05,
      "loss": 1.3827,
      "step": 2350
    },
    {
      "epoch": 0.378721014202038,
      "grad_norm": 0.2065112441778183,
      "learning_rate": 1.9518139193460775e-05,
      "loss": 1.218,
      "step": 2360
    },
    {
      "epoch": 0.38032576426221615,
      "grad_norm": 0.3966623544692993,
      "learning_rate": 1.9512811366842367e-05,
      "loss": 1.4419,
      "step": 2370
    },
    {
      "epoch": 0.3819305143223943,
      "grad_norm": 0.3066747784614563,
      "learning_rate": 1.950745498292678e-05,
      "loss": 1.6141,
      "step": 2380
    },
    {
      "epoch": 0.3835352643825724,
      "grad_norm": 0.4463857412338257,
      "learning_rate": 1.950207005779379e-05,
      "loss": 1.4721,
      "step": 2390
    },
    {
      "epoch": 0.38514001444275053,
      "grad_norm": 0.41368722915649414,
      "learning_rate": 1.9496656607608845e-05,
      "loss": 1.3954,
      "step": 2400
    },
    {
      "epoch": 0.38674476450292866,
      "grad_norm": 0.3056279718875885,
      "learning_rate": 1.949121464862303e-05,
      "loss": 1.3686,
      "step": 2410
    },
    {
      "epoch": 0.3883495145631068,
      "grad_norm": 0.5210683941841125,
      "learning_rate": 1.9485744197173016e-05,
      "loss": 1.5396,
      "step": 2420
    },
    {
      "epoch": 0.3899542646232849,
      "grad_norm": 0.35678398609161377,
      "learning_rate": 1.9480245269681006e-05,
      "loss": 1.2616,
      "step": 2430
    },
    {
      "epoch": 0.39155901468346305,
      "grad_norm": 0.3954680263996124,
      "learning_rate": 1.9474717882654682e-05,
      "loss": 1.2884,
      "step": 2440
    },
    {
      "epoch": 0.3931637647436412,
      "grad_norm": 0.412992924451828,
      "learning_rate": 1.9469162052687166e-05,
      "loss": 1.5022,
      "step": 2450
    },
    {
      "epoch": 0.3947685148038193,
      "grad_norm": 0.43660473823547363,
      "learning_rate": 1.946357779645697e-05,
      "loss": 1.1959,
      "step": 2460
    },
    {
      "epoch": 0.39637326486399743,
      "grad_norm": 0.35781991481781006,
      "learning_rate": 1.945796513072793e-05,
      "loss": 1.2859,
      "step": 2470
    },
    {
      "epoch": 0.39797801492417556,
      "grad_norm": 0.3486938774585724,
      "learning_rate": 1.945232407234918e-05,
      "loss": 1.3424,
      "step": 2480
    },
    {
      "epoch": 0.3995827649843537,
      "grad_norm": 0.41157066822052,
      "learning_rate": 1.9446654638255066e-05,
      "loss": 1.3515,
      "step": 2490
    },
    {
      "epoch": 0.4011875150445318,
      "grad_norm": 0.2521686851978302,
      "learning_rate": 1.944095684546515e-05,
      "loss": 1.2965,
      "step": 2500
    },
    {
      "epoch": 0.40279226510470995,
      "grad_norm": 0.3465510308742523,
      "learning_rate": 1.9435230711084093e-05,
      "loss": 1.3103,
      "step": 2510
    },
    {
      "epoch": 0.4043970151648881,
      "grad_norm": 0.4512653350830078,
      "learning_rate": 1.9429476252301667e-05,
      "loss": 1.3535,
      "step": 2520
    },
    {
      "epoch": 0.4060017652250662,
      "grad_norm": 0.22823373973369598,
      "learning_rate": 1.942369348639265e-05,
      "loss": 1.2815,
      "step": 2530
    },
    {
      "epoch": 0.40760651528524433,
      "grad_norm": 0.2904421389102936,
      "learning_rate": 1.9417882430716806e-05,
      "loss": 1.274,
      "step": 2540
    },
    {
      "epoch": 0.40921126534542246,
      "grad_norm": 0.22718197107315063,
      "learning_rate": 1.9412043102718826e-05,
      "loss": 1.3225,
      "step": 2550
    },
    {
      "epoch": 0.4108160154056006,
      "grad_norm": 0.36589524149894714,
      "learning_rate": 1.9406175519928277e-05,
      "loss": 1.3205,
      "step": 2560
    },
    {
      "epoch": 0.4124207654657787,
      "grad_norm": 0.2226024568080902,
      "learning_rate": 1.940027969995954e-05,
      "loss": 1.3326,
      "step": 2570
    },
    {
      "epoch": 0.41402551552595684,
      "grad_norm": 0.32647380232810974,
      "learning_rate": 1.9394355660511764e-05,
      "loss": 1.3379,
      "step": 2580
    },
    {
      "epoch": 0.415630265586135,
      "grad_norm": 0.4311791658401489,
      "learning_rate": 1.9388403419368815e-05,
      "loss": 1.3571,
      "step": 2590
    },
    {
      "epoch": 0.4172350156463131,
      "grad_norm": 0.3705790638923645,
      "learning_rate": 1.938242299439922e-05,
      "loss": 1.3533,
      "step": 2600
    },
    {
      "epoch": 0.41883976570649123,
      "grad_norm": 0.243331179022789,
      "learning_rate": 1.937641440355611e-05,
      "loss": 1.4036,
      "step": 2610
    },
    {
      "epoch": 0.42044451576666936,
      "grad_norm": 0.4500161111354828,
      "learning_rate": 1.9370377664877174e-05,
      "loss": 1.4308,
      "step": 2620
    },
    {
      "epoch": 0.4220492658268475,
      "grad_norm": 0.3864496052265167,
      "learning_rate": 1.9364312796484602e-05,
      "loss": 1.3605,
      "step": 2630
    },
    {
      "epoch": 0.4236540158870256,
      "grad_norm": 0.33515220880508423,
      "learning_rate": 1.9358219816585022e-05,
      "loss": 1.3077,
      "step": 2640
    },
    {
      "epoch": 0.42525876594720374,
      "grad_norm": 0.5244264006614685,
      "learning_rate": 1.9352098743469453e-05,
      "loss": 1.2898,
      "step": 2650
    },
    {
      "epoch": 0.42686351600738187,
      "grad_norm": 0.31695449352264404,
      "learning_rate": 1.9345949595513257e-05,
      "loss": 1.4166,
      "step": 2660
    },
    {
      "epoch": 0.42846826606756,
      "grad_norm": 0.30906620621681213,
      "learning_rate": 1.9339772391176065e-05,
      "loss": 1.5144,
      "step": 2670
    },
    {
      "epoch": 0.43007301612773813,
      "grad_norm": 0.39018145203590393,
      "learning_rate": 1.9333567149001742e-05,
      "loss": 1.4156,
      "step": 2680
    },
    {
      "epoch": 0.43167776618791626,
      "grad_norm": 0.5267777442932129,
      "learning_rate": 1.932733388761832e-05,
      "loss": 1.4698,
      "step": 2690
    },
    {
      "epoch": 0.4332825162480944,
      "grad_norm": 0.4009230434894562,
      "learning_rate": 1.9321072625737943e-05,
      "loss": 1.3226,
      "step": 2700
    },
    {
      "epoch": 0.4348872663082725,
      "grad_norm": 0.3111720383167267,
      "learning_rate": 1.931478338215681e-05,
      "loss": 1.4184,
      "step": 2710
    },
    {
      "epoch": 0.43649201636845064,
      "grad_norm": 0.31122878193855286,
      "learning_rate": 1.930846617575513e-05,
      "loss": 1.2398,
      "step": 2720
    },
    {
      "epoch": 0.4380967664286287,
      "grad_norm": 0.40437036752700806,
      "learning_rate": 1.9302121025497037e-05,
      "loss": 1.3129,
      "step": 2730
    },
    {
      "epoch": 0.43970151648880684,
      "grad_norm": 0.3509606420993805,
      "learning_rate": 1.9295747950430575e-05,
      "loss": 1.3335,
      "step": 2740
    },
    {
      "epoch": 0.44130626654898497,
      "grad_norm": 0.3115660548210144,
      "learning_rate": 1.9289346969687598e-05,
      "loss": 1.3304,
      "step": 2750
    },
    {
      "epoch": 0.4429110166091631,
      "grad_norm": 0.30947375297546387,
      "learning_rate": 1.928291810248374e-05,
      "loss": 1.2904,
      "step": 2760
    },
    {
      "epoch": 0.44451576666934123,
      "grad_norm": 0.3383250832557678,
      "learning_rate": 1.927646136811836e-05,
      "loss": 1.3329,
      "step": 2770
    },
    {
      "epoch": 0.44612051672951936,
      "grad_norm": 0.4008086323738098,
      "learning_rate": 1.9269976785974456e-05,
      "loss": 1.364,
      "step": 2780
    },
    {
      "epoch": 0.4477252667896975,
      "grad_norm": 0.28436827659606934,
      "learning_rate": 1.9263464375518634e-05,
      "loss": 1.3141,
      "step": 2790
    },
    {
      "epoch": 0.4493300168498756,
      "grad_norm": 0.40010377764701843,
      "learning_rate": 1.9256924156301046e-05,
      "loss": 1.332,
      "step": 2800
    },
    {
      "epoch": 0.45093476691005374,
      "grad_norm": 0.37946265935897827,
      "learning_rate": 1.9250356147955308e-05,
      "loss": 1.2775,
      "step": 2810
    },
    {
      "epoch": 0.45253951697023187,
      "grad_norm": 0.3174775540828705,
      "learning_rate": 1.9243760370198475e-05,
      "loss": 1.4392,
      "step": 2820
    },
    {
      "epoch": 0.45414426703041,
      "grad_norm": 0.3594072461128235,
      "learning_rate": 1.9237136842830953e-05,
      "loss": 1.4264,
      "step": 2830
    },
    {
      "epoch": 0.4557490170905881,
      "grad_norm": 0.32715851068496704,
      "learning_rate": 1.923048558573647e-05,
      "loss": 1.3317,
      "step": 2840
    },
    {
      "epoch": 0.45735376715076625,
      "grad_norm": 0.30426010489463806,
      "learning_rate": 1.9223806618881974e-05,
      "loss": 1.2423,
      "step": 2850
    },
    {
      "epoch": 0.4589585172109444,
      "grad_norm": 0.31703969836235046,
      "learning_rate": 1.9217099962317614e-05,
      "loss": 1.199,
      "step": 2860
    },
    {
      "epoch": 0.4605632672711225,
      "grad_norm": 0.2574061155319214,
      "learning_rate": 1.9210365636176664e-05,
      "loss": 1.458,
      "step": 2870
    },
    {
      "epoch": 0.46216801733130064,
      "grad_norm": 0.3669300079345703,
      "learning_rate": 1.9203603660675445e-05,
      "loss": 1.1514,
      "step": 2880
    },
    {
      "epoch": 0.46377276739147877,
      "grad_norm": 0.5132482647895813,
      "learning_rate": 1.91968140561133e-05,
      "loss": 1.3781,
      "step": 2890
    },
    {
      "epoch": 0.4653775174516569,
      "grad_norm": 0.4987383186817169,
      "learning_rate": 1.9189996842872504e-05,
      "loss": 1.2753,
      "step": 2900
    },
    {
      "epoch": 0.466982267511835,
      "grad_norm": 0.6567516922950745,
      "learning_rate": 1.9183152041418212e-05,
      "loss": 1.331,
      "step": 2910
    },
    {
      "epoch": 0.46858701757201315,
      "grad_norm": 0.457297146320343,
      "learning_rate": 1.9176279672298403e-05,
      "loss": 1.2382,
      "step": 2920
    },
    {
      "epoch": 0.4701917676321913,
      "grad_norm": 0.3900405764579773,
      "learning_rate": 1.9169379756143814e-05,
      "loss": 1.3317,
      "step": 2930
    },
    {
      "epoch": 0.4717965176923694,
      "grad_norm": 0.46646952629089355,
      "learning_rate": 1.916245231366787e-05,
      "loss": 1.1852,
      "step": 2940
    },
    {
      "epoch": 0.47340126775254754,
      "grad_norm": 0.2655135691165924,
      "learning_rate": 1.9155497365666642e-05,
      "loss": 1.2231,
      "step": 2950
    },
    {
      "epoch": 0.47500601781272567,
      "grad_norm": 0.4266279637813568,
      "learning_rate": 1.9148514933018758e-05,
      "loss": 1.4414,
      "step": 2960
    },
    {
      "epoch": 0.4766107678729038,
      "grad_norm": 0.4702107906341553,
      "learning_rate": 1.9141505036685366e-05,
      "loss": 1.3614,
      "step": 2970
    },
    {
      "epoch": 0.4782155179330819,
      "grad_norm": 0.3613738715648651,
      "learning_rate": 1.9134467697710052e-05,
      "loss": 1.3396,
      "step": 2980
    },
    {
      "epoch": 0.47982026799326005,
      "grad_norm": 0.3401474952697754,
      "learning_rate": 1.912740293721879e-05,
      "loss": 1.5286,
      "step": 2990
    },
    {
      "epoch": 0.4814250180534382,
      "grad_norm": 0.3083174526691437,
      "learning_rate": 1.912031077641987e-05,
      "loss": 1.2264,
      "step": 3000
    },
    {
      "epoch": 0.4830297681136163,
      "grad_norm": 0.5213725566864014,
      "learning_rate": 1.9113191236603835e-05,
      "loss": 1.36,
      "step": 3010
    },
    {
      "epoch": 0.48463451817379444,
      "grad_norm": 0.3317253589630127,
      "learning_rate": 1.9106044339143427e-05,
      "loss": 1.4199,
      "step": 3020
    },
    {
      "epoch": 0.48623926823397257,
      "grad_norm": 0.548594057559967,
      "learning_rate": 1.9098870105493504e-05,
      "loss": 1.2182,
      "step": 3030
    },
    {
      "epoch": 0.4878440182941507,
      "grad_norm": 0.40180525183677673,
      "learning_rate": 1.9091668557190996e-05,
      "loss": 1.2334,
      "step": 3040
    },
    {
      "epoch": 0.4894487683543288,
      "grad_norm": 0.3728240430355072,
      "learning_rate": 1.9084439715854828e-05,
      "loss": 1.483,
      "step": 3050
    },
    {
      "epoch": 0.49105351841450695,
      "grad_norm": 0.30843567848205566,
      "learning_rate": 1.9077183603185858e-05,
      "loss": 1.5069,
      "step": 3060
    },
    {
      "epoch": 0.4926582684746851,
      "grad_norm": 0.3186185657978058,
      "learning_rate": 1.906990024096681e-05,
      "loss": 1.2054,
      "step": 3070
    },
    {
      "epoch": 0.4942630185348632,
      "grad_norm": 0.4824373424053192,
      "learning_rate": 1.9062589651062215e-05,
      "loss": 1.4438,
      "step": 3080
    },
    {
      "epoch": 0.49586776859504134,
      "grad_norm": 0.2819381356239319,
      "learning_rate": 1.9055251855418343e-05,
      "loss": 1.2917,
      "step": 3090
    },
    {
      "epoch": 0.49747251865521946,
      "grad_norm": 0.34851837158203125,
      "learning_rate": 1.9047886876063124e-05,
      "loss": 1.5048,
      "step": 3100
    },
    {
      "epoch": 0.4990772687153976,
      "grad_norm": 0.3761436641216278,
      "learning_rate": 1.90404947351061e-05,
      "loss": 1.2536,
      "step": 3110
    },
    {
      "epoch": 0.5006820187755757,
      "grad_norm": 0.27981412410736084,
      "learning_rate": 1.903307545473836e-05,
      "loss": 1.2497,
      "step": 3120
    },
    {
      "epoch": 0.5022867688357538,
      "grad_norm": 0.36180564761161804,
      "learning_rate": 1.902562905723245e-05,
      "loss": 1.3459,
      "step": 3130
    },
    {
      "epoch": 0.503891518895932,
      "grad_norm": 0.36484453082084656,
      "learning_rate": 1.901815556494233e-05,
      "loss": 1.4141,
      "step": 3140
    },
    {
      "epoch": 0.5054962689561101,
      "grad_norm": 0.23243507742881775,
      "learning_rate": 1.9010655000303296e-05,
      "loss": 1.4432,
      "step": 3150
    },
    {
      "epoch": 0.5071010190162882,
      "grad_norm": 0.35065749287605286,
      "learning_rate": 1.9003127385831915e-05,
      "loss": 1.3832,
      "step": 3160
    },
    {
      "epoch": 0.5087057690764664,
      "grad_norm": 0.4324915409088135,
      "learning_rate": 1.8995572744125957e-05,
      "loss": 1.4079,
      "step": 3170
    },
    {
      "epoch": 0.5103105191366445,
      "grad_norm": 0.4284380078315735,
      "learning_rate": 1.898799109786433e-05,
      "loss": 1.5292,
      "step": 3180
    },
    {
      "epoch": 0.5119152691968226,
      "grad_norm": 0.3151065707206726,
      "learning_rate": 1.8980382469807003e-05,
      "loss": 1.5696,
      "step": 3190
    },
    {
      "epoch": 0.5135200192570007,
      "grad_norm": 0.3540195822715759,
      "learning_rate": 1.8972746882794947e-05,
      "loss": 1.2148,
      "step": 3200
    },
    {
      "epoch": 0.5151247693171789,
      "grad_norm": 0.3250848352909088,
      "learning_rate": 1.8965084359750063e-05,
      "loss": 1.3675,
      "step": 3210
    },
    {
      "epoch": 0.516729519377357,
      "grad_norm": 0.5598359107971191,
      "learning_rate": 1.895739492367512e-05,
      "loss": 1.3954,
      "step": 3220
    },
    {
      "epoch": 0.5183342694375351,
      "grad_norm": 0.48755258321762085,
      "learning_rate": 1.8949678597653667e-05,
      "loss": 1.2994,
      "step": 3230
    },
    {
      "epoch": 0.5199390194977133,
      "grad_norm": 0.4555019438266754,
      "learning_rate": 1.8941935404849987e-05,
      "loss": 1.4163,
      "step": 3240
    },
    {
      "epoch": 0.5215437695578914,
      "grad_norm": 0.423035204410553,
      "learning_rate": 1.8934165368509012e-05,
      "loss": 1.3923,
      "step": 3250
    },
    {
      "epoch": 0.5231485196180695,
      "grad_norm": 0.3289142847061157,
      "learning_rate": 1.8926368511956256e-05,
      "loss": 1.3082,
      "step": 3260
    },
    {
      "epoch": 0.5247532696782476,
      "grad_norm": 0.49323341250419617,
      "learning_rate": 1.8918544858597755e-05,
      "loss": 1.4025,
      "step": 3270
    },
    {
      "epoch": 0.5263580197384258,
      "grad_norm": 0.3933897316455841,
      "learning_rate": 1.8910694431919974e-05,
      "loss": 1.3069,
      "step": 3280
    },
    {
      "epoch": 0.5279627697986039,
      "grad_norm": 0.3914484977722168,
      "learning_rate": 1.8902817255489766e-05,
      "loss": 1.4352,
      "step": 3290
    },
    {
      "epoch": 0.529567519858782,
      "grad_norm": 0.36485975980758667,
      "learning_rate": 1.8894913352954282e-05,
      "loss": 1.2946,
      "step": 3300
    },
    {
      "epoch": 0.5311722699189602,
      "grad_norm": 0.49147748947143555,
      "learning_rate": 1.8886982748040892e-05,
      "loss": 1.3534,
      "step": 3310
    },
    {
      "epoch": 0.5327770199791383,
      "grad_norm": 0.5096155405044556,
      "learning_rate": 1.8879025464557146e-05,
      "loss": 1.309,
      "step": 3320
    },
    {
      "epoch": 0.5343817700393164,
      "grad_norm": 0.3081822395324707,
      "learning_rate": 1.8871041526390673e-05,
      "loss": 1.3639,
      "step": 3330
    },
    {
      "epoch": 0.5359865200994945,
      "grad_norm": 0.3889482617378235,
      "learning_rate": 1.886303095750911e-05,
      "loss": 1.2441,
      "step": 3340
    },
    {
      "epoch": 0.5375912701596727,
      "grad_norm": 0.4356420040130615,
      "learning_rate": 1.885499378196006e-05,
      "loss": 1.3678,
      "step": 3350
    },
    {
      "epoch": 0.5391960202198508,
      "grad_norm": 0.40843820571899414,
      "learning_rate": 1.8846930023870977e-05,
      "loss": 1.309,
      "step": 3360
    },
    {
      "epoch": 0.5408007702800289,
      "grad_norm": 0.39451417326927185,
      "learning_rate": 1.883883970744913e-05,
      "loss": 1.2417,
      "step": 3370
    },
    {
      "epoch": 0.5424055203402071,
      "grad_norm": 0.3055882155895233,
      "learning_rate": 1.8830722856981508e-05,
      "loss": 1.2256,
      "step": 3380
    },
    {
      "epoch": 0.5440102704003852,
      "grad_norm": 0.4477522671222687,
      "learning_rate": 1.8822579496834762e-05,
      "loss": 1.4449,
      "step": 3390
    },
    {
      "epoch": 0.5456150204605633,
      "grad_norm": 0.36812475323677063,
      "learning_rate": 1.8814409651455115e-05,
      "loss": 1.2899,
      "step": 3400
    },
    {
      "epoch": 0.5472197705207414,
      "grad_norm": 0.38545629382133484,
      "learning_rate": 1.8806213345368304e-05,
      "loss": 1.1903,
      "step": 3410
    },
    {
      "epoch": 0.5488245205809196,
      "grad_norm": 0.35380756855010986,
      "learning_rate": 1.8797990603179505e-05,
      "loss": 1.4448,
      "step": 3420
    },
    {
      "epoch": 0.5504292706410977,
      "grad_norm": 0.506960391998291,
      "learning_rate": 1.8789741449573243e-05,
      "loss": 1.2862,
      "step": 3430
    },
    {
      "epoch": 0.5520340207012758,
      "grad_norm": 0.3036964535713196,
      "learning_rate": 1.878146590931334e-05,
      "loss": 1.2406,
      "step": 3440
    },
    {
      "epoch": 0.553638770761454,
      "grad_norm": 0.4081314504146576,
      "learning_rate": 1.877316400724282e-05,
      "loss": 1.4669,
      "step": 3450
    },
    {
      "epoch": 0.5552435208216321,
      "grad_norm": 0.35533151030540466,
      "learning_rate": 1.876483576828386e-05,
      "loss": 1.2666,
      "step": 3460
    },
    {
      "epoch": 0.5568482708818101,
      "grad_norm": 0.4648311138153076,
      "learning_rate": 1.8756481217437685e-05,
      "loss": 1.3472,
      "step": 3470
    },
    {
      "epoch": 0.5584530209419882,
      "grad_norm": 0.3758234679698944,
      "learning_rate": 1.874810037978452e-05,
      "loss": 1.3189,
      "step": 3480
    },
    {
      "epoch": 0.5600577710021664,
      "grad_norm": 0.34578830003738403,
      "learning_rate": 1.873969328048349e-05,
      "loss": 1.5464,
      "step": 3490
    },
    {
      "epoch": 0.5616625210623445,
      "grad_norm": 0.44013527035713196,
      "learning_rate": 1.8731259944772566e-05,
      "loss": 1.3269,
      "step": 3500
    },
    {
      "epoch": 0.5632672711225226,
      "grad_norm": 0.30117514729499817,
      "learning_rate": 1.872280039796848e-05,
      "loss": 1.2317,
      "step": 3510
    },
    {
      "epoch": 0.5648720211827007,
      "grad_norm": 0.33515483140945435,
      "learning_rate": 1.871431466546664e-05,
      "loss": 1.2923,
      "step": 3520
    },
    {
      "epoch": 0.5664767712428789,
      "grad_norm": 0.3113756477832794,
      "learning_rate": 1.870580277274108e-05,
      "loss": 1.286,
      "step": 3530
    },
    {
      "epoch": 0.568081521303057,
      "grad_norm": 0.42696085572242737,
      "learning_rate": 1.869726474534435e-05,
      "loss": 1.3726,
      "step": 3540
    },
    {
      "epoch": 0.5696862713632351,
      "grad_norm": 0.33821311593055725,
      "learning_rate": 1.8688700608907462e-05,
      "loss": 1.3283,
      "step": 3550
    },
    {
      "epoch": 0.5712910214234133,
      "grad_norm": 0.30294883251190186,
      "learning_rate": 1.8680110389139806e-05,
      "loss": 1.3961,
      "step": 3560
    },
    {
      "epoch": 0.5728957714835914,
      "grad_norm": 0.37252262234687805,
      "learning_rate": 1.8671494111829084e-05,
      "loss": 1.3105,
      "step": 3570
    },
    {
      "epoch": 0.5745005215437695,
      "grad_norm": 0.3752776086330414,
      "learning_rate": 1.8662851802841202e-05,
      "loss": 1.3839,
      "step": 3580
    },
    {
      "epoch": 0.5761052716039476,
      "grad_norm": 0.4236966371536255,
      "learning_rate": 1.865418348812023e-05,
      "loss": 1.2352,
      "step": 3590
    },
    {
      "epoch": 0.5777100216641258,
      "grad_norm": 0.5295116901397705,
      "learning_rate": 1.8645489193688303e-05,
      "loss": 1.5045,
      "step": 3600
    },
    {
      "epoch": 0.5793147717243039,
      "grad_norm": 0.32668522000312805,
      "learning_rate": 1.863676894564554e-05,
      "loss": 1.1554,
      "step": 3610
    },
    {
      "epoch": 0.580919521784482,
      "grad_norm": 0.3489832580089569,
      "learning_rate": 1.8628022770169975e-05,
      "loss": 1.3662,
      "step": 3620
    },
    {
      "epoch": 0.5825242718446602,
      "grad_norm": 0.4019912779331207,
      "learning_rate": 1.8619250693517478e-05,
      "loss": 1.3283,
      "step": 3630
    },
    {
      "epoch": 0.5841290219048383,
      "grad_norm": 0.6127420663833618,
      "learning_rate": 1.861045274202168e-05,
      "loss": 1.4119,
      "step": 3640
    },
    {
      "epoch": 0.5857337719650164,
      "grad_norm": 0.506712794303894,
      "learning_rate": 1.8601628942093874e-05,
      "loss": 1.3606,
      "step": 3650
    },
    {
      "epoch": 0.5873385220251945,
      "grad_norm": 0.34272444248199463,
      "learning_rate": 1.859277932022296e-05,
      "loss": 1.3022,
      "step": 3660
    },
    {
      "epoch": 0.5889432720853727,
      "grad_norm": 0.2564506530761719,
      "learning_rate": 1.858390390297535e-05,
      "loss": 1.3398,
      "step": 3670
    },
    {
      "epoch": 0.5905480221455508,
      "grad_norm": 0.3201383352279663,
      "learning_rate": 1.8575002716994894e-05,
      "loss": 1.1833,
      "step": 3680
    },
    {
      "epoch": 0.5921527722057289,
      "grad_norm": 0.26274386048316956,
      "learning_rate": 1.85660757890028e-05,
      "loss": 1.2,
      "step": 3690
    },
    {
      "epoch": 0.5937575222659071,
      "grad_norm": 0.4444594085216522,
      "learning_rate": 1.855712314579756e-05,
      "loss": 1.3535,
      "step": 3700
    },
    {
      "epoch": 0.5953622723260852,
      "grad_norm": 0.3849436640739441,
      "learning_rate": 1.8548144814254846e-05,
      "loss": 1.3507,
      "step": 3710
    },
    {
      "epoch": 0.5969670223862633,
      "grad_norm": 0.7471434473991394,
      "learning_rate": 1.8539140821327465e-05,
      "loss": 1.3687,
      "step": 3720
    },
    {
      "epoch": 0.5985717724464414,
      "grad_norm": 0.37937498092651367,
      "learning_rate": 1.8530111194045244e-05,
      "loss": 1.3297,
      "step": 3730
    },
    {
      "epoch": 0.6001765225066196,
      "grad_norm": 0.5485889315605164,
      "learning_rate": 1.852105595951497e-05,
      "loss": 1.2996,
      "step": 3740
    },
    {
      "epoch": 0.6017812725667977,
      "grad_norm": 0.344595342874527,
      "learning_rate": 1.8511975144920303e-05,
      "loss": 1.4174,
      "step": 3750
    },
    {
      "epoch": 0.6033860226269758,
      "grad_norm": 0.36519238352775574,
      "learning_rate": 1.8502868777521698e-05,
      "loss": 1.3573,
      "step": 3760
    },
    {
      "epoch": 0.604990772687154,
      "grad_norm": 0.33092305064201355,
      "learning_rate": 1.8493736884656308e-05,
      "loss": 1.1399,
      "step": 3770
    },
    {
      "epoch": 0.6065955227473321,
      "grad_norm": 0.6363629698753357,
      "learning_rate": 1.8484579493737922e-05,
      "loss": 1.5172,
      "step": 3780
    },
    {
      "epoch": 0.6082002728075102,
      "grad_norm": 0.5183701515197754,
      "learning_rate": 1.847539663225687e-05,
      "loss": 1.4047,
      "step": 3790
    },
    {
      "epoch": 0.6098050228676883,
      "grad_norm": 0.4549940824508667,
      "learning_rate": 1.8466188327779945e-05,
      "loss": 1.338,
      "step": 3800
    },
    {
      "epoch": 0.6114097729278665,
      "grad_norm": 0.4385157823562622,
      "learning_rate": 1.8456954607950323e-05,
      "loss": 1.4217,
      "step": 3810
    },
    {
      "epoch": 0.6130145229880446,
      "grad_norm": 0.3409535586833954,
      "learning_rate": 1.844769550048747e-05,
      "loss": 1.215,
      "step": 3820
    },
    {
      "epoch": 0.6146192730482227,
      "grad_norm": 0.38314902782440186,
      "learning_rate": 1.8438411033187072e-05,
      "loss": 1.347,
      "step": 3830
    },
    {
      "epoch": 0.6162240231084009,
      "grad_norm": 0.32588592171669006,
      "learning_rate": 1.8429101233920934e-05,
      "loss": 1.2749,
      "step": 3840
    },
    {
      "epoch": 0.617828773168579,
      "grad_norm": 0.3507879674434662,
      "learning_rate": 1.8419766130636922e-05,
      "loss": 1.2889,
      "step": 3850
    },
    {
      "epoch": 0.6194335232287571,
      "grad_norm": 0.4801709055900574,
      "learning_rate": 1.841040575135885e-05,
      "loss": 1.2979,
      "step": 3860
    },
    {
      "epoch": 0.6210382732889352,
      "grad_norm": 0.3517807126045227,
      "learning_rate": 1.840102012418642e-05,
      "loss": 1.3173,
      "step": 3870
    },
    {
      "epoch": 0.6226430233491134,
      "grad_norm": 0.28233009576797485,
      "learning_rate": 1.839160927729513e-05,
      "loss": 1.2639,
      "step": 3880
    },
    {
      "epoch": 0.6242477734092915,
      "grad_norm": 0.3936665654182434,
      "learning_rate": 1.838217323893617e-05,
      "loss": 1.4767,
      "step": 3890
    },
    {
      "epoch": 0.6258525234694696,
      "grad_norm": 0.42626455426216125,
      "learning_rate": 1.8372712037436377e-05,
      "loss": 1.4665,
      "step": 3900
    },
    {
      "epoch": 0.6274572735296478,
      "grad_norm": 0.36147841811180115,
      "learning_rate": 1.8363225701198105e-05,
      "loss": 1.3301,
      "step": 3910
    },
    {
      "epoch": 0.6290620235898259,
      "grad_norm": 0.48877590894699097,
      "learning_rate": 1.8353714258699185e-05,
      "loss": 1.4647,
      "step": 3920
    },
    {
      "epoch": 0.630666773650004,
      "grad_norm": 0.3290277421474457,
      "learning_rate": 1.8344177738492797e-05,
      "loss": 1.4444,
      "step": 3930
    },
    {
      "epoch": 0.6322715237101821,
      "grad_norm": 0.35547274351119995,
      "learning_rate": 1.8334616169207414e-05,
      "loss": 1.353,
      "step": 3940
    },
    {
      "epoch": 0.6338762737703603,
      "grad_norm": 0.31548550724983215,
      "learning_rate": 1.8325029579546703e-05,
      "loss": 1.3747,
      "step": 3950
    },
    {
      "epoch": 0.6354810238305384,
      "grad_norm": 0.37399932742118835,
      "learning_rate": 1.831541799828944e-05,
      "loss": 1.222,
      "step": 3960
    },
    {
      "epoch": 0.6370857738907165,
      "grad_norm": 0.696702778339386,
      "learning_rate": 1.8305781454289436e-05,
      "loss": 1.3068,
      "step": 3970
    },
    {
      "epoch": 0.6386905239508947,
      "grad_norm": 0.4077337682247162,
      "learning_rate": 1.8296119976475422e-05,
      "loss": 1.3649,
      "step": 3980
    },
    {
      "epoch": 0.6402952740110728,
      "grad_norm": 0.5040619373321533,
      "learning_rate": 1.8286433593851e-05,
      "loss": 1.3536,
      "step": 3990
    },
    {
      "epoch": 0.6419000240712509,
      "grad_norm": 0.30516791343688965,
      "learning_rate": 1.827672233549451e-05,
      "loss": 1.3191,
      "step": 4000
    },
    {
      "epoch": 0.643504774131429,
      "grad_norm": 0.4528673589229584,
      "learning_rate": 1.8266986230559e-05,
      "loss": 1.3107,
      "step": 4010
    },
    {
      "epoch": 0.6451095241916072,
      "grad_norm": 0.37125346064567566,
      "learning_rate": 1.8257225308272078e-05,
      "loss": 1.1527,
      "step": 4020
    },
    {
      "epoch": 0.6467142742517853,
      "grad_norm": 0.5220421552658081,
      "learning_rate": 1.8247439597935873e-05,
      "loss": 1.3151,
      "step": 4030
    },
    {
      "epoch": 0.6483190243119634,
      "grad_norm": 0.5411961078643799,
      "learning_rate": 1.8237629128926914e-05,
      "loss": 1.2768,
      "step": 4040
    },
    {
      "epoch": 0.6499237743721415,
      "grad_norm": 0.32979291677474976,
      "learning_rate": 1.8227793930696068e-05,
      "loss": 1.2769,
      "step": 4050
    },
    {
      "epoch": 0.6515285244323197,
      "grad_norm": 0.7464665770530701,
      "learning_rate": 1.821793403276843e-05,
      "loss": 1.3573,
      "step": 4060
    },
    {
      "epoch": 0.6531332744924978,
      "grad_norm": 0.4306504726409912,
      "learning_rate": 1.8208049464743244e-05,
      "loss": 1.2734,
      "step": 4070
    },
    {
      "epoch": 0.6547380245526759,
      "grad_norm": 0.45659545063972473,
      "learning_rate": 1.8198140256293814e-05,
      "loss": 1.2771,
      "step": 4080
    },
    {
      "epoch": 0.6563427746128541,
      "grad_norm": 0.37459665536880493,
      "learning_rate": 1.8188206437167415e-05,
      "loss": 1.3551,
      "step": 4090
    },
    {
      "epoch": 0.6579475246730322,
      "grad_norm": 0.6561301946640015,
      "learning_rate": 1.8178248037185207e-05,
      "loss": 1.4558,
      "step": 4100
    },
    {
      "epoch": 0.6595522747332103,
      "grad_norm": 0.40747231245040894,
      "learning_rate": 1.8168265086242124e-05,
      "loss": 1.2322,
      "step": 4110
    },
    {
      "epoch": 0.6611570247933884,
      "grad_norm": 0.38931646943092346,
      "learning_rate": 1.8158257614306828e-05,
      "loss": 1.3496,
      "step": 4120
    },
    {
      "epoch": 0.6627617748535666,
      "grad_norm": 0.3700779676437378,
      "learning_rate": 1.8148225651421573e-05,
      "loss": 1.2368,
      "step": 4130
    },
    {
      "epoch": 0.6643665249137447,
      "grad_norm": 0.4402172565460205,
      "learning_rate": 1.813816922770214e-05,
      "loss": 1.3536,
      "step": 4140
    },
    {
      "epoch": 0.6659712749739228,
      "grad_norm": 0.3810122311115265,
      "learning_rate": 1.8128088373337738e-05,
      "loss": 1.3272,
      "step": 4150
    },
    {
      "epoch": 0.667576025034101,
      "grad_norm": 0.4991161823272705,
      "learning_rate": 1.8117983118590927e-05,
      "loss": 1.4764,
      "step": 4160
    },
    {
      "epoch": 0.6691807750942791,
      "grad_norm": 0.5510333776473999,
      "learning_rate": 1.8107853493797502e-05,
      "loss": 1.3793,
      "step": 4170
    },
    {
      "epoch": 0.6707855251544572,
      "grad_norm": 0.421845406293869,
      "learning_rate": 1.8097699529366425e-05,
      "loss": 1.3538,
      "step": 4180
    },
    {
      "epoch": 0.6723902752146353,
      "grad_norm": 0.47272321581840515,
      "learning_rate": 1.8087521255779728e-05,
      "loss": 1.3916,
      "step": 4190
    },
    {
      "epoch": 0.6739950252748135,
      "grad_norm": 0.4718872606754303,
      "learning_rate": 1.8077318703592413e-05,
      "loss": 1.4242,
      "step": 4200
    },
    {
      "epoch": 0.6755997753349916,
      "grad_norm": 0.28562572598457336,
      "learning_rate": 1.8067091903432362e-05,
      "loss": 1.3378,
      "step": 4210
    },
    {
      "epoch": 0.6772045253951697,
      "grad_norm": 0.4194621443748474,
      "learning_rate": 1.8056840886000263e-05,
      "loss": 1.3515,
      "step": 4220
    },
    {
      "epoch": 0.6788092754553479,
      "grad_norm": 0.5180320739746094,
      "learning_rate": 1.8046565682069488e-05,
      "loss": 1.3462,
      "step": 4230
    },
    {
      "epoch": 0.680414025515526,
      "grad_norm": 0.5235304832458496,
      "learning_rate": 1.8036266322486025e-05,
      "loss": 1.2596,
      "step": 4240
    },
    {
      "epoch": 0.6820187755757041,
      "grad_norm": 0.5107454061508179,
      "learning_rate": 1.8025942838168376e-05,
      "loss": 1.2346,
      "step": 4250
    },
    {
      "epoch": 0.6836235256358822,
      "grad_norm": 0.4136069118976593,
      "learning_rate": 1.8015595260107467e-05,
      "loss": 1.3906,
      "step": 4260
    },
    {
      "epoch": 0.6852282756960604,
      "grad_norm": 0.3837946653366089,
      "learning_rate": 1.800522361936655e-05,
      "loss": 1.2655,
      "step": 4270
    },
    {
      "epoch": 0.6868330257562385,
      "grad_norm": 0.5983788371086121,
      "learning_rate": 1.7994827947081108e-05,
      "loss": 1.3558,
      "step": 4280
    },
    {
      "epoch": 0.6884377758164166,
      "grad_norm": 0.26743337512016296,
      "learning_rate": 1.798440827445878e-05,
      "loss": 1.2114,
      "step": 4290
    },
    {
      "epoch": 0.6900425258765948,
      "grad_norm": 0.38096147775650024,
      "learning_rate": 1.797396463277924e-05,
      "loss": 1.3249,
      "step": 4300
    },
    {
      "epoch": 0.6916472759367729,
      "grad_norm": 0.5418678522109985,
      "learning_rate": 1.7963497053394118e-05,
      "loss": 1.3708,
      "step": 4310
    },
    {
      "epoch": 0.693252025996951,
      "grad_norm": 0.34386369585990906,
      "learning_rate": 1.795300556772692e-05,
      "loss": 1.5,
      "step": 4320
    },
    {
      "epoch": 0.6948567760571291,
      "grad_norm": 0.44043245911598206,
      "learning_rate": 1.794249020727289e-05,
      "loss": 1.3789,
      "step": 4330
    },
    {
      "epoch": 0.6964615261173073,
      "grad_norm": 0.44178494811058044,
      "learning_rate": 1.793195100359898e-05,
      "loss": 1.2944,
      "step": 4340
    },
    {
      "epoch": 0.6980662761774854,
      "grad_norm": 0.4453251361846924,
      "learning_rate": 1.7921387988343683e-05,
      "loss": 1.235,
      "step": 4350
    },
    {
      "epoch": 0.6996710262376635,
      "grad_norm": 0.4749120771884918,
      "learning_rate": 1.7910801193217e-05,
      "loss": 1.4486,
      "step": 4360
    },
    {
      "epoch": 0.7012757762978417,
      "grad_norm": 0.43452924489974976,
      "learning_rate": 1.7900190650000305e-05,
      "loss": 1.3148,
      "step": 4370
    },
    {
      "epoch": 0.7028805263580198,
      "grad_norm": 0.3879772424697876,
      "learning_rate": 1.7889556390546267e-05,
      "loss": 1.3008,
      "step": 4380
    },
    {
      "epoch": 0.7044852764181979,
      "grad_norm": 0.4637013375759125,
      "learning_rate": 1.7878898446778757e-05,
      "loss": 1.5488,
      "step": 4390
    },
    {
      "epoch": 0.706090026478376,
      "grad_norm": 0.27585384249687195,
      "learning_rate": 1.786821685069273e-05,
      "loss": 1.2449,
      "step": 4400
    },
    {
      "epoch": 0.7076947765385542,
      "grad_norm": 0.5484049916267395,
      "learning_rate": 1.785751163435416e-05,
      "loss": 1.519,
      "step": 4410
    },
    {
      "epoch": 0.7092995265987323,
      "grad_norm": 0.28094980120658875,
      "learning_rate": 1.7846782829899928e-05,
      "loss": 1.396,
      "step": 4420
    },
    {
      "epoch": 0.7109042766589104,
      "grad_norm": 0.5125242471694946,
      "learning_rate": 1.7836030469537717e-05,
      "loss": 1.2525,
      "step": 4430
    },
    {
      "epoch": 0.7125090267190886,
      "grad_norm": 0.39358553290367126,
      "learning_rate": 1.782525458554593e-05,
      "loss": 1.5223,
      "step": 4440
    },
    {
      "epoch": 0.7141137767792667,
      "grad_norm": 0.40496373176574707,
      "learning_rate": 1.7814455210273585e-05,
      "loss": 1.2904,
      "step": 4450
    },
    {
      "epoch": 0.7157185268394447,
      "grad_norm": 0.4594113826751709,
      "learning_rate": 1.7803632376140224e-05,
      "loss": 1.3437,
      "step": 4460
    },
    {
      "epoch": 0.7173232768996228,
      "grad_norm": 0.4577178955078125,
      "learning_rate": 1.7792786115635808e-05,
      "loss": 1.3009,
      "step": 4470
    },
    {
      "epoch": 0.718928026959801,
      "grad_norm": 0.31177616119384766,
      "learning_rate": 1.778191646132063e-05,
      "loss": 1.251,
      "step": 4480
    },
    {
      "epoch": 0.7205327770199791,
      "grad_norm": 0.5064173340797424,
      "learning_rate": 1.7771023445825203e-05,
      "loss": 1.4454,
      "step": 4490
    },
    {
      "epoch": 0.7221375270801572,
      "grad_norm": 0.5016399621963501,
      "learning_rate": 1.776010710185017e-05,
      "loss": 1.4249,
      "step": 4500
    },
    {
      "epoch": 0.7237422771403353,
      "grad_norm": 0.3784669041633606,
      "learning_rate": 1.7749167462166217e-05,
      "loss": 1.3686,
      "step": 4510
    },
    {
      "epoch": 0.7253470272005135,
      "grad_norm": 0.6547024250030518,
      "learning_rate": 1.7738204559613953e-05,
      "loss": 1.3508,
      "step": 4520
    },
    {
      "epoch": 0.7269517772606916,
      "grad_norm": 0.41100314259529114,
      "learning_rate": 1.7727218427103822e-05,
      "loss": 1.4067,
      "step": 4530
    },
    {
      "epoch": 0.7285565273208697,
      "grad_norm": 0.3411480188369751,
      "learning_rate": 1.7716209097616003e-05,
      "loss": 1.3073,
      "step": 4540
    },
    {
      "epoch": 0.7301612773810479,
      "grad_norm": 0.44814205169677734,
      "learning_rate": 1.7705176604200323e-05,
      "loss": 1.3775,
      "step": 4550
    },
    {
      "epoch": 0.731766027441226,
      "grad_norm": 0.4059377610683441,
      "learning_rate": 1.7694120979976132e-05,
      "loss": 1.4588,
      "step": 4560
    },
    {
      "epoch": 0.7333707775014041,
      "grad_norm": 0.44208186864852905,
      "learning_rate": 1.7683042258132232e-05,
      "loss": 1.3924,
      "step": 4570
    },
    {
      "epoch": 0.7349755275615822,
      "grad_norm": 0.4174703359603882,
      "learning_rate": 1.7671940471926746e-05,
      "loss": 1.2993,
      "step": 4580
    },
    {
      "epoch": 0.7365802776217604,
      "grad_norm": 0.4241965413093567,
      "learning_rate": 1.7660815654687055e-05,
      "loss": 1.363,
      "step": 4590
    },
    {
      "epoch": 0.7381850276819385,
      "grad_norm": 0.43813377618789673,
      "learning_rate": 1.764966783980967e-05,
      "loss": 1.1295,
      "step": 4600
    },
    {
      "epoch": 0.7397897777421166,
      "grad_norm": 0.4926077723503113,
      "learning_rate": 1.763849706076014e-05,
      "loss": 1.3185,
      "step": 4610
    },
    {
      "epoch": 0.7413945278022948,
      "grad_norm": 0.44836950302124023,
      "learning_rate": 1.762730335107295e-05,
      "loss": 1.3133,
      "step": 4620
    },
    {
      "epoch": 0.7429992778624729,
      "grad_norm": 0.3741202652454376,
      "learning_rate": 1.7616086744351423e-05,
      "loss": 1.3731,
      "step": 4630
    },
    {
      "epoch": 0.744604027922651,
      "grad_norm": 0.5487156510353088,
      "learning_rate": 1.7604847274267628e-05,
      "loss": 1.3456,
      "step": 4640
    },
    {
      "epoch": 0.7462087779828291,
      "grad_norm": 0.4102467894554138,
      "learning_rate": 1.7593584974562258e-05,
      "loss": 1.2209,
      "step": 4650
    },
    {
      "epoch": 0.7478135280430073,
      "grad_norm": 0.319533109664917,
      "learning_rate": 1.7582299879044548e-05,
      "loss": 1.4936,
      "step": 4660
    },
    {
      "epoch": 0.7494182781031854,
      "grad_norm": 0.3102225065231323,
      "learning_rate": 1.7570992021592154e-05,
      "loss": 1.2653,
      "step": 4670
    },
    {
      "epoch": 0.7510230281633635,
      "grad_norm": 0.40316125750541687,
      "learning_rate": 1.7559661436151082e-05,
      "loss": 1.2612,
      "step": 4680
    },
    {
      "epoch": 0.7526277782235417,
      "grad_norm": 0.27865055203437805,
      "learning_rate": 1.7548308156735544e-05,
      "loss": 1.4759,
      "step": 4690
    },
    {
      "epoch": 0.7542325282837198,
      "grad_norm": 0.37750911712646484,
      "learning_rate": 1.7536932217427898e-05,
      "loss": 1.2777,
      "step": 4700
    },
    {
      "epoch": 0.7558372783438979,
      "grad_norm": 0.5535004138946533,
      "learning_rate": 1.752553365237852e-05,
      "loss": 1.438,
      "step": 4710
    },
    {
      "epoch": 0.757442028404076,
      "grad_norm": 0.4563482999801636,
      "learning_rate": 1.7514112495805703e-05,
      "loss": 1.2838,
      "step": 4720
    },
    {
      "epoch": 0.7590467784642542,
      "grad_norm": 0.3439822793006897,
      "learning_rate": 1.7502668781995566e-05,
      "loss": 1.3012,
      "step": 4730
    },
    {
      "epoch": 0.7606515285244323,
      "grad_norm": 0.4144960939884186,
      "learning_rate": 1.7491202545301944e-05,
      "loss": 1.4224,
      "step": 4740
    },
    {
      "epoch": 0.7622562785846104,
      "grad_norm": 0.41869184374809265,
      "learning_rate": 1.7479713820146282e-05,
      "loss": 1.2688,
      "step": 4750
    },
    {
      "epoch": 0.7638610286447886,
      "grad_norm": 0.5026125907897949,
      "learning_rate": 1.7468202641017538e-05,
      "loss": 1.3464,
      "step": 4760
    },
    {
      "epoch": 0.7654657787049667,
      "grad_norm": 0.5020219087600708,
      "learning_rate": 1.7456669042472072e-05,
      "loss": 1.0694,
      "step": 4770
    },
    {
      "epoch": 0.7670705287651448,
      "grad_norm": 0.2963052988052368,
      "learning_rate": 1.7445113059133554e-05,
      "loss": 1.2345,
      "step": 4780
    },
    {
      "epoch": 0.7686752788253229,
      "grad_norm": 0.44063690304756165,
      "learning_rate": 1.7433534725692843e-05,
      "loss": 1.2226,
      "step": 4790
    },
    {
      "epoch": 0.7702800288855011,
      "grad_norm": 0.4285176992416382,
      "learning_rate": 1.7421934076907905e-05,
      "loss": 1.4068,
      "step": 4800
    },
    {
      "epoch": 0.7718847789456792,
      "grad_norm": 0.37804731726646423,
      "learning_rate": 1.7410311147603682e-05,
      "loss": 1.2514,
      "step": 4810
    },
    {
      "epoch": 0.7734895290058573,
      "grad_norm": 0.4041316509246826,
      "learning_rate": 1.7398665972672014e-05,
      "loss": 1.4336,
      "step": 4820
    },
    {
      "epoch": 0.7750942790660355,
      "grad_norm": 0.3655970096588135,
      "learning_rate": 1.7386998587071518e-05,
      "loss": 1.1238,
      "step": 4830
    },
    {
      "epoch": 0.7766990291262136,
      "grad_norm": 0.4350801408290863,
      "learning_rate": 1.7375309025827482e-05,
      "loss": 1.5054,
      "step": 4840
    },
    {
      "epoch": 0.7783037791863917,
      "grad_norm": 0.49292856454849243,
      "learning_rate": 1.7363597324031772e-05,
      "loss": 1.3391,
      "step": 4850
    },
    {
      "epoch": 0.7799085292465698,
      "grad_norm": 0.37051087617874146,
      "learning_rate": 1.7351863516842717e-05,
      "loss": 1.3629,
      "step": 4860
    },
    {
      "epoch": 0.781513279306748,
      "grad_norm": 0.4974030554294586,
      "learning_rate": 1.7340107639485006e-05,
      "loss": 1.2496,
      "step": 4870
    },
    {
      "epoch": 0.7831180293669261,
      "grad_norm": 0.4464688301086426,
      "learning_rate": 1.7328329727249577e-05,
      "loss": 1.3146,
      "step": 4880
    },
    {
      "epoch": 0.7847227794271042,
      "grad_norm": 0.3693033456802368,
      "learning_rate": 1.7316529815493532e-05,
      "loss": 1.3152,
      "step": 4890
    },
    {
      "epoch": 0.7863275294872824,
      "grad_norm": 0.4830872714519501,
      "learning_rate": 1.730470793963999e-05,
      "loss": 1.3206,
      "step": 4900
    },
    {
      "epoch": 0.7879322795474605,
      "grad_norm": 0.34010177850723267,
      "learning_rate": 1.7292864135178032e-05,
      "loss": 1.4691,
      "step": 4910
    },
    {
      "epoch": 0.7895370296076386,
      "grad_norm": 0.5918980836868286,
      "learning_rate": 1.728099843766255e-05,
      "loss": 1.2618,
      "step": 4920
    },
    {
      "epoch": 0.7911417796678167,
      "grad_norm": 0.3285658359527588,
      "learning_rate": 1.7269110882714167e-05,
      "loss": 1.3736,
      "step": 4930
    },
    {
      "epoch": 0.7927465297279949,
      "grad_norm": 0.44096946716308594,
      "learning_rate": 1.7257201506019127e-05,
      "loss": 1.3606,
      "step": 4940
    },
    {
      "epoch": 0.794351279788173,
      "grad_norm": 0.584700345993042,
      "learning_rate": 1.7245270343329162e-05,
      "loss": 1.2994,
      "step": 4950
    },
    {
      "epoch": 0.7959560298483511,
      "grad_norm": 0.47238895297050476,
      "learning_rate": 1.723331743046143e-05,
      "loss": 1.3257,
      "step": 4960
    },
    {
      "epoch": 0.7975607799085292,
      "grad_norm": 0.3651365637779236,
      "learning_rate": 1.722134280329836e-05,
      "loss": 1.2081,
      "step": 4970
    },
    {
      "epoch": 0.7991655299687074,
      "grad_norm": 0.49651721119880676,
      "learning_rate": 1.7209346497787593e-05,
      "loss": 1.2263,
      "step": 4980
    },
    {
      "epoch": 0.8007702800288855,
      "grad_norm": 0.3314235806465149,
      "learning_rate": 1.7197328549941818e-05,
      "loss": 1.2219,
      "step": 4990
    },
    {
      "epoch": 0.8023750300890636,
      "grad_norm": 0.384847491979599,
      "learning_rate": 1.718528899583872e-05,
      "loss": 1.1697,
      "step": 5000
    },
    {
      "epoch": 0.8039797801492418,
      "grad_norm": 0.5230315923690796,
      "learning_rate": 1.7173227871620827e-05,
      "loss": 1.5142,
      "step": 5010
    },
    {
      "epoch": 0.8055845302094199,
      "grad_norm": 0.42152613401412964,
      "learning_rate": 1.7161145213495434e-05,
      "loss": 1.357,
      "step": 5020
    },
    {
      "epoch": 0.807189280269598,
      "grad_norm": 0.41914135217666626,
      "learning_rate": 1.7149041057734474e-05,
      "loss": 1.2972,
      "step": 5030
    },
    {
      "epoch": 0.8087940303297761,
      "grad_norm": 0.4114096164703369,
      "learning_rate": 1.713691544067441e-05,
      "loss": 1.5291,
      "step": 5040
    },
    {
      "epoch": 0.8103987803899543,
      "grad_norm": 0.7391153573989868,
      "learning_rate": 1.712476839871614e-05,
      "loss": 1.4112,
      "step": 5050
    },
    {
      "epoch": 0.8120035304501324,
      "grad_norm": 0.4324323236942291,
      "learning_rate": 1.711259996832488e-05,
      "loss": 1.3118,
      "step": 5060
    },
    {
      "epoch": 0.8136082805103105,
      "grad_norm": 0.5286919474601746,
      "learning_rate": 1.7100410186030045e-05,
      "loss": 1.4575,
      "step": 5070
    },
    {
      "epoch": 0.8152130305704887,
      "grad_norm": 0.4221147298812866,
      "learning_rate": 1.7088199088425158e-05,
      "loss": 1.3758,
      "step": 5080
    },
    {
      "epoch": 0.8168177806306668,
      "grad_norm": 0.5743736624717712,
      "learning_rate": 1.707596671216772e-05,
      "loss": 1.4401,
      "step": 5090
    },
    {
      "epoch": 0.8184225306908449,
      "grad_norm": 0.3428259789943695,
      "learning_rate": 1.7063713093979118e-05,
      "loss": 1.3772,
      "step": 5100
    },
    {
      "epoch": 0.820027280751023,
      "grad_norm": 0.40434467792510986,
      "learning_rate": 1.7051438270644504e-05,
      "loss": 1.4265,
      "step": 5110
    },
    {
      "epoch": 0.8216320308112012,
      "grad_norm": 0.3157801628112793,
      "learning_rate": 1.7039142279012693e-05,
      "loss": 1.3497,
      "step": 5120
    },
    {
      "epoch": 0.8232367808713793,
      "grad_norm": 0.3540233075618744,
      "learning_rate": 1.7026825155996035e-05,
      "loss": 1.1807,
      "step": 5130
    },
    {
      "epoch": 0.8248415309315574,
      "grad_norm": 0.44661834836006165,
      "learning_rate": 1.7014486938570324e-05,
      "loss": 1.3529,
      "step": 5140
    },
    {
      "epoch": 0.8264462809917356,
      "grad_norm": 0.4605134129524231,
      "learning_rate": 1.700212766377468e-05,
      "loss": 1.3941,
      "step": 5150
    },
    {
      "epoch": 0.8280510310519137,
      "grad_norm": 0.44499823451042175,
      "learning_rate": 1.6989747368711432e-05,
      "loss": 1.3659,
      "step": 5160
    },
    {
      "epoch": 0.8296557811120918,
      "grad_norm": 0.7105720043182373,
      "learning_rate": 1.697734609054602e-05,
      "loss": 1.3627,
      "step": 5170
    },
    {
      "epoch": 0.83126053117227,
      "grad_norm": 0.3888545036315918,
      "learning_rate": 1.6964923866506865e-05,
      "loss": 1.3088,
      "step": 5180
    },
    {
      "epoch": 0.8328652812324481,
      "grad_norm": 0.4209115207195282,
      "learning_rate": 1.695248073388527e-05,
      "loss": 1.2464,
      "step": 5190
    },
    {
      "epoch": 0.8344700312926262,
      "grad_norm": 0.48704811930656433,
      "learning_rate": 1.6940016730035306e-05,
      "loss": 1.3356,
      "step": 5200
    },
    {
      "epoch": 0.8360747813528043,
      "grad_norm": 0.5031517148017883,
      "learning_rate": 1.69275318923737e-05,
      "loss": 1.3395,
      "step": 5210
    },
    {
      "epoch": 0.8376795314129825,
      "grad_norm": 0.43179312348365784,
      "learning_rate": 1.691502625837973e-05,
      "loss": 1.3407,
      "step": 5220
    },
    {
      "epoch": 0.8392842814731606,
      "grad_norm": 0.2716063857078552,
      "learning_rate": 1.690249986559508e-05,
      "loss": 1.3156,
      "step": 5230
    },
    {
      "epoch": 0.8408890315333387,
      "grad_norm": 0.42406779527664185,
      "learning_rate": 1.688995275162378e-05,
      "loss": 1.3187,
      "step": 5240
    },
    {
      "epoch": 0.8424937815935168,
      "grad_norm": 0.3839367926120758,
      "learning_rate": 1.6877384954132052e-05,
      "loss": 1.1937,
      "step": 5250
    },
    {
      "epoch": 0.844098531653695,
      "grad_norm": 0.49437153339385986,
      "learning_rate": 1.6864796510848197e-05,
      "loss": 1.2126,
      "step": 5260
    },
    {
      "epoch": 0.8457032817138731,
      "grad_norm": 0.287202924489975,
      "learning_rate": 1.685218745956252e-05,
      "loss": 1.3967,
      "step": 5270
    },
    {
      "epoch": 0.8473080317740512,
      "grad_norm": 0.3923187851905823,
      "learning_rate": 1.683955783812717e-05,
      "loss": 1.1879,
      "step": 5280
    },
    {
      "epoch": 0.8489127818342294,
      "grad_norm": 0.443006306886673,
      "learning_rate": 1.6826907684456055e-05,
      "loss": 1.447,
      "step": 5290
    },
    {
      "epoch": 0.8505175318944075,
      "grad_norm": 0.3437308371067047,
      "learning_rate": 1.6814237036524725e-05,
      "loss": 1.3741,
      "step": 5300
    },
    {
      "epoch": 0.8521222819545856,
      "grad_norm": 0.4169386327266693,
      "learning_rate": 1.6801545932370244e-05,
      "loss": 1.3657,
      "step": 5310
    },
    {
      "epoch": 0.8537270320147637,
      "grad_norm": 0.3671761453151703,
      "learning_rate": 1.6788834410091094e-05,
      "loss": 1.2365,
      "step": 5320
    },
    {
      "epoch": 0.8553317820749419,
      "grad_norm": 0.42742592096328735,
      "learning_rate": 1.677610250784704e-05,
      "loss": 1.3898,
      "step": 5330
    },
    {
      "epoch": 0.85693653213512,
      "grad_norm": 0.39841219782829285,
      "learning_rate": 1.6763350263859043e-05,
      "loss": 1.39,
      "step": 5340
    },
    {
      "epoch": 0.8585412821952981,
      "grad_norm": 0.6718493700027466,
      "learning_rate": 1.6750577716409115e-05,
      "loss": 1.3272,
      "step": 5350
    },
    {
      "epoch": 0.8601460322554763,
      "grad_norm": 0.43465569615364075,
      "learning_rate": 1.673778490384023e-05,
      "loss": 1.519,
      "step": 5360
    },
    {
      "epoch": 0.8617507823156544,
      "grad_norm": 0.526240348815918,
      "learning_rate": 1.6724971864556193e-05,
      "loss": 1.2687,
      "step": 5370
    },
    {
      "epoch": 0.8633555323758325,
      "grad_norm": 0.45785650610923767,
      "learning_rate": 1.6712138637021526e-05,
      "loss": 1.3477,
      "step": 5380
    },
    {
      "epoch": 0.8649602824360106,
      "grad_norm": 0.389891117811203,
      "learning_rate": 1.669928525976136e-05,
      "loss": 1.2942,
      "step": 5390
    },
    {
      "epoch": 0.8665650324961888,
      "grad_norm": 0.3290356993675232,
      "learning_rate": 1.6686411771361314e-05,
      "loss": 1.2516,
      "step": 5400
    },
    {
      "epoch": 0.8681697825563669,
      "grad_norm": 0.4714694023132324,
      "learning_rate": 1.667351821046738e-05,
      "loss": 1.3926,
      "step": 5410
    },
    {
      "epoch": 0.869774532616545,
      "grad_norm": 0.41370436549186707,
      "learning_rate": 1.666060461578581e-05,
      "loss": 1.1895,
      "step": 5420
    },
    {
      "epoch": 0.8713792826767232,
      "grad_norm": 0.3037577271461487,
      "learning_rate": 1.664767102608299e-05,
      "loss": 1.4118,
      "step": 5430
    },
    {
      "epoch": 0.8729840327369013,
      "grad_norm": 0.4214405417442322,
      "learning_rate": 1.6634717480185338e-05,
      "loss": 1.455,
      "step": 5440
    },
    {
      "epoch": 0.8745887827970793,
      "grad_norm": 0.5915951132774353,
      "learning_rate": 1.6621744016979176e-05,
      "loss": 1.4248,
      "step": 5450
    },
    {
      "epoch": 0.8761935328572574,
      "grad_norm": 0.45366013050079346,
      "learning_rate": 1.6608750675410624e-05,
      "loss": 1.3524,
      "step": 5460
    },
    {
      "epoch": 0.8777982829174356,
      "grad_norm": 0.3286932408809662,
      "learning_rate": 1.6595737494485463e-05,
      "loss": 1.2665,
      "step": 5470
    },
    {
      "epoch": 0.8794030329776137,
      "grad_norm": 0.39342668652534485,
      "learning_rate": 1.6582704513269048e-05,
      "loss": 1.2325,
      "step": 5480
    },
    {
      "epoch": 0.8810077830377918,
      "grad_norm": 0.5058841109275818,
      "learning_rate": 1.656965177088616e-05,
      "loss": 1.2939,
      "step": 5490
    },
    {
      "epoch": 0.8826125330979699,
      "grad_norm": 0.37228599190711975,
      "learning_rate": 1.655657930652091e-05,
      "loss": 1.2751,
      "step": 5500
    },
    {
      "epoch": 0.8842172831581481,
      "grad_norm": 0.32073843479156494,
      "learning_rate": 1.6543487159416615e-05,
      "loss": 1.308,
      "step": 5510
    },
    {
      "epoch": 0.8858220332183262,
      "grad_norm": 0.40155431628227234,
      "learning_rate": 1.6530375368875674e-05,
      "loss": 1.3307,
      "step": 5520
    },
    {
      "epoch": 0.8874267832785043,
      "grad_norm": 0.5695632100105286,
      "learning_rate": 1.6517243974259457e-05,
      "loss": 1.393,
      "step": 5530
    },
    {
      "epoch": 0.8890315333386825,
      "grad_norm": 0.48095759749412537,
      "learning_rate": 1.650409301498819e-05,
      "loss": 1.3773,
      "step": 5540
    },
    {
      "epoch": 0.8906362833988606,
      "grad_norm": 0.46708589792251587,
      "learning_rate": 1.649092253054083e-05,
      "loss": 1.4356,
      "step": 5550
    },
    {
      "epoch": 0.8922410334590387,
      "grad_norm": 0.29170000553131104,
      "learning_rate": 1.647773256045494e-05,
      "loss": 1.3835,
      "step": 5560
    },
    {
      "epoch": 0.8938457835192168,
      "grad_norm": 0.36648043990135193,
      "learning_rate": 1.646452314432659e-05,
      "loss": 1.2114,
      "step": 5570
    },
    {
      "epoch": 0.895450533579395,
      "grad_norm": 0.343148797750473,
      "learning_rate": 1.6451294321810215e-05,
      "loss": 1.2981,
      "step": 5580
    },
    {
      "epoch": 0.8970552836395731,
      "grad_norm": 0.4367126226425171,
      "learning_rate": 1.6438046132618522e-05,
      "loss": 1.1562,
      "step": 5590
    },
    {
      "epoch": 0.8986600336997512,
      "grad_norm": 0.4520427882671356,
      "learning_rate": 1.6424778616522345e-05,
      "loss": 1.4461,
      "step": 5600
    },
    {
      "epoch": 0.9002647837599294,
      "grad_norm": 0.49677371978759766,
      "learning_rate": 1.641149181335054e-05,
      "loss": 1.4926,
      "step": 5610
    },
    {
      "epoch": 0.9018695338201075,
      "grad_norm": 0.6070894002914429,
      "learning_rate": 1.639818576298986e-05,
      "loss": 1.3126,
      "step": 5620
    },
    {
      "epoch": 0.9034742838802856,
      "grad_norm": 0.3122079074382782,
      "learning_rate": 1.638486050538485e-05,
      "loss": 1.2197,
      "step": 5630
    },
    {
      "epoch": 0.9050790339404637,
      "grad_norm": 0.4353470504283905,
      "learning_rate": 1.6371516080537696e-05,
      "loss": 1.3893,
      "step": 5640
    },
    {
      "epoch": 0.9066837840006419,
      "grad_norm": 0.3354873061180115,
      "learning_rate": 1.635815252850814e-05,
      "loss": 1.4285,
      "step": 5650
    },
    {
      "epoch": 0.90828853406082,
      "grad_norm": 0.3952888250350952,
      "learning_rate": 1.634476988941333e-05,
      "loss": 1.1802,
      "step": 5660
    },
    {
      "epoch": 0.9098932841209981,
      "grad_norm": 0.4878421425819397,
      "learning_rate": 1.6331368203427732e-05,
      "loss": 1.239,
      "step": 5670
    },
    {
      "epoch": 0.9114980341811763,
      "grad_norm": 0.48459434509277344,
      "learning_rate": 1.6317947510782968e-05,
      "loss": 1.3353,
      "step": 5680
    },
    {
      "epoch": 0.9131027842413544,
      "grad_norm": 0.5296024680137634,
      "learning_rate": 1.6304507851767728e-05,
      "loss": 1.3325,
      "step": 5690
    },
    {
      "epoch": 0.9147075343015325,
      "grad_norm": 0.45877718925476074,
      "learning_rate": 1.6291049266727644e-05,
      "loss": 1.3223,
      "step": 5700
    },
    {
      "epoch": 0.9163122843617106,
      "grad_norm": 0.36395880579948425,
      "learning_rate": 1.627757179606515e-05,
      "loss": 1.3718,
      "step": 5710
    },
    {
      "epoch": 0.9179170344218888,
      "grad_norm": 0.6373873949050903,
      "learning_rate": 1.6264075480239394e-05,
      "loss": 1.3696,
      "step": 5720
    },
    {
      "epoch": 0.9195217844820669,
      "grad_norm": 0.5325868129730225,
      "learning_rate": 1.6250560359766078e-05,
      "loss": 1.4063,
      "step": 5730
    },
    {
      "epoch": 0.921126534542245,
      "grad_norm": 0.47153016924858093,
      "learning_rate": 1.6237026475217364e-05,
      "loss": 1.3867,
      "step": 5740
    },
    {
      "epoch": 0.9227312846024232,
      "grad_norm": 0.41277918219566345,
      "learning_rate": 1.6223473867221745e-05,
      "loss": 1.446,
      "step": 5750
    },
    {
      "epoch": 0.9243360346626013,
      "grad_norm": 0.5519567728042603,
      "learning_rate": 1.6209902576463913e-05,
      "loss": 1.3142,
      "step": 5760
    },
    {
      "epoch": 0.9259407847227794,
      "grad_norm": 0.6120237112045288,
      "learning_rate": 1.619631264368466e-05,
      "loss": 1.1825,
      "step": 5770
    },
    {
      "epoch": 0.9275455347829575,
      "grad_norm": 0.6467441916465759,
      "learning_rate": 1.6182704109680722e-05,
      "loss": 1.3095,
      "step": 5780
    },
    {
      "epoch": 0.9291502848431357,
      "grad_norm": 0.45790350437164307,
      "learning_rate": 1.6169077015304687e-05,
      "loss": 1.2986,
      "step": 5790
    },
    {
      "epoch": 0.9307550349033138,
      "grad_norm": 0.4265598952770233,
      "learning_rate": 1.6155431401464868e-05,
      "loss": 1.2973,
      "step": 5800
    },
    {
      "epoch": 0.9323597849634919,
      "grad_norm": 0.38908231258392334,
      "learning_rate": 1.6141767309125157e-05,
      "loss": 1.2323,
      "step": 5810
    },
    {
      "epoch": 0.93396453502367,
      "grad_norm": 0.8979561924934387,
      "learning_rate": 1.6128084779304923e-05,
      "loss": 1.282,
      "step": 5820
    },
    {
      "epoch": 0.9355692850838482,
      "grad_norm": 0.5202555060386658,
      "learning_rate": 1.61143838530789e-05,
      "loss": 1.4424,
      "step": 5830
    },
    {
      "epoch": 0.9371740351440263,
      "grad_norm": 0.666973888874054,
      "learning_rate": 1.6100664571577018e-05,
      "loss": 1.3073,
      "step": 5840
    },
    {
      "epoch": 0.9387787852042044,
      "grad_norm": 0.825140118598938,
      "learning_rate": 1.608692697598434e-05,
      "loss": 1.3351,
      "step": 5850
    },
    {
      "epoch": 0.9403835352643826,
      "grad_norm": 0.4914003610610962,
      "learning_rate": 1.6073171107540883e-05,
      "loss": 1.2839,
      "step": 5860
    },
    {
      "epoch": 0.9419882853245607,
      "grad_norm": 0.40694382786750793,
      "learning_rate": 1.6059397007541533e-05,
      "loss": 1.3518,
      "step": 5870
    },
    {
      "epoch": 0.9435930353847388,
      "grad_norm": 0.621853232383728,
      "learning_rate": 1.60456047173359e-05,
      "loss": 1.3419,
      "step": 5880
    },
    {
      "epoch": 0.945197785444917,
      "grad_norm": 0.40042200684547424,
      "learning_rate": 1.603179427832821e-05,
      "loss": 1.4809,
      "step": 5890
    },
    {
      "epoch": 0.9468025355050951,
      "grad_norm": 0.5344259142875671,
      "learning_rate": 1.6017965731977158e-05,
      "loss": 1.3183,
      "step": 5900
    },
    {
      "epoch": 0.9484072855652732,
      "grad_norm": 0.816536545753479,
      "learning_rate": 1.600411911979581e-05,
      "loss": 1.3356,
      "step": 5910
    },
    {
      "epoch": 0.9500120356254513,
      "grad_norm": 0.48372316360473633,
      "learning_rate": 1.5990254483351453e-05,
      "loss": 1.3854,
      "step": 5920
    },
    {
      "epoch": 0.9516167856856295,
      "grad_norm": 0.49060237407684326,
      "learning_rate": 1.5976371864265493e-05,
      "loss": 1.4454,
      "step": 5930
    },
    {
      "epoch": 0.9532215357458076,
      "grad_norm": 0.4114634394645691,
      "learning_rate": 1.5962471304213315e-05,
      "loss": 1.2264,
      "step": 5940
    },
    {
      "epoch": 0.9548262858059857,
      "grad_norm": 0.4883602559566498,
      "learning_rate": 1.5948552844924158e-05,
      "loss": 1.2849,
      "step": 5950
    },
    {
      "epoch": 0.9564310358661638,
      "grad_norm": 0.393923819065094,
      "learning_rate": 1.593461652818101e-05,
      "loss": 1.2245,
      "step": 5960
    },
    {
      "epoch": 0.958035785926342,
      "grad_norm": 0.4913346767425537,
      "learning_rate": 1.5920662395820442e-05,
      "loss": 1.0894,
      "step": 5970
    },
    {
      "epoch": 0.9596405359865201,
      "grad_norm": 0.3558640778064728,
      "learning_rate": 1.590669048973253e-05,
      "loss": 1.3691,
      "step": 5980
    },
    {
      "epoch": 0.9612452860466982,
      "grad_norm": 0.39837709069252014,
      "learning_rate": 1.5892700851860694e-05,
      "loss": 1.2236,
      "step": 5990
    },
    {
      "epoch": 0.9628500361068764,
      "grad_norm": 0.40076902508735657,
      "learning_rate": 1.5878693524201588e-05,
      "loss": 1.2526,
      "step": 6000
    },
    {
      "epoch": 0.9644547861670545,
      "grad_norm": 0.4735957384109497,
      "learning_rate": 1.5864668548804972e-05,
      "loss": 1.4731,
      "step": 6010
    },
    {
      "epoch": 0.9660595362272326,
      "grad_norm": 0.473957359790802,
      "learning_rate": 1.585062596777358e-05,
      "loss": 1.5207,
      "step": 6020
    },
    {
      "epoch": 0.9676642862874107,
      "grad_norm": 0.4437260925769806,
      "learning_rate": 1.5836565823263e-05,
      "loss": 1.2809,
      "step": 6030
    },
    {
      "epoch": 0.9692690363475889,
      "grad_norm": 0.3869938552379608,
      "learning_rate": 1.582248815748155e-05,
      "loss": 1.4852,
      "step": 6040
    },
    {
      "epoch": 0.970873786407767,
      "grad_norm": 0.35249489545822144,
      "learning_rate": 1.5808393012690143e-05,
      "loss": 1.2395,
      "step": 6050
    },
    {
      "epoch": 0.9724785364679451,
      "grad_norm": 0.5415266752243042,
      "learning_rate": 1.5794280431202153e-05,
      "loss": 1.2244,
      "step": 6060
    },
    {
      "epoch": 0.9740832865281233,
      "grad_norm": 0.450879842042923,
      "learning_rate": 1.5780150455383315e-05,
      "loss": 1.2263,
      "step": 6070
    },
    {
      "epoch": 0.9756880365883014,
      "grad_norm": 0.37794679403305054,
      "learning_rate": 1.5766003127651578e-05,
      "loss": 1.4547,
      "step": 6080
    },
    {
      "epoch": 0.9772927866484795,
      "grad_norm": 0.42578089237213135,
      "learning_rate": 1.5751838490476977e-05,
      "loss": 1.2277,
      "step": 6090
    },
    {
      "epoch": 0.9788975367086576,
      "grad_norm": 0.3842075765132904,
      "learning_rate": 1.5737656586381502e-05,
      "loss": 1.2639,
      "step": 6100
    },
    {
      "epoch": 0.9805022867688358,
      "grad_norm": 0.8705730438232422,
      "learning_rate": 1.5723457457938997e-05,
      "loss": 1.4355,
      "step": 6110
    },
    {
      "epoch": 0.9821070368290139,
      "grad_norm": 0.3839168846607208,
      "learning_rate": 1.5709241147775e-05,
      "loss": 1.2519,
      "step": 6120
    },
    {
      "epoch": 0.983711786889192,
      "grad_norm": 0.6457141637802124,
      "learning_rate": 1.5695007698566625e-05,
      "loss": 1.3103,
      "step": 6130
    },
    {
      "epoch": 0.9853165369493702,
      "grad_norm": 0.44989705085754395,
      "learning_rate": 1.5680757153042455e-05,
      "loss": 1.2612,
      "step": 6140
    },
    {
      "epoch": 0.9869212870095483,
      "grad_norm": 0.3752959072589874,
      "learning_rate": 1.5666489553982376e-05,
      "loss": 1.2201,
      "step": 6150
    },
    {
      "epoch": 0.9885260370697264,
      "grad_norm": 0.3515862226486206,
      "learning_rate": 1.565220494421748e-05,
      "loss": 1.2803,
      "step": 6160
    },
    {
      "epoch": 0.9901307871299045,
      "grad_norm": 0.3068527579307556,
      "learning_rate": 1.563790336662992e-05,
      "loss": 1.1936,
      "step": 6170
    },
    {
      "epoch": 0.9917355371900827,
      "grad_norm": 0.4431750178337097,
      "learning_rate": 1.5623584864152784e-05,
      "loss": 1.2306,
      "step": 6180
    },
    {
      "epoch": 0.9933402872502608,
      "grad_norm": 0.6194785833358765,
      "learning_rate": 1.560924947976998e-05,
      "loss": 1.3348,
      "step": 6190
    },
    {
      "epoch": 0.9949450373104389,
      "grad_norm": 0.5039888620376587,
      "learning_rate": 1.5594897256516075e-05,
      "loss": 1.3855,
      "step": 6200
    },
    {
      "epoch": 0.9965497873706171,
      "grad_norm": 0.6017631888389587,
      "learning_rate": 1.5580528237476208e-05,
      "loss": 1.2783,
      "step": 6210
    },
    {
      "epoch": 0.9981545374307952,
      "grad_norm": 0.574985146522522,
      "learning_rate": 1.556614246578593e-05,
      "loss": 1.2288,
      "step": 6220
    },
    {
      "epoch": 0.9997592874909733,
      "grad_norm": 0.4361003637313843,
      "learning_rate": 1.5551739984631073e-05,
      "loss": 1.3075,
      "step": 6230
    },
    {
      "epoch": 1.0012838000481425,
      "grad_norm": 0.3601723909378052,
      "learning_rate": 1.5537320837247646e-05,
      "loss": 1.2991,
      "step": 6240
    },
    {
      "epoch": 1.0028885501083207,
      "grad_norm": 0.4324955940246582,
      "learning_rate": 1.5522885066921684e-05,
      "loss": 1.3122,
      "step": 6250
    },
    {
      "epoch": 1.0044933001684988,
      "grad_norm": 0.33751097321510315,
      "learning_rate": 1.5508432716989117e-05,
      "loss": 1.4255,
      "step": 6260
    },
    {
      "epoch": 1.006098050228677,
      "grad_norm": 0.4428054690361023,
      "learning_rate": 1.5493963830835658e-05,
      "loss": 1.3473,
      "step": 6270
    },
    {
      "epoch": 1.007702800288855,
      "grad_norm": 0.5338355302810669,
      "learning_rate": 1.5479478451896648e-05,
      "loss": 1.3517,
      "step": 6280
    },
    {
      "epoch": 1.0093075503490332,
      "grad_norm": 0.425942987203598,
      "learning_rate": 1.546497662365696e-05,
      "loss": 1.3183,
      "step": 6290
    },
    {
      "epoch": 1.0109123004092113,
      "grad_norm": 0.5304164290428162,
      "learning_rate": 1.545045838965082e-05,
      "loss": 1.3874,
      "step": 6300
    },
    {
      "epoch": 1.0125170504693894,
      "grad_norm": 0.4224250316619873,
      "learning_rate": 1.543592379346173e-05,
      "loss": 1.2632,
      "step": 6310
    },
    {
      "epoch": 1.0141218005295676,
      "grad_norm": 0.3829323947429657,
      "learning_rate": 1.542137287872229e-05,
      "loss": 1.2622,
      "step": 6320
    },
    {
      "epoch": 1.0157265505897457,
      "grad_norm": 0.35731014609336853,
      "learning_rate": 1.5406805689114107e-05,
      "loss": 1.3027,
      "step": 6330
    },
    {
      "epoch": 1.0173313006499238,
      "grad_norm": 0.4790075421333313,
      "learning_rate": 1.539222226836763e-05,
      "loss": 1.4207,
      "step": 6340
    },
    {
      "epoch": 1.018936050710102,
      "grad_norm": 0.6849955916404724,
      "learning_rate": 1.537762266026204e-05,
      "loss": 1.3475,
      "step": 6350
    },
    {
      "epoch": 1.02054080077028,
      "grad_norm": 0.31947189569473267,
      "learning_rate": 1.536300690862511e-05,
      "loss": 1.3133,
      "step": 6360
    },
    {
      "epoch": 1.0221455508304582,
      "grad_norm": 0.41740599274635315,
      "learning_rate": 1.5348375057333077e-05,
      "loss": 1.2148,
      "step": 6370
    },
    {
      "epoch": 1.0237503008906363,
      "grad_norm": 0.7626890540122986,
      "learning_rate": 1.533372715031051e-05,
      "loss": 1.2917,
      "step": 6380
    },
    {
      "epoch": 1.0253550509508145,
      "grad_norm": 0.4480336904525757,
      "learning_rate": 1.531906323153017e-05,
      "loss": 1.227,
      "step": 6390
    },
    {
      "epoch": 1.0269598010109926,
      "grad_norm": 0.4390794336795807,
      "learning_rate": 1.53043833450129e-05,
      "loss": 1.2819,
      "step": 6400
    },
    {
      "epoch": 1.0285645510711707,
      "grad_norm": 0.3649744689464569,
      "learning_rate": 1.5289687534827463e-05,
      "loss": 1.2173,
      "step": 6410
    },
    {
      "epoch": 1.0301693011313489,
      "grad_norm": 0.5818130970001221,
      "learning_rate": 1.5274975845090433e-05,
      "loss": 1.4234,
      "step": 6420
    },
    {
      "epoch": 1.031774051191527,
      "grad_norm": 0.4034980535507202,
      "learning_rate": 1.5260248319966047e-05,
      "loss": 1.3347,
      "step": 6430
    },
    {
      "epoch": 1.0333788012517051,
      "grad_norm": 0.48886194825172424,
      "learning_rate": 1.5245505003666083e-05,
      "loss": 1.3065,
      "step": 6440
    },
    {
      "epoch": 1.0349835513118832,
      "grad_norm": 0.37109822034835815,
      "learning_rate": 1.5230745940449729e-05,
      "loss": 1.2236,
      "step": 6450
    },
    {
      "epoch": 1.0365883013720614,
      "grad_norm": 0.3626192808151245,
      "learning_rate": 1.5215971174623439e-05,
      "loss": 1.2796,
      "step": 6460
    },
    {
      "epoch": 1.0381930514322395,
      "grad_norm": 0.5692756175994873,
      "learning_rate": 1.5201180750540807e-05,
      "loss": 1.3854,
      "step": 6470
    },
    {
      "epoch": 1.0397978014924176,
      "grad_norm": 0.3761465847492218,
      "learning_rate": 1.5186374712602433e-05,
      "loss": 1.3716,
      "step": 6480
    },
    {
      "epoch": 1.0414025515525958,
      "grad_norm": 0.48764920234680176,
      "learning_rate": 1.5171553105255794e-05,
      "loss": 1.3049,
      "step": 6490
    },
    {
      "epoch": 1.0430073016127739,
      "grad_norm": 0.5362102389335632,
      "learning_rate": 1.5156715972995096e-05,
      "loss": 1.3683,
      "step": 6500
    },
    {
      "epoch": 1.044612051672952,
      "grad_norm": 0.4372890889644623,
      "learning_rate": 1.514186336036116e-05,
      "loss": 1.3398,
      "step": 6510
    },
    {
      "epoch": 1.0462168017331301,
      "grad_norm": 0.645440936088562,
      "learning_rate": 1.5126995311941274e-05,
      "loss": 1.243,
      "step": 6520
    },
    {
      "epoch": 1.0478215517933083,
      "grad_norm": 0.45468226075172424,
      "learning_rate": 1.5112111872369067e-05,
      "loss": 1.4602,
      "step": 6530
    },
    {
      "epoch": 1.0494263018534864,
      "grad_norm": 0.459573358297348,
      "learning_rate": 1.5097213086324367e-05,
      "loss": 1.2885,
      "step": 6540
    },
    {
      "epoch": 1.0510310519136645,
      "grad_norm": 0.4216645061969757,
      "learning_rate": 1.508229899853308e-05,
      "loss": 1.1765,
      "step": 6550
    },
    {
      "epoch": 1.0526358019738427,
      "grad_norm": 0.4805035889148712,
      "learning_rate": 1.5067369653767036e-05,
      "loss": 1.2619,
      "step": 6560
    },
    {
      "epoch": 1.0542405520340208,
      "grad_norm": 0.42158639430999756,
      "learning_rate": 1.505242509684388e-05,
      "loss": 1.3451,
      "step": 6570
    },
    {
      "epoch": 1.055845302094199,
      "grad_norm": 0.4415193200111389,
      "learning_rate": 1.5037465372626914e-05,
      "loss": 1.2924,
      "step": 6580
    },
    {
      "epoch": 1.057450052154377,
      "grad_norm": 0.4799317419528961,
      "learning_rate": 1.5022490526024973e-05,
      "loss": 1.3174,
      "step": 6590
    },
    {
      "epoch": 1.0590548022145552,
      "grad_norm": 0.4865780770778656,
      "learning_rate": 1.5007500601992294e-05,
      "loss": 1.3613,
      "step": 6600
    },
    {
      "epoch": 1.0606595522747333,
      "grad_norm": 0.5198495984077454,
      "learning_rate": 1.4992495645528365e-05,
      "loss": 1.2907,
      "step": 6610
    },
    {
      "epoch": 1.0622643023349114,
      "grad_norm": 0.5259076952934265,
      "learning_rate": 1.4977475701677818e-05,
      "loss": 1.3438,
      "step": 6620
    },
    {
      "epoch": 1.0638690523950896,
      "grad_norm": 0.391799658536911,
      "learning_rate": 1.4962440815530261e-05,
      "loss": 1.2975,
      "step": 6630
    },
    {
      "epoch": 1.0654738024552677,
      "grad_norm": 0.3793030381202698,
      "learning_rate": 1.4947391032220173e-05,
      "loss": 1.2415,
      "step": 6640
    },
    {
      "epoch": 1.0670785525154458,
      "grad_norm": 0.5111414790153503,
      "learning_rate": 1.493232639692674e-05,
      "loss": 1.3922,
      "step": 6650
    },
    {
      "epoch": 1.068683302575624,
      "grad_norm": 0.5521757006645203,
      "learning_rate": 1.4917246954873739e-05,
      "loss": 1.4384,
      "step": 6660
    },
    {
      "epoch": 1.070288052635802,
      "grad_norm": 0.6244081258773804,
      "learning_rate": 1.4902152751329401e-05,
      "loss": 1.3634,
      "step": 6670
    },
    {
      "epoch": 1.0718928026959802,
      "grad_norm": 0.484292596578598,
      "learning_rate": 1.4887043831606267e-05,
      "loss": 1.1858,
      "step": 6680
    },
    {
      "epoch": 1.0734975527561583,
      "grad_norm": 0.36072757840156555,
      "learning_rate": 1.4871920241061056e-05,
      "loss": 1.3018,
      "step": 6690
    },
    {
      "epoch": 1.0751023028163365,
      "grad_norm": 0.4387272894382477,
      "learning_rate": 1.4856782025094527e-05,
      "loss": 1.2818,
      "step": 6700
    },
    {
      "epoch": 1.0767070528765146,
      "grad_norm": 0.38968297839164734,
      "learning_rate": 1.4841629229151345e-05,
      "loss": 1.2832,
      "step": 6710
    },
    {
      "epoch": 1.0783118029366927,
      "grad_norm": 0.6619718074798584,
      "learning_rate": 1.4826461898719944e-05,
      "loss": 1.3435,
      "step": 6720
    },
    {
      "epoch": 1.0799165529968708,
      "grad_norm": 0.5053989887237549,
      "learning_rate": 1.4811280079332393e-05,
      "loss": 1.2909,
      "step": 6730
    },
    {
      "epoch": 1.081521303057049,
      "grad_norm": 0.4098435044288635,
      "learning_rate": 1.4796083816564255e-05,
      "loss": 1.2031,
      "step": 6740
    },
    {
      "epoch": 1.083126053117227,
      "grad_norm": 0.4420308768749237,
      "learning_rate": 1.4780873156034447e-05,
      "loss": 1.4824,
      "step": 6750
    },
    {
      "epoch": 1.0847308031774052,
      "grad_norm": 0.3314979374408722,
      "learning_rate": 1.4765648143405118e-05,
      "loss": 1.3183,
      "step": 6760
    },
    {
      "epoch": 1.0863355532375834,
      "grad_norm": 0.3510865569114685,
      "learning_rate": 1.4750408824381491e-05,
      "loss": 1.2142,
      "step": 6770
    },
    {
      "epoch": 1.0879403032977613,
      "grad_norm": 0.7053998112678528,
      "learning_rate": 1.4735155244711741e-05,
      "loss": 1.315,
      "step": 6780
    },
    {
      "epoch": 1.0895450533579396,
      "grad_norm": 0.5080541968345642,
      "learning_rate": 1.4719887450186858e-05,
      "loss": 1.3033,
      "step": 6790
    },
    {
      "epoch": 1.0911498034181175,
      "grad_norm": 0.47557002305984497,
      "learning_rate": 1.4704605486640495e-05,
      "loss": 1.2938,
      "step": 6800
    },
    {
      "epoch": 1.0927545534782959,
      "grad_norm": 0.4491935968399048,
      "learning_rate": 1.468930939994885e-05,
      "loss": 1.3345,
      "step": 6810
    },
    {
      "epoch": 1.0943593035384738,
      "grad_norm": 0.44362714886665344,
      "learning_rate": 1.4673999236030514e-05,
      "loss": 1.1347,
      "step": 6820
    },
    {
      "epoch": 1.0959640535986521,
      "grad_norm": 0.4518422782421112,
      "learning_rate": 1.4658675040846333e-05,
      "loss": 1.3781,
      "step": 6830
    },
    {
      "epoch": 1.09756880365883,
      "grad_norm": 0.41093572974205017,
      "learning_rate": 1.4643336860399282e-05,
      "loss": 1.3406,
      "step": 6840
    },
    {
      "epoch": 1.0991735537190084,
      "grad_norm": 0.6091871857643127,
      "learning_rate": 1.4627984740734316e-05,
      "loss": 1.3216,
      "step": 6850
    },
    {
      "epoch": 1.1007783037791863,
      "grad_norm": 0.7222230434417725,
      "learning_rate": 1.4612618727938235e-05,
      "loss": 1.3419,
      "step": 6860
    },
    {
      "epoch": 1.1023830538393646,
      "grad_norm": 0.5202787518501282,
      "learning_rate": 1.459723886813955e-05,
      "loss": 1.2601,
      "step": 6870
    },
    {
      "epoch": 1.1039878038995425,
      "grad_norm": 0.3911527395248413,
      "learning_rate": 1.4581845207508333e-05,
      "loss": 1.2106,
      "step": 6880
    },
    {
      "epoch": 1.1055925539597207,
      "grad_norm": 0.41159531474113464,
      "learning_rate": 1.4566437792256097e-05,
      "loss": 1.1649,
      "step": 6890
    },
    {
      "epoch": 1.1071973040198988,
      "grad_norm": 0.5409526228904724,
      "learning_rate": 1.4551016668635632e-05,
      "loss": 1.2035,
      "step": 6900
    },
    {
      "epoch": 1.108802054080077,
      "grad_norm": 0.30948135256767273,
      "learning_rate": 1.4535581882940888e-05,
      "loss": 1.2175,
      "step": 6910
    },
    {
      "epoch": 1.110406804140255,
      "grad_norm": 0.4835200607776642,
      "learning_rate": 1.4520133481506833e-05,
      "loss": 1.3498,
      "step": 6920
    },
    {
      "epoch": 1.1120115542004332,
      "grad_norm": 0.4115942716598511,
      "learning_rate": 1.45046715107093e-05,
      "loss": 1.2632,
      "step": 6930
    },
    {
      "epoch": 1.1136163042606113,
      "grad_norm": 0.8460289835929871,
      "learning_rate": 1.4489196016964865e-05,
      "loss": 1.3076,
      "step": 6940
    },
    {
      "epoch": 1.1152210543207894,
      "grad_norm": 0.2751508057117462,
      "learning_rate": 1.4473707046730692e-05,
      "loss": 1.3567,
      "step": 6950
    },
    {
      "epoch": 1.1168258043809676,
      "grad_norm": 0.6270081996917725,
      "learning_rate": 1.4458204646504406e-05,
      "loss": 1.2648,
      "step": 6960
    },
    {
      "epoch": 1.1184305544411457,
      "grad_norm": 0.339470773935318,
      "learning_rate": 1.4442688862823947e-05,
      "loss": 1.2423,
      "step": 6970
    },
    {
      "epoch": 1.1200353045013238,
      "grad_norm": 0.3658987879753113,
      "learning_rate": 1.4427159742267436e-05,
      "loss": 1.3307,
      "step": 6980
    },
    {
      "epoch": 1.121640054561502,
      "grad_norm": 0.5582230091094971,
      "learning_rate": 1.4411617331453024e-05,
      "loss": 1.2053,
      "step": 6990
    },
    {
      "epoch": 1.12324480462168,
      "grad_norm": 0.37663304805755615,
      "learning_rate": 1.4396061677038764e-05,
      "loss": 1.1812,
      "step": 7000
    },
    {
      "epoch": 1.1248495546818582,
      "grad_norm": 0.38784775137901306,
      "learning_rate": 1.4380492825722464e-05,
      "loss": 1.4165,
      "step": 7010
    },
    {
      "epoch": 1.1264543047420363,
      "grad_norm": 0.3521536588668823,
      "learning_rate": 1.436491082424155e-05,
      "loss": 1.3488,
      "step": 7020
    },
    {
      "epoch": 1.1280590548022145,
      "grad_norm": 0.3474646508693695,
      "learning_rate": 1.4349315719372925e-05,
      "loss": 1.3054,
      "step": 7030
    },
    {
      "epoch": 1.1296638048623926,
      "grad_norm": 0.3786047399044037,
      "learning_rate": 1.4333707557932825e-05,
      "loss": 1.0053,
      "step": 7040
    },
    {
      "epoch": 1.1312685549225707,
      "grad_norm": 0.4184497594833374,
      "learning_rate": 1.4318086386776688e-05,
      "loss": 1.4007,
      "step": 7050
    },
    {
      "epoch": 1.1328733049827489,
      "grad_norm": 0.43812254071235657,
      "learning_rate": 1.4302452252799e-05,
      "loss": 1.4642,
      "step": 7060
    },
    {
      "epoch": 1.134478055042927,
      "grad_norm": 0.49178361892700195,
      "learning_rate": 1.4286805202933162e-05,
      "loss": 1.3949,
      "step": 7070
    },
    {
      "epoch": 1.136082805103105,
      "grad_norm": 0.4279196560382843,
      "learning_rate": 1.4271145284151355e-05,
      "loss": 1.4526,
      "step": 7080
    },
    {
      "epoch": 1.1376875551632832,
      "grad_norm": 0.5261572599411011,
      "learning_rate": 1.4255472543464385e-05,
      "loss": 1.4703,
      "step": 7090
    },
    {
      "epoch": 1.1392923052234614,
      "grad_norm": 0.6121659874916077,
      "learning_rate": 1.4239787027921555e-05,
      "loss": 1.4138,
      "step": 7100
    },
    {
      "epoch": 1.1408970552836395,
      "grad_norm": 0.3736075460910797,
      "learning_rate": 1.4224088784610507e-05,
      "loss": 1.4209,
      "step": 7110
    },
    {
      "epoch": 1.1425018053438176,
      "grad_norm": 0.5189878344535828,
      "learning_rate": 1.4208377860657108e-05,
      "loss": 1.4667,
      "step": 7120
    },
    {
      "epoch": 1.1441065554039958,
      "grad_norm": 0.40697869658470154,
      "learning_rate": 1.4192654303225277e-05,
      "loss": 1.2793,
      "step": 7130
    },
    {
      "epoch": 1.1457113054641739,
      "grad_norm": 0.396034300327301,
      "learning_rate": 1.4176918159516869e-05,
      "loss": 1.42,
      "step": 7140
    },
    {
      "epoch": 1.147316055524352,
      "grad_norm": 0.5505780577659607,
      "learning_rate": 1.4161169476771515e-05,
      "loss": 1.4229,
      "step": 7150
    },
    {
      "epoch": 1.1489208055845301,
      "grad_norm": 0.4597626030445099,
      "learning_rate": 1.4145408302266494e-05,
      "loss": 1.3511,
      "step": 7160
    },
    {
      "epoch": 1.1505255556447083,
      "grad_norm": 0.46073710918426514,
      "learning_rate": 1.412963468331658e-05,
      "loss": 1.2401,
      "step": 7170
    },
    {
      "epoch": 1.1521303057048864,
      "grad_norm": 0.8317685723304749,
      "learning_rate": 1.4113848667273913e-05,
      "loss": 1.2792,
      "step": 7180
    },
    {
      "epoch": 1.1537350557650645,
      "grad_norm": 0.6350285410881042,
      "learning_rate": 1.4098050301527835e-05,
      "loss": 1.3959,
      "step": 7190
    },
    {
      "epoch": 1.1553398058252426,
      "grad_norm": 0.6157631874084473,
      "learning_rate": 1.4082239633504778e-05,
      "loss": 1.3762,
      "step": 7200
    },
    {
      "epoch": 1.1569445558854208,
      "grad_norm": 0.5284351706504822,
      "learning_rate": 1.4066416710668093e-05,
      "loss": 1.3333,
      "step": 7210
    },
    {
      "epoch": 1.158549305945599,
      "grad_norm": 0.6936942338943481,
      "learning_rate": 1.4050581580517925e-05,
      "loss": 1.409,
      "step": 7220
    },
    {
      "epoch": 1.160154056005777,
      "grad_norm": 0.6341999173164368,
      "learning_rate": 1.4034734290591064e-05,
      "loss": 1.4347,
      "step": 7230
    },
    {
      "epoch": 1.1617588060659552,
      "grad_norm": 0.29309824109077454,
      "learning_rate": 1.4018874888460803e-05,
      "loss": 1.2808,
      "step": 7240
    },
    {
      "epoch": 1.1633635561261333,
      "grad_norm": 0.6630398631095886,
      "learning_rate": 1.4003003421736798e-05,
      "loss": 1.2953,
      "step": 7250
    },
    {
      "epoch": 1.1649683061863114,
      "grad_norm": 0.3834102749824524,
      "learning_rate": 1.3987119938064919e-05,
      "loss": 1.173,
      "step": 7260
    },
    {
      "epoch": 1.1665730562464895,
      "grad_norm": 0.5507009029388428,
      "learning_rate": 1.3971224485127116e-05,
      "loss": 1.4009,
      "step": 7270
    },
    {
      "epoch": 1.1681778063066677,
      "grad_norm": 0.49438032507896423,
      "learning_rate": 1.395531711064126e-05,
      "loss": 1.2463,
      "step": 7280
    },
    {
      "epoch": 1.1697825563668458,
      "grad_norm": 0.4966919720172882,
      "learning_rate": 1.3939397862361026e-05,
      "loss": 1.3507,
      "step": 7290
    },
    {
      "epoch": 1.171387306427024,
      "grad_norm": 0.41381627321243286,
      "learning_rate": 1.3923466788075719e-05,
      "loss": 1.3816,
      "step": 7300
    },
    {
      "epoch": 1.172992056487202,
      "grad_norm": 0.40047743916511536,
      "learning_rate": 1.3907523935610154e-05,
      "loss": 1.286,
      "step": 7310
    },
    {
      "epoch": 1.1745968065473802,
      "grad_norm": 0.45795977115631104,
      "learning_rate": 1.3891569352824501e-05,
      "loss": 1.2834,
      "step": 7320
    },
    {
      "epoch": 1.1762015566075583,
      "grad_norm": 0.42646050453186035,
      "learning_rate": 1.3875603087614147e-05,
      "loss": 1.3431,
      "step": 7330
    },
    {
      "epoch": 1.1778063066677364,
      "grad_norm": 0.5583655834197998,
      "learning_rate": 1.3859625187909545e-05,
      "loss": 1.3837,
      "step": 7340
    },
    {
      "epoch": 1.1794110567279146,
      "grad_norm": 0.7619643211364746,
      "learning_rate": 1.3843635701676078e-05,
      "loss": 1.3277,
      "step": 7350
    },
    {
      "epoch": 1.1810158067880927,
      "grad_norm": 0.4550929665565491,
      "learning_rate": 1.382763467691391e-05,
      "loss": 1.1936,
      "step": 7360
    },
    {
      "epoch": 1.1826205568482708,
      "grad_norm": 0.39123114943504333,
      "learning_rate": 1.3811622161657844e-05,
      "loss": 1.2075,
      "step": 7370
    },
    {
      "epoch": 1.184225306908449,
      "grad_norm": 0.5276375412940979,
      "learning_rate": 1.3795598203977179e-05,
      "loss": 1.2623,
      "step": 7380
    },
    {
      "epoch": 1.185830056968627,
      "grad_norm": 0.34813618659973145,
      "learning_rate": 1.377956285197556e-05,
      "loss": 1.3291,
      "step": 7390
    },
    {
      "epoch": 1.1874348070288052,
      "grad_norm": 0.5610764026641846,
      "learning_rate": 1.3763516153790839e-05,
      "loss": 1.4134,
      "step": 7400
    },
    {
      "epoch": 1.1890395570889833,
      "grad_norm": 0.41077131032943726,
      "learning_rate": 1.3747458157594932e-05,
      "loss": 1.2891,
      "step": 7410
    },
    {
      "epoch": 1.1906443071491615,
      "grad_norm": 0.3441135585308075,
      "learning_rate": 1.3731388911593669e-05,
      "loss": 1.4564,
      "step": 7420
    },
    {
      "epoch": 1.1922490572093396,
      "grad_norm": 0.4646686613559723,
      "learning_rate": 1.3715308464026649e-05,
      "loss": 1.41,
      "step": 7430
    },
    {
      "epoch": 1.1938538072695177,
      "grad_norm": 0.38971275091171265,
      "learning_rate": 1.3699216863167103e-05,
      "loss": 1.3341,
      "step": 7440
    },
    {
      "epoch": 1.1954585573296959,
      "grad_norm": 0.38166874647140503,
      "learning_rate": 1.3683114157321745e-05,
      "loss": 1.1631,
      "step": 7450
    },
    {
      "epoch": 1.197063307389874,
      "grad_norm": 0.35580551624298096,
      "learning_rate": 1.3667000394830617e-05,
      "loss": 1.248,
      "step": 7460
    },
    {
      "epoch": 1.1986680574500521,
      "grad_norm": 0.43652981519699097,
      "learning_rate": 1.3650875624066964e-05,
      "loss": 1.2756,
      "step": 7470
    },
    {
      "epoch": 1.2002728075102302,
      "grad_norm": 0.42601877450942993,
      "learning_rate": 1.3634739893437066e-05,
      "loss": 1.3872,
      "step": 7480
    },
    {
      "epoch": 1.2018775575704084,
      "grad_norm": 0.3693404197692871,
      "learning_rate": 1.3618593251380117e-05,
      "loss": 1.3187,
      "step": 7490
    },
    {
      "epoch": 1.2034823076305865,
      "grad_norm": 0.41958141326904297,
      "learning_rate": 1.3602435746368055e-05,
      "loss": 1.2432,
      "step": 7500
    },
    {
      "epoch": 1.2050870576907646,
      "grad_norm": 0.3722675144672394,
      "learning_rate": 1.358626742690544e-05,
      "loss": 1.2077,
      "step": 7510
    },
    {
      "epoch": 1.2066918077509428,
      "grad_norm": 0.38971027731895447,
      "learning_rate": 1.3570088341529286e-05,
      "loss": 1.3264,
      "step": 7520
    },
    {
      "epoch": 1.2082965578111209,
      "grad_norm": 0.433913916349411,
      "learning_rate": 1.3553898538808932e-05,
      "loss": 1.3777,
      "step": 7530
    },
    {
      "epoch": 1.209901307871299,
      "grad_norm": 0.3125605285167694,
      "learning_rate": 1.3537698067345891e-05,
      "loss": 1.1755,
      "step": 7540
    },
    {
      "epoch": 1.2115060579314771,
      "grad_norm": 0.6322104930877686,
      "learning_rate": 1.35214869757737e-05,
      "loss": 1.3435,
      "step": 7550
    },
    {
      "epoch": 1.2131108079916553,
      "grad_norm": 0.33701908588409424,
      "learning_rate": 1.3505265312757776e-05,
      "loss": 1.3467,
      "step": 7560
    },
    {
      "epoch": 1.2147155580518334,
      "grad_norm": 0.5904881358146667,
      "learning_rate": 1.348903312699528e-05,
      "loss": 1.269,
      "step": 7570
    },
    {
      "epoch": 1.2163203081120115,
      "grad_norm": 0.34604138135910034,
      "learning_rate": 1.3472790467214951e-05,
      "loss": 1.3224,
      "step": 7580
    },
    {
      "epoch": 1.2179250581721897,
      "grad_norm": 0.42672184109687805,
      "learning_rate": 1.3456537382176982e-05,
      "loss": 1.4349,
      "step": 7590
    },
    {
      "epoch": 1.2195298082323678,
      "grad_norm": 0.5021414756774902,
      "learning_rate": 1.344027392067285e-05,
      "loss": 1.2085,
      "step": 7600
    },
    {
      "epoch": 1.221134558292546,
      "grad_norm": 0.40774115920066833,
      "learning_rate": 1.3424000131525193e-05,
      "loss": 1.3823,
      "step": 7610
    },
    {
      "epoch": 1.222739308352724,
      "grad_norm": 0.6307203769683838,
      "learning_rate": 1.3407716063587645e-05,
      "loss": 1.3097,
      "step": 7620
    },
    {
      "epoch": 1.2243440584129022,
      "grad_norm": 0.7373653650283813,
      "learning_rate": 1.3391421765744706e-05,
      "loss": 1.3351,
      "step": 7630
    },
    {
      "epoch": 1.2259488084730803,
      "grad_norm": 0.8907294869422913,
      "learning_rate": 1.337511728691157e-05,
      "loss": 1.3109,
      "step": 7640
    },
    {
      "epoch": 1.2275535585332584,
      "grad_norm": 0.4963296055793762,
      "learning_rate": 1.335880267603401e-05,
      "loss": 1.3072,
      "step": 7650
    },
    {
      "epoch": 1.2291583085934366,
      "grad_norm": 0.3151059150695801,
      "learning_rate": 1.3342477982088209e-05,
      "loss": 1.341,
      "step": 7660
    },
    {
      "epoch": 1.2307630586536147,
      "grad_norm": 0.613586962223053,
      "learning_rate": 1.332614325408062e-05,
      "loss": 1.4259,
      "step": 7670
    },
    {
      "epoch": 1.2323678087137928,
      "grad_norm": 0.42419764399528503,
      "learning_rate": 1.3309798541047813e-05,
      "loss": 1.2646,
      "step": 7680
    },
    {
      "epoch": 1.233972558773971,
      "grad_norm": 0.5329625606536865,
      "learning_rate": 1.329344389205634e-05,
      "loss": 1.3818,
      "step": 7690
    },
    {
      "epoch": 1.235577308834149,
      "grad_norm": 0.46859243512153625,
      "learning_rate": 1.3277079356202578e-05,
      "loss": 1.3215,
      "step": 7700
    },
    {
      "epoch": 1.2371820588943272,
      "grad_norm": 0.4753597378730774,
      "learning_rate": 1.3260704982612584e-05,
      "loss": 1.2435,
      "step": 7710
    },
    {
      "epoch": 1.2387868089545053,
      "grad_norm": 0.44442829489707947,
      "learning_rate": 1.3244320820441946e-05,
      "loss": 1.3199,
      "step": 7720
    },
    {
      "epoch": 1.2403915590146835,
      "grad_norm": 0.47191905975341797,
      "learning_rate": 1.3227926918875644e-05,
      "loss": 1.2851,
      "step": 7730
    },
    {
      "epoch": 1.2419963090748616,
      "grad_norm": 0.45169103145599365,
      "learning_rate": 1.3211523327127883e-05,
      "loss": 1.1977,
      "step": 7740
    },
    {
      "epoch": 1.2436010591350397,
      "grad_norm": 0.4244837164878845,
      "learning_rate": 1.3195110094441972e-05,
      "loss": 1.3071,
      "step": 7750
    },
    {
      "epoch": 1.2452058091952178,
      "grad_norm": 0.4697318375110626,
      "learning_rate": 1.317868727009015e-05,
      "loss": 1.1962,
      "step": 7760
    },
    {
      "epoch": 1.246810559255396,
      "grad_norm": 0.6292215585708618,
      "learning_rate": 1.3162254903373457e-05,
      "loss": 1.5945,
      "step": 7770
    },
    {
      "epoch": 1.248415309315574,
      "grad_norm": 0.6986608505249023,
      "learning_rate": 1.3145813043621578e-05,
      "loss": 1.3643,
      "step": 7780
    },
    {
      "epoch": 1.2500200593757522,
      "grad_norm": 0.4346173405647278,
      "learning_rate": 1.3129361740192694e-05,
      "loss": 1.1721,
      "step": 7790
    },
    {
      "epoch": 1.2516248094359304,
      "grad_norm": 0.3822895586490631,
      "learning_rate": 1.3112901042473336e-05,
      "loss": 1.2735,
      "step": 7800
    },
    {
      "epoch": 1.2532295594961085,
      "grad_norm": 0.5531186461448669,
      "learning_rate": 1.3096430999878238e-05,
      "loss": 1.2641,
      "step": 7810
    },
    {
      "epoch": 1.2548343095562866,
      "grad_norm": 0.439873069524765,
      "learning_rate": 1.3079951661850187e-05,
      "loss": 1.276,
      "step": 7820
    },
    {
      "epoch": 1.2564390596164647,
      "grad_norm": 0.6348855495452881,
      "learning_rate": 1.306346307785988e-05,
      "loss": 1.2874,
      "step": 7830
    },
    {
      "epoch": 1.2580438096766429,
      "grad_norm": 0.48618176579475403,
      "learning_rate": 1.3046965297405751e-05,
      "loss": 1.3119,
      "step": 7840
    },
    {
      "epoch": 1.259648559736821,
      "grad_norm": 0.47632744908332825,
      "learning_rate": 1.3030458370013863e-05,
      "loss": 1.2751,
      "step": 7850
    },
    {
      "epoch": 1.2612533097969991,
      "grad_norm": 0.6458721160888672,
      "learning_rate": 1.3013942345237731e-05,
      "loss": 1.252,
      "step": 7860
    },
    {
      "epoch": 1.2628580598571773,
      "grad_norm": 0.376121461391449,
      "learning_rate": 1.2997417272658178e-05,
      "loss": 1.2583,
      "step": 7870
    },
    {
      "epoch": 1.2644628099173554,
      "grad_norm": 0.3605959415435791,
      "learning_rate": 1.2980883201883186e-05,
      "loss": 1.1997,
      "step": 7880
    },
    {
      "epoch": 1.2660675599775335,
      "grad_norm": 0.5622216463088989,
      "learning_rate": 1.2964340182547758e-05,
      "loss": 1.3531,
      "step": 7890
    },
    {
      "epoch": 1.2676723100377116,
      "grad_norm": 0.9512320756912231,
      "learning_rate": 1.2947788264313753e-05,
      "loss": 1.2665,
      "step": 7900
    },
    {
      "epoch": 1.2692770600978898,
      "grad_norm": 0.5057741403579712,
      "learning_rate": 1.2931227496869747e-05,
      "loss": 1.2972,
      "step": 7910
    },
    {
      "epoch": 1.270881810158068,
      "grad_norm": 0.2990984320640564,
      "learning_rate": 1.291465792993088e-05,
      "loss": 1.349,
      "step": 7920
    },
    {
      "epoch": 1.272486560218246,
      "grad_norm": 0.45057356357574463,
      "learning_rate": 1.2898079613238712e-05,
      "loss": 1.2777,
      "step": 7930
    },
    {
      "epoch": 1.2740913102784241,
      "grad_norm": 0.5843234658241272,
      "learning_rate": 1.2881492596561063e-05,
      "loss": 1.2019,
      "step": 7940
    },
    {
      "epoch": 1.2756960603386023,
      "grad_norm": 0.4822700619697571,
      "learning_rate": 1.2864896929691874e-05,
      "loss": 1.2658,
      "step": 7950
    },
    {
      "epoch": 1.2773008103987804,
      "grad_norm": 0.5484413504600525,
      "learning_rate": 1.2848292662451055e-05,
      "loss": 1.2573,
      "step": 7960
    },
    {
      "epoch": 1.2789055604589585,
      "grad_norm": 0.28138402104377747,
      "learning_rate": 1.2831679844684332e-05,
      "loss": 1.3079,
      "step": 7970
    },
    {
      "epoch": 1.2805103105191367,
      "grad_norm": 0.645535945892334,
      "learning_rate": 1.28150585262631e-05,
      "loss": 1.5523,
      "step": 7980
    },
    {
      "epoch": 1.2821150605793148,
      "grad_norm": 0.41554227471351624,
      "learning_rate": 1.2798428757084271e-05,
      "loss": 1.1431,
      "step": 7990
    },
    {
      "epoch": 1.283719810639493,
      "grad_norm": 0.6188637614250183,
      "learning_rate": 1.2781790587070131e-05,
      "loss": 1.2114,
      "step": 8000
    },
    {
      "epoch": 1.285324560699671,
      "grad_norm": 0.39754635095596313,
      "learning_rate": 1.276514406616818e-05,
      "loss": 1.2338,
      "step": 8010
    },
    {
      "epoch": 1.2869293107598492,
      "grad_norm": 0.6637294888496399,
      "learning_rate": 1.2748489244350992e-05,
      "loss": 1.1554,
      "step": 8020
    },
    {
      "epoch": 1.2885340608200273,
      "grad_norm": 0.47590771317481995,
      "learning_rate": 1.2731826171616053e-05,
      "loss": 1.3423,
      "step": 8030
    },
    {
      "epoch": 1.2901388108802054,
      "grad_norm": 0.45480504631996155,
      "learning_rate": 1.2715154897985627e-05,
      "loss": 1.4462,
      "step": 8040
    },
    {
      "epoch": 1.2917435609403836,
      "grad_norm": 0.60245281457901,
      "learning_rate": 1.269847547350659e-05,
      "loss": 1.3435,
      "step": 8050
    },
    {
      "epoch": 1.2933483110005617,
      "grad_norm": 0.3781774938106537,
      "learning_rate": 1.268178794825029e-05,
      "loss": 1.226,
      "step": 8060
    },
    {
      "epoch": 1.2949530610607398,
      "grad_norm": 0.5589027404785156,
      "learning_rate": 1.2665092372312393e-05,
      "loss": 1.3327,
      "step": 8070
    },
    {
      "epoch": 1.296557811120918,
      "grad_norm": 0.3527999222278595,
      "learning_rate": 1.2648388795812732e-05,
      "loss": 1.2599,
      "step": 8080
    },
    {
      "epoch": 1.298162561181096,
      "grad_norm": 0.36413395404815674,
      "learning_rate": 1.263167726889516e-05,
      "loss": 1.3486,
      "step": 8090
    },
    {
      "epoch": 1.2997673112412742,
      "grad_norm": 0.588789701461792,
      "learning_rate": 1.2614957841727391e-05,
      "loss": 1.2093,
      "step": 8100
    },
    {
      "epoch": 1.3013720613014523,
      "grad_norm": 0.7329758405685425,
      "learning_rate": 1.2598230564500869e-05,
      "loss": 1.1892,
      "step": 8110
    },
    {
      "epoch": 1.3029768113616305,
      "grad_norm": 0.33255577087402344,
      "learning_rate": 1.2581495487430579e-05,
      "loss": 1.3614,
      "step": 8120
    },
    {
      "epoch": 1.3045815614218086,
      "grad_norm": 0.4325100779533386,
      "learning_rate": 1.2564752660754951e-05,
      "loss": 1.3827,
      "step": 8130
    },
    {
      "epoch": 1.3061863114819867,
      "grad_norm": 0.46744903922080994,
      "learning_rate": 1.2548002134735657e-05,
      "loss": 1.1451,
      "step": 8140
    },
    {
      "epoch": 1.3077910615421648,
      "grad_norm": 0.36994969844818115,
      "learning_rate": 1.2531243959657493e-05,
      "loss": 1.3015,
      "step": 8150
    },
    {
      "epoch": 1.309395811602343,
      "grad_norm": 0.41128799319267273,
      "learning_rate": 1.2514478185828214e-05,
      "loss": 1.2192,
      "step": 8160
    },
    {
      "epoch": 1.311000561662521,
      "grad_norm": 0.4450591802597046,
      "learning_rate": 1.2497704863578384e-05,
      "loss": 1.3085,
      "step": 8170
    },
    {
      "epoch": 1.3126053117226992,
      "grad_norm": 0.48298510909080505,
      "learning_rate": 1.248092404326123e-05,
      "loss": 1.3365,
      "step": 8180
    },
    {
      "epoch": 1.3142100617828774,
      "grad_norm": 0.3929745852947235,
      "learning_rate": 1.2464135775252493e-05,
      "loss": 1.2866,
      "step": 8190
    },
    {
      "epoch": 1.3158148118430555,
      "grad_norm": 0.34664878249168396,
      "learning_rate": 1.2447340109950262e-05,
      "loss": 1.1876,
      "step": 8200
    },
    {
      "epoch": 1.3174195619032336,
      "grad_norm": 0.6476680040359497,
      "learning_rate": 1.2430537097774838e-05,
      "loss": 1.2697,
      "step": 8210
    },
    {
      "epoch": 1.3190243119634117,
      "grad_norm": 0.517227292060852,
      "learning_rate": 1.2413726789168576e-05,
      "loss": 1.347,
      "step": 8220
    },
    {
      "epoch": 1.3206290620235899,
      "grad_norm": 0.49171507358551025,
      "learning_rate": 1.2396909234595737e-05,
      "loss": 1.3026,
      "step": 8230
    },
    {
      "epoch": 1.322233812083768,
      "grad_norm": 0.4261479675769806,
      "learning_rate": 1.2380084484542333e-05,
      "loss": 1.4349,
      "step": 8240
    },
    {
      "epoch": 1.3238385621439461,
      "grad_norm": 0.5554542541503906,
      "learning_rate": 1.236325258951597e-05,
      "loss": 1.1946,
      "step": 8250
    },
    {
      "epoch": 1.3254433122041243,
      "grad_norm": 0.3498288691043854,
      "learning_rate": 1.2346413600045717e-05,
      "loss": 1.4893,
      "step": 8260
    },
    {
      "epoch": 1.3270480622643024,
      "grad_norm": 0.34357771277427673,
      "learning_rate": 1.2329567566681931e-05,
      "loss": 1.3772,
      "step": 8270
    },
    {
      "epoch": 1.3286528123244805,
      "grad_norm": 0.5095021724700928,
      "learning_rate": 1.2312714539996111e-05,
      "loss": 1.2766,
      "step": 8280
    },
    {
      "epoch": 1.3302575623846586,
      "grad_norm": 0.7153652906417847,
      "learning_rate": 1.2295854570580761e-05,
      "loss": 1.5027,
      "step": 8290
    },
    {
      "epoch": 1.3318623124448368,
      "grad_norm": 0.3345617949962616,
      "learning_rate": 1.227898770904922e-05,
      "loss": 1.1703,
      "step": 8300
    },
    {
      "epoch": 1.333467062505015,
      "grad_norm": 0.5505359172821045,
      "learning_rate": 1.2262114006035517e-05,
      "loss": 1.2998,
      "step": 8310
    },
    {
      "epoch": 1.335071812565193,
      "grad_norm": 0.4179230034351349,
      "learning_rate": 1.224523351219422e-05,
      "loss": 1.2123,
      "step": 8320
    },
    {
      "epoch": 1.3366765626253712,
      "grad_norm": 0.47714290022850037,
      "learning_rate": 1.2228346278200282e-05,
      "loss": 1.3336,
      "step": 8330
    },
    {
      "epoch": 1.3382813126855493,
      "grad_norm": 0.5441111326217651,
      "learning_rate": 1.2211452354748894e-05,
      "loss": 1.428,
      "step": 8340
    },
    {
      "epoch": 1.3398860627457274,
      "grad_norm": 0.48453477025032043,
      "learning_rate": 1.2194551792555323e-05,
      "loss": 1.283,
      "step": 8350
    },
    {
      "epoch": 1.3414908128059055,
      "grad_norm": 0.34199202060699463,
      "learning_rate": 1.217764464235477e-05,
      "loss": 1.212,
      "step": 8360
    },
    {
      "epoch": 1.3430955628660837,
      "grad_norm": 0.4048543870449066,
      "learning_rate": 1.2160730954902208e-05,
      "loss": 1.2824,
      "step": 8370
    },
    {
      "epoch": 1.3447003129262618,
      "grad_norm": 0.5567260980606079,
      "learning_rate": 1.214381078097224e-05,
      "loss": 1.1986,
      "step": 8380
    },
    {
      "epoch": 1.34630506298644,
      "grad_norm": 0.6571035981178284,
      "learning_rate": 1.2126884171358941e-05,
      "loss": 1.2567,
      "step": 8390
    },
    {
      "epoch": 1.347909813046618,
      "grad_norm": 0.6787120699882507,
      "learning_rate": 1.21099511768757e-05,
      "loss": 1.4128,
      "step": 8400
    },
    {
      "epoch": 1.3495145631067962,
      "grad_norm": 0.4723717272281647,
      "learning_rate": 1.2093011848355077e-05,
      "loss": 1.3208,
      "step": 8410
    },
    {
      "epoch": 1.3511193131669743,
      "grad_norm": 0.4018743336200714,
      "learning_rate": 1.2076066236648649e-05,
      "loss": 1.3074,
      "step": 8420
    },
    {
      "epoch": 1.3527240632271524,
      "grad_norm": 0.37755438685417175,
      "learning_rate": 1.2059114392626852e-05,
      "loss": 1.3438,
      "step": 8430
    },
    {
      "epoch": 1.3543288132873306,
      "grad_norm": 0.45434141159057617,
      "learning_rate": 1.2042156367178833e-05,
      "loss": 1.32,
      "step": 8440
    },
    {
      "epoch": 1.3559335633475087,
      "grad_norm": 0.4530329704284668,
      "learning_rate": 1.2025192211212293e-05,
      "loss": 1.2147,
      "step": 8450
    },
    {
      "epoch": 1.3575383134076868,
      "grad_norm": 0.4891365170478821,
      "learning_rate": 1.2008221975653339e-05,
      "loss": 1.3763,
      "step": 8460
    },
    {
      "epoch": 1.359143063467865,
      "grad_norm": 0.5381444096565247,
      "learning_rate": 1.199124571144633e-05,
      "loss": 1.425,
      "step": 8470
    },
    {
      "epoch": 1.360747813528043,
      "grad_norm": 0.42470335960388184,
      "learning_rate": 1.1974263469553718e-05,
      "loss": 1.4415,
      "step": 8480
    },
    {
      "epoch": 1.3623525635882212,
      "grad_norm": 0.645168125629425,
      "learning_rate": 1.1957275300955903e-05,
      "loss": 1.274,
      "step": 8490
    },
    {
      "epoch": 1.3639573136483993,
      "grad_norm": 0.4900779128074646,
      "learning_rate": 1.194028125665108e-05,
      "loss": 1.3773,
      "step": 8500
    },
    {
      "epoch": 1.3655620637085775,
      "grad_norm": 0.4401026666164398,
      "learning_rate": 1.1923281387655077e-05,
      "loss": 1.33,
      "step": 8510
    },
    {
      "epoch": 1.3671668137687556,
      "grad_norm": 0.4375276565551758,
      "learning_rate": 1.1906275745001212e-05,
      "loss": 1.2678,
      "step": 8520
    },
    {
      "epoch": 1.3687715638289337,
      "grad_norm": 0.38777750730514526,
      "learning_rate": 1.188926437974013e-05,
      "loss": 1.2551,
      "step": 8530
    },
    {
      "epoch": 1.3703763138891119,
      "grad_norm": 0.6465415954589844,
      "learning_rate": 1.1872247342939667e-05,
      "loss": 1.3257,
      "step": 8540
    },
    {
      "epoch": 1.37198106394929,
      "grad_norm": 0.5299310684204102,
      "learning_rate": 1.1855224685684667e-05,
      "loss": 1.2168,
      "step": 8550
    },
    {
      "epoch": 1.373585814009468,
      "grad_norm": 0.4115622341632843,
      "learning_rate": 1.1838196459076864e-05,
      "loss": 1.3731,
      "step": 8560
    },
    {
      "epoch": 1.375190564069646,
      "grad_norm": 0.4625302851200104,
      "learning_rate": 1.1821162714234697e-05,
      "loss": 1.3381,
      "step": 8570
    },
    {
      "epoch": 1.3767953141298244,
      "grad_norm": 0.5291891098022461,
      "learning_rate": 1.1804123502293181e-05,
      "loss": 1.3669,
      "step": 8580
    },
    {
      "epoch": 1.3784000641900023,
      "grad_norm": 0.6452414393424988,
      "learning_rate": 1.1787078874403737e-05,
      "loss": 1.3412,
      "step": 8590
    },
    {
      "epoch": 1.3800048142501806,
      "grad_norm": 0.36883407831192017,
      "learning_rate": 1.1770028881734048e-05,
      "loss": 1.4255,
      "step": 8600
    },
    {
      "epoch": 1.3816095643103585,
      "grad_norm": 0.5101768374443054,
      "learning_rate": 1.1752973575467901e-05,
      "loss": 1.3352,
      "step": 8610
    },
    {
      "epoch": 1.3832143143705369,
      "grad_norm": 0.39968395233154297,
      "learning_rate": 1.1735913006805033e-05,
      "loss": 1.2118,
      "step": 8620
    },
    {
      "epoch": 1.3848190644307148,
      "grad_norm": 0.3971270024776459,
      "learning_rate": 1.171884722696098e-05,
      "loss": 1.3322,
      "step": 8630
    },
    {
      "epoch": 1.3864238144908931,
      "grad_norm": 0.5070668458938599,
      "learning_rate": 1.170177628716692e-05,
      "loss": 1.3286,
      "step": 8640
    },
    {
      "epoch": 1.388028564551071,
      "grad_norm": 0.40874800086021423,
      "learning_rate": 1.1684700238669526e-05,
      "loss": 1.3987,
      "step": 8650
    },
    {
      "epoch": 1.3896333146112494,
      "grad_norm": 0.4954782724380493,
      "learning_rate": 1.1667619132730802e-05,
      "loss": 1.2074,
      "step": 8660
    },
    {
      "epoch": 1.3912380646714273,
      "grad_norm": 0.36395907402038574,
      "learning_rate": 1.1650533020627937e-05,
      "loss": 1.3012,
      "step": 8670
    },
    {
      "epoch": 1.3928428147316056,
      "grad_norm": 0.44027063250541687,
      "learning_rate": 1.1633441953653143e-05,
      "loss": 1.348,
      "step": 8680
    },
    {
      "epoch": 1.3944475647917836,
      "grad_norm": 0.3093055188655853,
      "learning_rate": 1.1616345983113516e-05,
      "loss": 1.3614,
      "step": 8690
    },
    {
      "epoch": 1.396052314851962,
      "grad_norm": 0.5862752199172974,
      "learning_rate": 1.1599245160330866e-05,
      "loss": 1.2803,
      "step": 8700
    },
    {
      "epoch": 1.3976570649121398,
      "grad_norm": 0.40818434953689575,
      "learning_rate": 1.158213953664157e-05,
      "loss": 1.2492,
      "step": 8710
    },
    {
      "epoch": 1.3992618149723182,
      "grad_norm": 0.5676238536834717,
      "learning_rate": 1.156502916339642e-05,
      "loss": 1.2,
      "step": 8720
    },
    {
      "epoch": 1.400866565032496,
      "grad_norm": 0.4251767694950104,
      "learning_rate": 1.1547914091960463e-05,
      "loss": 1.341,
      "step": 8730
    },
    {
      "epoch": 1.4024713150926744,
      "grad_norm": 0.3724423050880432,
      "learning_rate": 1.153079437371285e-05,
      "loss": 1.3924,
      "step": 8740
    },
    {
      "epoch": 1.4040760651528523,
      "grad_norm": 0.5566845536231995,
      "learning_rate": 1.1513670060046685e-05,
      "loss": 1.3988,
      "step": 8750
    },
    {
      "epoch": 1.4056808152130307,
      "grad_norm": 0.6623894572257996,
      "learning_rate": 1.1496541202368863e-05,
      "loss": 1.2676,
      "step": 8760
    },
    {
      "epoch": 1.4072855652732086,
      "grad_norm": 0.5004273056983948,
      "learning_rate": 1.1479407852099922e-05,
      "loss": 1.2287,
      "step": 8770
    },
    {
      "epoch": 1.408890315333387,
      "grad_norm": 0.4145958125591278,
      "learning_rate": 1.1462270060673888e-05,
      "loss": 1.2321,
      "step": 8780
    },
    {
      "epoch": 1.4104950653935648,
      "grad_norm": 0.397914856672287,
      "learning_rate": 1.1445127879538117e-05,
      "loss": 1.2859,
      "step": 8790
    },
    {
      "epoch": 1.4120998154537432,
      "grad_norm": 0.5796698927879333,
      "learning_rate": 1.1427981360153143e-05,
      "loss": 1.5296,
      "step": 8800
    },
    {
      "epoch": 1.413704565513921,
      "grad_norm": 0.2995744049549103,
      "learning_rate": 1.1410830553992527e-05,
      "loss": 1.2787,
      "step": 8810
    },
    {
      "epoch": 1.4153093155740994,
      "grad_norm": 0.43969741463661194,
      "learning_rate": 1.1393675512542695e-05,
      "loss": 1.1841,
      "step": 8820
    },
    {
      "epoch": 1.4169140656342774,
      "grad_norm": 0.6251104474067688,
      "learning_rate": 1.1376516287302789e-05,
      "loss": 1.4875,
      "step": 8830
    },
    {
      "epoch": 1.4185188156944557,
      "grad_norm": 0.6077860593795776,
      "learning_rate": 1.1359352929784506e-05,
      "loss": 1.3382,
      "step": 8840
    },
    {
      "epoch": 1.4201235657546336,
      "grad_norm": 0.6382263898849487,
      "learning_rate": 1.1342185491511957e-05,
      "loss": 1.4388,
      "step": 8850
    },
    {
      "epoch": 1.421728315814812,
      "grad_norm": 0.5587853789329529,
      "learning_rate": 1.1325014024021494e-05,
      "loss": 1.2698,
      "step": 8860
    },
    {
      "epoch": 1.4233330658749899,
      "grad_norm": 0.44043320417404175,
      "learning_rate": 1.1307838578861573e-05,
      "loss": 1.259,
      "step": 8870
    },
    {
      "epoch": 1.4249378159351682,
      "grad_norm": 0.4108255207538605,
      "learning_rate": 1.1290659207592588e-05,
      "loss": 1.4734,
      "step": 8880
    },
    {
      "epoch": 1.4265425659953461,
      "grad_norm": 0.38001808524131775,
      "learning_rate": 1.127347596178671e-05,
      "loss": 1.2766,
      "step": 8890
    },
    {
      "epoch": 1.4281473160555245,
      "grad_norm": 0.7457751035690308,
      "learning_rate": 1.1256288893027758e-05,
      "loss": 1.1252,
      "step": 8900
    },
    {
      "epoch": 1.4297520661157024,
      "grad_norm": 0.49614080786705017,
      "learning_rate": 1.1239098052911013e-05,
      "loss": 1.4077,
      "step": 8910
    },
    {
      "epoch": 1.4313568161758807,
      "grad_norm": 0.32776719331741333,
      "learning_rate": 1.1221903493043088e-05,
      "loss": 1.2703,
      "step": 8920
    },
    {
      "epoch": 1.4329615662360586,
      "grad_norm": 0.5177673697471619,
      "learning_rate": 1.120470526504175e-05,
      "loss": 1.2345,
      "step": 8930
    },
    {
      "epoch": 1.434566316296237,
      "grad_norm": 0.6331548690795898,
      "learning_rate": 1.1187503420535798e-05,
      "loss": 1.4242,
      "step": 8940
    },
    {
      "epoch": 1.436171066356415,
      "grad_norm": 0.4373107850551605,
      "learning_rate": 1.1170298011164863e-05,
      "loss": 1.1219,
      "step": 8950
    },
    {
      "epoch": 1.4377758164165932,
      "grad_norm": 0.5678044557571411,
      "learning_rate": 1.11530890885793e-05,
      "loss": 1.2895,
      "step": 8960
    },
    {
      "epoch": 1.4393805664767712,
      "grad_norm": 0.4400615692138672,
      "learning_rate": 1.1135876704439994e-05,
      "loss": 1.3671,
      "step": 8970
    },
    {
      "epoch": 1.4409853165369495,
      "grad_norm": 0.6141665577888489,
      "learning_rate": 1.1118660910418228e-05,
      "loss": 1.2818,
      "step": 8980
    },
    {
      "epoch": 1.4425900665971274,
      "grad_norm": 0.6309098601341248,
      "learning_rate": 1.1101441758195524e-05,
      "loss": 1.2054,
      "step": 8990
    },
    {
      "epoch": 1.4441948166573058,
      "grad_norm": 0.5055993795394897,
      "learning_rate": 1.1084219299463484e-05,
      "loss": 1.4019,
      "step": 9000
    },
    {
      "epoch": 1.4457995667174837,
      "grad_norm": 0.5752190947532654,
      "learning_rate": 1.1066993585923628e-05,
      "loss": 1.1936,
      "step": 9010
    },
    {
      "epoch": 1.447404316777662,
      "grad_norm": 0.28613463044166565,
      "learning_rate": 1.1049764669287265e-05,
      "loss": 1.3169,
      "step": 9020
    },
    {
      "epoch": 1.44900906683784,
      "grad_norm": 0.2837562561035156,
      "learning_rate": 1.1032532601275298e-05,
      "loss": 1.3299,
      "step": 9030
    },
    {
      "epoch": 1.4506138168980183,
      "grad_norm": 0.5696951746940613,
      "learning_rate": 1.1015297433618107e-05,
      "loss": 1.4582,
      "step": 9040
    },
    {
      "epoch": 1.4522185669581962,
      "grad_norm": 0.38746750354766846,
      "learning_rate": 1.0998059218055366e-05,
      "loss": 1.2116,
      "step": 9050
    },
    {
      "epoch": 1.4538233170183743,
      "grad_norm": 0.42330387234687805,
      "learning_rate": 1.0980818006335907e-05,
      "loss": 1.1413,
      "step": 9060
    },
    {
      "epoch": 1.4554280670785524,
      "grad_norm": 0.7380138635635376,
      "learning_rate": 1.0963573850217553e-05,
      "loss": 1.4244,
      "step": 9070
    },
    {
      "epoch": 1.4570328171387306,
      "grad_norm": 0.2893231511116028,
      "learning_rate": 1.0946326801466964e-05,
      "loss": 1.5662,
      "step": 9080
    },
    {
      "epoch": 1.4586375671989087,
      "grad_norm": 0.4452526867389679,
      "learning_rate": 1.0929076911859487e-05,
      "loss": 1.3258,
      "step": 9090
    },
    {
      "epoch": 1.4602423172590868,
      "grad_norm": 0.47603633999824524,
      "learning_rate": 1.0911824233178995e-05,
      "loss": 1.2894,
      "step": 9100
    },
    {
      "epoch": 1.461847067319265,
      "grad_norm": 0.45050227642059326,
      "learning_rate": 1.0894568817217736e-05,
      "loss": 1.1209,
      "step": 9110
    },
    {
      "epoch": 1.463451817379443,
      "grad_norm": 0.6243150234222412,
      "learning_rate": 1.0877310715776175e-05,
      "loss": 1.2994,
      "step": 9120
    },
    {
      "epoch": 1.4650565674396212,
      "grad_norm": 0.28925564885139465,
      "learning_rate": 1.0860049980662832e-05,
      "loss": 1.3688,
      "step": 9130
    },
    {
      "epoch": 1.4666613174997993,
      "grad_norm": 0.47817665338516235,
      "learning_rate": 1.0842786663694145e-05,
      "loss": 1.3101,
      "step": 9140
    },
    {
      "epoch": 1.4682660675599775,
      "grad_norm": 0.43149423599243164,
      "learning_rate": 1.0825520816694295e-05,
      "loss": 1.2572,
      "step": 9150
    },
    {
      "epoch": 1.4698708176201556,
      "grad_norm": 0.4288705587387085,
      "learning_rate": 1.0808252491495057e-05,
      "loss": 1.1729,
      "step": 9160
    },
    {
      "epoch": 1.4714755676803337,
      "grad_norm": 0.4268832802772522,
      "learning_rate": 1.0790981739935652e-05,
      "loss": 1.2318,
      "step": 9170
    },
    {
      "epoch": 1.4730803177405118,
      "grad_norm": 0.6261513829231262,
      "learning_rate": 1.0773708613862577e-05,
      "loss": 1.4976,
      "step": 9180
    },
    {
      "epoch": 1.47468506780069,
      "grad_norm": 0.4662007689476013,
      "learning_rate": 1.0756433165129462e-05,
      "loss": 1.3217,
      "step": 9190
    },
    {
      "epoch": 1.476289817860868,
      "grad_norm": 0.5503376722335815,
      "learning_rate": 1.0739155445596914e-05,
      "loss": 1.3551,
      "step": 9200
    },
    {
      "epoch": 1.4778945679210462,
      "grad_norm": 0.6103018522262573,
      "learning_rate": 1.0721875507132347e-05,
      "loss": 1.3378,
      "step": 9210
    },
    {
      "epoch": 1.4794993179812244,
      "grad_norm": 0.4730494022369385,
      "learning_rate": 1.0704593401609842e-05,
      "loss": 1.3869,
      "step": 9220
    },
    {
      "epoch": 1.4811040680414025,
      "grad_norm": 0.45912331342697144,
      "learning_rate": 1.0687309180909984e-05,
      "loss": 1.3005,
      "step": 9230
    },
    {
      "epoch": 1.4827088181015806,
      "grad_norm": 0.7722640037536621,
      "learning_rate": 1.0670022896919711e-05,
      "loss": 1.2601,
      "step": 9240
    },
    {
      "epoch": 1.4843135681617587,
      "grad_norm": 0.4240722954273224,
      "learning_rate": 1.0652734601532149e-05,
      "loss": 1.2971,
      "step": 9250
    },
    {
      "epoch": 1.4859183182219369,
      "grad_norm": 0.34611833095550537,
      "learning_rate": 1.0635444346646467e-05,
      "loss": 1.2676,
      "step": 9260
    },
    {
      "epoch": 1.487523068282115,
      "grad_norm": 0.4019455909729004,
      "learning_rate": 1.0618152184167712e-05,
      "loss": 1.5207,
      "step": 9270
    },
    {
      "epoch": 1.4891278183422931,
      "grad_norm": 0.4068852961063385,
      "learning_rate": 1.0600858166006664e-05,
      "loss": 1.2538,
      "step": 9280
    },
    {
      "epoch": 1.4907325684024713,
      "grad_norm": 0.6425724625587463,
      "learning_rate": 1.0583562344079668e-05,
      "loss": 1.3007,
      "step": 9290
    },
    {
      "epoch": 1.4923373184626494,
      "grad_norm": 0.48550939559936523,
      "learning_rate": 1.0566264770308485e-05,
      "loss": 1.4296,
      "step": 9300
    },
    {
      "epoch": 1.4939420685228275,
      "grad_norm": 0.4583524167537689,
      "learning_rate": 1.0548965496620138e-05,
      "loss": 1.3346,
      "step": 9310
    },
    {
      "epoch": 1.4955468185830056,
      "grad_norm": 0.5861687064170837,
      "learning_rate": 1.0531664574946752e-05,
      "loss": 1.4121,
      "step": 9320
    },
    {
      "epoch": 1.4971515686431838,
      "grad_norm": 0.5131075382232666,
      "learning_rate": 1.0514362057225395e-05,
      "loss": 1.2911,
      "step": 9330
    },
    {
      "epoch": 1.498756318703362,
      "grad_norm": 0.6177898049354553,
      "learning_rate": 1.049705799539793e-05,
      "loss": 1.3211,
      "step": 9340
    },
    {
      "epoch": 1.50036106876354,
      "grad_norm": 0.4633405804634094,
      "learning_rate": 1.0479752441410857e-05,
      "loss": 1.2506,
      "step": 9350
    },
    {
      "epoch": 1.5019658188237182,
      "grad_norm": 0.5027555227279663,
      "learning_rate": 1.0462445447215154e-05,
      "loss": 1.384,
      "step": 9360
    },
    {
      "epoch": 1.5035705688838963,
      "grad_norm": 0.7161389589309692,
      "learning_rate": 1.044513706476612e-05,
      "loss": 1.4567,
      "step": 9370
    },
    {
      "epoch": 1.5051753189440744,
      "grad_norm": 0.5154787302017212,
      "learning_rate": 1.042782734602322e-05,
      "loss": 1.2602,
      "step": 9380
    },
    {
      "epoch": 1.5067800690042525,
      "grad_norm": 0.5886952877044678,
      "learning_rate": 1.041051634294994e-05,
      "loss": 1.263,
      "step": 9390
    },
    {
      "epoch": 1.5083848190644307,
      "grad_norm": 0.4104962646961212,
      "learning_rate": 1.0393204107513614e-05,
      "loss": 1.3834,
      "step": 9400
    },
    {
      "epoch": 1.5099895691246088,
      "grad_norm": 0.6174566149711609,
      "learning_rate": 1.0375890691685274e-05,
      "loss": 1.4073,
      "step": 9410
    },
    {
      "epoch": 1.511594319184787,
      "grad_norm": 0.4865262508392334,
      "learning_rate": 1.03585761474395e-05,
      "loss": 1.366,
      "step": 9420
    },
    {
      "epoch": 1.513199069244965,
      "grad_norm": 0.5779155492782593,
      "learning_rate": 1.034126052675426e-05,
      "loss": 1.1822,
      "step": 9430
    },
    {
      "epoch": 1.5148038193051432,
      "grad_norm": 0.4840981960296631,
      "learning_rate": 1.032394388161075e-05,
      "loss": 1.1629,
      "step": 9440
    },
    {
      "epoch": 1.5164085693653213,
      "grad_norm": 0.36747467517852783,
      "learning_rate": 1.0306626263993242e-05,
      "loss": 1.3736,
      "step": 9450
    },
    {
      "epoch": 1.5180133194254994,
      "grad_norm": 0.43062517046928406,
      "learning_rate": 1.0289307725888929e-05,
      "loss": 1.3422,
      "step": 9460
    },
    {
      "epoch": 1.5196180694856776,
      "grad_norm": 0.5593737363815308,
      "learning_rate": 1.0271988319287765e-05,
      "loss": 1.3549,
      "step": 9470
    },
    {
      "epoch": 1.5212228195458557,
      "grad_norm": 0.5526537299156189,
      "learning_rate": 1.0254668096182313e-05,
      "loss": 1.3362,
      "step": 9480
    },
    {
      "epoch": 1.5228275696060338,
      "grad_norm": 0.5397584438323975,
      "learning_rate": 1.023734710856759e-05,
      "loss": 1.2868,
      "step": 9490
    },
    {
      "epoch": 1.524432319666212,
      "grad_norm": 0.5956773161888123,
      "learning_rate": 1.02200254084409e-05,
      "loss": 1.2728,
      "step": 9500
    },
    {
      "epoch": 1.52603706972639,
      "grad_norm": 0.49894410371780396,
      "learning_rate": 1.0202703047801696e-05,
      "loss": 1.2865,
      "step": 9510
    },
    {
      "epoch": 1.5276418197865682,
      "grad_norm": 0.6718289256095886,
      "learning_rate": 1.0185380078651408e-05,
      "loss": 1.3946,
      "step": 9520
    },
    {
      "epoch": 1.5292465698467463,
      "grad_norm": 0.5137860774993896,
      "learning_rate": 1.0168056552993288e-05,
      "loss": 1.3255,
      "step": 9530
    },
    {
      "epoch": 1.5308513199069245,
      "grad_norm": 0.5104056596755981,
      "learning_rate": 1.0150732522832268e-05,
      "loss": 1.2502,
      "step": 9540
    },
    {
      "epoch": 1.5324560699671026,
      "grad_norm": 0.3354523777961731,
      "learning_rate": 1.013340804017479e-05,
      "loss": 1.1625,
      "step": 9550
    },
    {
      "epoch": 1.5340608200272807,
      "grad_norm": 0.5526414513587952,
      "learning_rate": 1.0116083157028656e-05,
      "loss": 1.3795,
      "step": 9560
    },
    {
      "epoch": 1.5356655700874589,
      "grad_norm": 0.6103456616401672,
      "learning_rate": 1.0098757925402866e-05,
      "loss": 1.2743,
      "step": 9570
    },
    {
      "epoch": 1.537270320147637,
      "grad_norm": 0.5660024285316467,
      "learning_rate": 1.0081432397307474e-05,
      "loss": 1.305,
      "step": 9580
    },
    {
      "epoch": 1.538875070207815,
      "grad_norm": 0.4005955457687378,
      "learning_rate": 1.0064106624753417e-05,
      "loss": 1.2612,
      "step": 9590
    },
    {
      "epoch": 1.5404798202679932,
      "grad_norm": 0.37001246213912964,
      "learning_rate": 1.0046780659752364e-05,
      "loss": 1.2803,
      "step": 9600
    },
    {
      "epoch": 1.5420845703281714,
      "grad_norm": 0.6065647602081299,
      "learning_rate": 1.0029454554316574e-05,
      "loss": 1.2171,
      "step": 9610
    },
    {
      "epoch": 1.5436893203883495,
      "grad_norm": 0.34911027550697327,
      "learning_rate": 1.0012128360458713e-05,
      "loss": 1.1811,
      "step": 9620
    },
    {
      "epoch": 1.5452940704485276,
      "grad_norm": 0.5313422083854675,
      "learning_rate": 9.994802130191719e-06,
      "loss": 1.2787,
      "step": 9630
    },
    {
      "epoch": 1.5468988205087058,
      "grad_norm": 0.6233901381492615,
      "learning_rate": 9.977475915528647e-06,
      "loss": 1.433,
      "step": 9640
    },
    {
      "epoch": 1.5485035705688839,
      "grad_norm": 0.6291518211364746,
      "learning_rate": 9.960149768482485e-06,
      "loss": 1.3126,
      "step": 9650
    },
    {
      "epoch": 1.550108320629062,
      "grad_norm": 0.5162368416786194,
      "learning_rate": 9.942823741066043e-06,
      "loss": 1.2563,
      "step": 9660
    },
    {
      "epoch": 1.5517130706892401,
      "grad_norm": 0.42715251445770264,
      "learning_rate": 9.925497885291752e-06,
      "loss": 1.4011,
      "step": 9670
    },
    {
      "epoch": 1.5533178207494183,
      "grad_norm": 0.5093327164649963,
      "learning_rate": 9.908172253171534e-06,
      "loss": 1.3438,
      "step": 9680
    },
    {
      "epoch": 1.5549225708095964,
      "grad_norm": 0.31581199169158936,
      "learning_rate": 9.890846896716647e-06,
      "loss": 1.3662,
      "step": 9690
    },
    {
      "epoch": 1.5565273208697745,
      "grad_norm": 0.5133839845657349,
      "learning_rate": 9.873521867937506e-06,
      "loss": 1.3054,
      "step": 9700
    },
    {
      "epoch": 1.5581320709299527,
      "grad_norm": 0.43646156787872314,
      "learning_rate": 9.856197218843561e-06,
      "loss": 1.2362,
      "step": 9710
    },
    {
      "epoch": 1.5597368209901308,
      "grad_norm": 0.5532973408699036,
      "learning_rate": 9.838873001443103e-06,
      "loss": 1.3932,
      "step": 9720
    },
    {
      "epoch": 1.561341571050309,
      "grad_norm": 0.6536970138549805,
      "learning_rate": 9.821549267743145e-06,
      "loss": 1.2072,
      "step": 9730
    },
    {
      "epoch": 1.562946321110487,
      "grad_norm": 0.464897096157074,
      "learning_rate": 9.804226069749234e-06,
      "loss": 1.5062,
      "step": 9740
    },
    {
      "epoch": 1.5645510711706652,
      "grad_norm": 0.4531822204589844,
      "learning_rate": 9.78690345946532e-06,
      "loss": 1.3122,
      "step": 9750
    },
    {
      "epoch": 1.5661558212308433,
      "grad_norm": 0.5209041237831116,
      "learning_rate": 9.769581488893575e-06,
      "loss": 1.3426,
      "step": 9760
    },
    {
      "epoch": 1.5677605712910214,
      "grad_norm": 0.7090029716491699,
      "learning_rate": 9.752260210034266e-06,
      "loss": 1.3979,
      "step": 9770
    },
    {
      "epoch": 1.5693653213511995,
      "grad_norm": 0.5189130902290344,
      "learning_rate": 9.73493967488557e-06,
      "loss": 1.1663,
      "step": 9780
    },
    {
      "epoch": 1.5709700714113777,
      "grad_norm": 0.5736579298973083,
      "learning_rate": 9.717619935443448e-06,
      "loss": 1.3169,
      "step": 9790
    },
    {
      "epoch": 1.5725748214715558,
      "grad_norm": 0.550003170967102,
      "learning_rate": 9.700301043701447e-06,
      "loss": 1.4483,
      "step": 9800
    },
    {
      "epoch": 1.574179571531734,
      "grad_norm": 0.38397595286369324,
      "learning_rate": 9.682983051650597e-06,
      "loss": 1.149,
      "step": 9810
    },
    {
      "epoch": 1.575784321591912,
      "grad_norm": 0.4317736327648163,
      "learning_rate": 9.665666011279206e-06,
      "loss": 1.4116,
      "step": 9820
    },
    {
      "epoch": 1.5773890716520902,
      "grad_norm": 0.8652298450469971,
      "learning_rate": 9.648349974572739e-06,
      "loss": 1.3851,
      "step": 9830
    },
    {
      "epoch": 1.5789938217122683,
      "grad_norm": 0.6816331744194031,
      "learning_rate": 9.631034993513637e-06,
      "loss": 1.1529,
      "step": 9840
    },
    {
      "epoch": 1.5805985717724464,
      "grad_norm": 0.4067188501358032,
      "learning_rate": 9.613721120081184e-06,
      "loss": 1.107,
      "step": 9850
    },
    {
      "epoch": 1.5822033218326246,
      "grad_norm": 0.6432110071182251,
      "learning_rate": 9.596408406251323e-06,
      "loss": 1.2874,
      "step": 9860
    },
    {
      "epoch": 1.5838080718928027,
      "grad_norm": 0.5622227787971497,
      "learning_rate": 9.579096903996535e-06,
      "loss": 1.249,
      "step": 9870
    },
    {
      "epoch": 1.5854128219529808,
      "grad_norm": 0.36109793186187744,
      "learning_rate": 9.561786665285646e-06,
      "loss": 1.1388,
      "step": 9880
    },
    {
      "epoch": 1.587017572013159,
      "grad_norm": 0.7643912434577942,
      "learning_rate": 9.544477742083704e-06,
      "loss": 1.3524,
      "step": 9890
    },
    {
      "epoch": 1.588622322073337,
      "grad_norm": 0.4878406524658203,
      "learning_rate": 9.527170186351792e-06,
      "loss": 1.2164,
      "step": 9900
    },
    {
      "epoch": 1.5902270721335152,
      "grad_norm": 0.8255204558372498,
      "learning_rate": 9.509864050046904e-06,
      "loss": 1.5354,
      "step": 9910
    },
    {
      "epoch": 1.5918318221936933,
      "grad_norm": 0.7140220403671265,
      "learning_rate": 9.492559385121762e-06,
      "loss": 1.4168,
      "step": 9920
    },
    {
      "epoch": 1.5934365722538715,
      "grad_norm": 0.43024447560310364,
      "learning_rate": 9.475256243524678e-06,
      "loss": 1.0933,
      "step": 9930
    },
    {
      "epoch": 1.5950413223140496,
      "grad_norm": 0.5931713581085205,
      "learning_rate": 9.457954677199383e-06,
      "loss": 1.4246,
      "step": 9940
    },
    {
      "epoch": 1.5966460723742277,
      "grad_norm": 0.6254360675811768,
      "learning_rate": 9.440654738084885e-06,
      "loss": 1.3693,
      "step": 9950
    },
    {
      "epoch": 1.5982508224344059,
      "grad_norm": 0.7071413397789001,
      "learning_rate": 9.423356478115304e-06,
      "loss": 1.4853,
      "step": 9960
    },
    {
      "epoch": 1.599855572494584,
      "grad_norm": 0.6861327290534973,
      "learning_rate": 9.406059949219724e-06,
      "loss": 1.3482,
      "step": 9970
    },
    {
      "epoch": 1.6014603225547621,
      "grad_norm": 0.4743536412715912,
      "learning_rate": 9.388765203322029e-06,
      "loss": 1.1261,
      "step": 9980
    },
    {
      "epoch": 1.6030650726149402,
      "grad_norm": 0.5346304178237915,
      "learning_rate": 9.371472292340748e-06,
      "loss": 1.4086,
      "step": 9990
    },
    {
      "epoch": 1.6046698226751184,
      "grad_norm": 0.5557130575180054,
      "learning_rate": 9.354181268188907e-06,
      "loss": 1.2709,
      "step": 10000
    },
    {
      "epoch": 1.6062745727352965,
      "grad_norm": 0.611912190914154,
      "learning_rate": 9.336892182773864e-06,
      "loss": 1.2891,
      "step": 10010
    },
    {
      "epoch": 1.6078793227954746,
      "grad_norm": 0.5284813642501831,
      "learning_rate": 9.319605087997157e-06,
      "loss": 1.354,
      "step": 10020
    },
    {
      "epoch": 1.6094840728556528,
      "grad_norm": 0.30901047587394714,
      "learning_rate": 9.30232003575435e-06,
      "loss": 1.37,
      "step": 10030
    },
    {
      "epoch": 1.6110888229158309,
      "grad_norm": 0.4922613799571991,
      "learning_rate": 9.285037077934874e-06,
      "loss": 1.2974,
      "step": 10040
    },
    {
      "epoch": 1.612693572976009,
      "grad_norm": 0.4004596471786499,
      "learning_rate": 9.267756266421875e-06,
      "loss": 1.2456,
      "step": 10050
    },
    {
      "epoch": 1.6142983230361871,
      "grad_norm": 0.4462622404098511,
      "learning_rate": 9.250477653092051e-06,
      "loss": 1.38,
      "step": 10060
    },
    {
      "epoch": 1.6159030730963653,
      "grad_norm": 0.4766418933868408,
      "learning_rate": 9.233201289815505e-06,
      "loss": 1.3339,
      "step": 10070
    },
    {
      "epoch": 1.6175078231565434,
      "grad_norm": 0.5451598763465881,
      "learning_rate": 9.215927228455587e-06,
      "loss": 1.2365,
      "step": 10080
    },
    {
      "epoch": 1.6191125732167215,
      "grad_norm": 0.44418027997016907,
      "learning_rate": 9.19865552086873e-06,
      "loss": 1.2417,
      "step": 10090
    },
    {
      "epoch": 1.6207173232768997,
      "grad_norm": 0.40806153416633606,
      "learning_rate": 9.181386218904308e-06,
      "loss": 1.1334,
      "step": 10100
    },
    {
      "epoch": 1.6223220733370778,
      "grad_norm": 0.5471625328063965,
      "learning_rate": 9.16411937440447e-06,
      "loss": 1.1424,
      "step": 10110
    },
    {
      "epoch": 1.623926823397256,
      "grad_norm": 0.5932746529579163,
      "learning_rate": 9.146855039203986e-06,
      "loss": 1.284,
      "step": 10120
    },
    {
      "epoch": 1.625531573457434,
      "grad_norm": 0.47057968378067017,
      "learning_rate": 9.129593265130097e-06,
      "loss": 1.3882,
      "step": 10130
    },
    {
      "epoch": 1.6271363235176122,
      "grad_norm": 0.3208356201648712,
      "learning_rate": 9.112334104002353e-06,
      "loss": 1.2611,
      "step": 10140
    },
    {
      "epoch": 1.6287410735777903,
      "grad_norm": 0.5072731971740723,
      "learning_rate": 9.095077607632462e-06,
      "loss": 1.2939,
      "step": 10150
    },
    {
      "epoch": 1.6303458236379684,
      "grad_norm": 0.4697054922580719,
      "learning_rate": 9.07782382782413e-06,
      "loss": 1.281,
      "step": 10160
    },
    {
      "epoch": 1.6319505736981466,
      "grad_norm": 0.6101133823394775,
      "learning_rate": 9.06057281637291e-06,
      "loss": 1.3214,
      "step": 10170
    },
    {
      "epoch": 1.6335553237583247,
      "grad_norm": 0.9278947114944458,
      "learning_rate": 9.043324625066045e-06,
      "loss": 1.4435,
      "step": 10180
    },
    {
      "epoch": 1.6351600738185028,
      "grad_norm": 0.7842887043952942,
      "learning_rate": 9.026079305682304e-06,
      "loss": 1.2535,
      "step": 10190
    },
    {
      "epoch": 1.636764823878681,
      "grad_norm": 0.8392810225486755,
      "learning_rate": 9.008836909991852e-06,
      "loss": 1.3297,
      "step": 10200
    },
    {
      "epoch": 1.638369573938859,
      "grad_norm": 0.6077150106430054,
      "learning_rate": 8.991597489756057e-06,
      "loss": 1.3909,
      "step": 10210
    },
    {
      "epoch": 1.6399743239990372,
      "grad_norm": 0.6001397967338562,
      "learning_rate": 8.97436109672737e-06,
      "loss": 1.3027,
      "step": 10220
    },
    {
      "epoch": 1.6415790740592153,
      "grad_norm": 0.5625351071357727,
      "learning_rate": 8.957127782649146e-06,
      "loss": 1.4741,
      "step": 10230
    },
    {
      "epoch": 1.6431838241193935,
      "grad_norm": 0.3739023804664612,
      "learning_rate": 8.939897599255496e-06,
      "loss": 1.1699,
      "step": 10240
    },
    {
      "epoch": 1.6447885741795716,
      "grad_norm": 0.4957106411457062,
      "learning_rate": 8.92267059827114e-06,
      "loss": 1.3978,
      "step": 10250
    },
    {
      "epoch": 1.6463933242397497,
      "grad_norm": 0.45849132537841797,
      "learning_rate": 8.90544683141124e-06,
      "loss": 1.293,
      "step": 10260
    },
    {
      "epoch": 1.6479980742999278,
      "grad_norm": 0.3547096848487854,
      "learning_rate": 8.88822635038125e-06,
      "loss": 1.2681,
      "step": 10270
    },
    {
      "epoch": 1.649602824360106,
      "grad_norm": 0.41155973076820374,
      "learning_rate": 8.871009206876757e-06,
      "loss": 1.2996,
      "step": 10280
    },
    {
      "epoch": 1.651207574420284,
      "grad_norm": 0.41697436571121216,
      "learning_rate": 8.853795452583339e-06,
      "loss": 1.1865,
      "step": 10290
    },
    {
      "epoch": 1.652812324480462,
      "grad_norm": 0.43161270022392273,
      "learning_rate": 8.836585139176382e-06,
      "loss": 1.2051,
      "step": 10300
    },
    {
      "epoch": 1.6544170745406404,
      "grad_norm": 0.5570599436759949,
      "learning_rate": 8.819378318320962e-06,
      "loss": 1.4229,
      "step": 10310
    },
    {
      "epoch": 1.6560218246008183,
      "grad_norm": 0.40513068437576294,
      "learning_rate": 8.802175041671655e-06,
      "loss": 1.1828,
      "step": 10320
    },
    {
      "epoch": 1.6576265746609966,
      "grad_norm": 0.589361846446991,
      "learning_rate": 8.784975360872407e-06,
      "loss": 1.3967,
      "step": 10330
    },
    {
      "epoch": 1.6592313247211745,
      "grad_norm": 0.4880925416946411,
      "learning_rate": 8.767779327556362e-06,
      "loss": 1.3754,
      "step": 10340
    },
    {
      "epoch": 1.6608360747813529,
      "grad_norm": 0.6069830656051636,
      "learning_rate": 8.750586993345726e-06,
      "loss": 1.3158,
      "step": 10350
    },
    {
      "epoch": 1.6624408248415308,
      "grad_norm": 0.5541645884513855,
      "learning_rate": 8.733398409851582e-06,
      "loss": 1.3009,
      "step": 10360
    },
    {
      "epoch": 1.6640455749017091,
      "grad_norm": 0.47428232431411743,
      "learning_rate": 8.716213628673776e-06,
      "loss": 1.2403,
      "step": 10370
    },
    {
      "epoch": 1.665650324961887,
      "grad_norm": 0.35994043946266174,
      "learning_rate": 8.699032701400714e-06,
      "loss": 1.3217,
      "step": 10380
    },
    {
      "epoch": 1.6672550750220654,
      "grad_norm": 0.6396415829658508,
      "learning_rate": 8.681855679609256e-06,
      "loss": 1.2925,
      "step": 10390
    },
    {
      "epoch": 1.6688598250822433,
      "grad_norm": 0.3323845863342285,
      "learning_rate": 8.664682614864524e-06,
      "loss": 1.3322,
      "step": 10400
    },
    {
      "epoch": 1.6704645751424216,
      "grad_norm": 0.37678366899490356,
      "learning_rate": 8.647513558719768e-06,
      "loss": 1.2973,
      "step": 10410
    },
    {
      "epoch": 1.6720693252025995,
      "grad_norm": 0.6612173318862915,
      "learning_rate": 8.630348562716193e-06,
      "loss": 1.3613,
      "step": 10420
    },
    {
      "epoch": 1.673674075262778,
      "grad_norm": 0.4672214090824127,
      "learning_rate": 8.613187678382836e-06,
      "loss": 1.4009,
      "step": 10430
    },
    {
      "epoch": 1.6752788253229558,
      "grad_norm": 0.4266873002052307,
      "learning_rate": 8.59603095723637e-06,
      "loss": 1.4341,
      "step": 10440
    },
    {
      "epoch": 1.6768835753831342,
      "grad_norm": 0.4876948595046997,
      "learning_rate": 8.578878450780984e-06,
      "loss": 1.2497,
      "step": 10450
    },
    {
      "epoch": 1.678488325443312,
      "grad_norm": 0.34636998176574707,
      "learning_rate": 8.5617302105082e-06,
      "loss": 1.2475,
      "step": 10460
    },
    {
      "epoch": 1.6800930755034904,
      "grad_norm": 0.45646658539772034,
      "learning_rate": 8.544586287896754e-06,
      "loss": 1.3532,
      "step": 10470
    },
    {
      "epoch": 1.6816978255636683,
      "grad_norm": 0.5559931993484497,
      "learning_rate": 8.527446734412399e-06,
      "loss": 1.416,
      "step": 10480
    },
    {
      "epoch": 1.6833025756238467,
      "grad_norm": 0.6177324056625366,
      "learning_rate": 8.51031160150779e-06,
      "loss": 1.4708,
      "step": 10490
    },
    {
      "epoch": 1.6849073256840246,
      "grad_norm": 0.4872027337551117,
      "learning_rate": 8.4931809406223e-06,
      "loss": 1.3138,
      "step": 10500
    },
    {
      "epoch": 1.686512075744203,
      "grad_norm": 0.6699690222740173,
      "learning_rate": 8.476054803181873e-06,
      "loss": 1.5105,
      "step": 10510
    },
    {
      "epoch": 1.6881168258043808,
      "grad_norm": 0.4383772015571594,
      "learning_rate": 8.458933240598894e-06,
      "loss": 1.2915,
      "step": 10520
    },
    {
      "epoch": 1.6897215758645592,
      "grad_norm": 0.42415520548820496,
      "learning_rate": 8.441816304271988e-06,
      "loss": 1.3777,
      "step": 10530
    },
    {
      "epoch": 1.691326325924737,
      "grad_norm": 0.5191252827644348,
      "learning_rate": 8.424704045585919e-06,
      "loss": 1.2759,
      "step": 10540
    },
    {
      "epoch": 1.6929310759849154,
      "grad_norm": 0.41795119643211365,
      "learning_rate": 8.407596515911383e-06,
      "loss": 1.229,
      "step": 10550
    },
    {
      "epoch": 1.6945358260450933,
      "grad_norm": 0.616546094417572,
      "learning_rate": 8.3904937666049e-06,
      "loss": 1.3616,
      "step": 10560
    },
    {
      "epoch": 1.6961405761052717,
      "grad_norm": 0.4757571816444397,
      "learning_rate": 8.373395849008626e-06,
      "loss": 1.3373,
      "step": 10570
    },
    {
      "epoch": 1.6977453261654496,
      "grad_norm": 0.5635285377502441,
      "learning_rate": 8.356302814450223e-06,
      "loss": 1.3847,
      "step": 10580
    },
    {
      "epoch": 1.699350076225628,
      "grad_norm": 0.48056450486183167,
      "learning_rate": 8.33921471424268e-06,
      "loss": 1.3416,
      "step": 10590
    },
    {
      "epoch": 1.7009548262858059,
      "grad_norm": 0.5515750646591187,
      "learning_rate": 8.322131599684193e-06,
      "loss": 1.3848,
      "step": 10600
    },
    {
      "epoch": 1.7025595763459842,
      "grad_norm": 0.5110709071159363,
      "learning_rate": 8.30505352205797e-06,
      "loss": 1.3409,
      "step": 10610
    },
    {
      "epoch": 1.7041643264061621,
      "grad_norm": 0.5171849727630615,
      "learning_rate": 8.287980532632115e-06,
      "loss": 1.3358,
      "step": 10620
    },
    {
      "epoch": 1.7057690764663405,
      "grad_norm": 0.3165454864501953,
      "learning_rate": 8.270912682659446e-06,
      "loss": 1.3347,
      "step": 10630
    },
    {
      "epoch": 1.7073738265265184,
      "grad_norm": 0.42589443922042847,
      "learning_rate": 8.25385002337736e-06,
      "loss": 1.3777,
      "step": 10640
    },
    {
      "epoch": 1.7089785765866967,
      "grad_norm": 0.5552883744239807,
      "learning_rate": 8.23679260600767e-06,
      "loss": 1.2111,
      "step": 10650
    },
    {
      "epoch": 1.7105833266468746,
      "grad_norm": 0.5080781579017639,
      "learning_rate": 8.219740481756445e-06,
      "loss": 1.373,
      "step": 10660
    },
    {
      "epoch": 1.712188076707053,
      "grad_norm": 0.45718783140182495,
      "learning_rate": 8.202693701813876e-06,
      "loss": 1.1633,
      "step": 10670
    },
    {
      "epoch": 1.7137928267672309,
      "grad_norm": 0.502780556678772,
      "learning_rate": 8.185652317354105e-06,
      "loss": 1.2779,
      "step": 10680
    },
    {
      "epoch": 1.7153975768274092,
      "grad_norm": 0.4601869583129883,
      "learning_rate": 8.168616379535074e-06,
      "loss": 1.4262,
      "step": 10690
    },
    {
      "epoch": 1.7170023268875871,
      "grad_norm": 0.530651867389679,
      "learning_rate": 8.15158593949838e-06,
      "loss": 1.3103,
      "step": 10700
    },
    {
      "epoch": 1.7186070769477655,
      "grad_norm": 0.5618245005607605,
      "learning_rate": 8.134561048369112e-06,
      "loss": 1.2285,
      "step": 10710
    },
    {
      "epoch": 1.7202118270079434,
      "grad_norm": 0.5721569061279297,
      "learning_rate": 8.117541757255702e-06,
      "loss": 1.3778,
      "step": 10720
    },
    {
      "epoch": 1.7218165770681217,
      "grad_norm": 0.6814433336257935,
      "learning_rate": 8.100528117249771e-06,
      "loss": 1.3417,
      "step": 10730
    },
    {
      "epoch": 1.7234213271282997,
      "grad_norm": 0.6132250428199768,
      "learning_rate": 8.083520179425977e-06,
      "loss": 1.2133,
      "step": 10740
    },
    {
      "epoch": 1.725026077188478,
      "grad_norm": 0.5856893658638,
      "learning_rate": 8.066517994841858e-06,
      "loss": 1.1279,
      "step": 10750
    },
    {
      "epoch": 1.726630827248656,
      "grad_norm": 0.42318642139434814,
      "learning_rate": 8.049521614537681e-06,
      "loss": 1.3051,
      "step": 10760
    },
    {
      "epoch": 1.7282355773088343,
      "grad_norm": 0.5308985114097595,
      "learning_rate": 8.032531089536288e-06,
      "loss": 1.4259,
      "step": 10770
    },
    {
      "epoch": 1.7298403273690122,
      "grad_norm": 0.8518968224525452,
      "learning_rate": 8.01554647084295e-06,
      "loss": 1.3305,
      "step": 10780
    },
    {
      "epoch": 1.7314450774291905,
      "grad_norm": 0.49992072582244873,
      "learning_rate": 7.998567809445198e-06,
      "loss": 1.3028,
      "step": 10790
    },
    {
      "epoch": 1.7330498274893684,
      "grad_norm": 0.4143707752227783,
      "learning_rate": 7.981595156312678e-06,
      "loss": 1.3308,
      "step": 10800
    },
    {
      "epoch": 1.7346545775495468,
      "grad_norm": 0.5473443269729614,
      "learning_rate": 7.964628562397017e-06,
      "loss": 1.2825,
      "step": 10810
    },
    {
      "epoch": 1.7362593276097247,
      "grad_norm": 0.6666749119758606,
      "learning_rate": 7.947668078631628e-06,
      "loss": 1.271,
      "step": 10820
    },
    {
      "epoch": 1.737864077669903,
      "grad_norm": 0.4105549156665802,
      "learning_rate": 7.930713755931605e-06,
      "loss": 1.1689,
      "step": 10830
    },
    {
      "epoch": 1.739468827730081,
      "grad_norm": 0.40751364827156067,
      "learning_rate": 7.913765645193523e-06,
      "loss": 1.3475,
      "step": 10840
    },
    {
      "epoch": 1.7410735777902593,
      "grad_norm": 0.5400144457817078,
      "learning_rate": 7.896823797295332e-06,
      "loss": 1.4013,
      "step": 10850
    },
    {
      "epoch": 1.7426783278504372,
      "grad_norm": 0.5191487669944763,
      "learning_rate": 7.879888263096161e-06,
      "loss": 1.2742,
      "step": 10860
    },
    {
      "epoch": 1.7442830779106155,
      "grad_norm": 0.489709734916687,
      "learning_rate": 7.862959093436201e-06,
      "loss": 1.2378,
      "step": 10870
    },
    {
      "epoch": 1.7458878279707934,
      "grad_norm": 0.7321893572807312,
      "learning_rate": 7.846036339136524e-06,
      "loss": 1.3028,
      "step": 10880
    },
    {
      "epoch": 1.7474925780309718,
      "grad_norm": 0.49724358320236206,
      "learning_rate": 7.829120050998957e-06,
      "loss": 1.423,
      "step": 10890
    },
    {
      "epoch": 1.7490973280911497,
      "grad_norm": 0.5561866760253906,
      "learning_rate": 7.812210279805898e-06,
      "loss": 1.3103,
      "step": 10900
    },
    {
      "epoch": 1.750702078151328,
      "grad_norm": 0.4211002290248871,
      "learning_rate": 7.795307076320202e-06,
      "loss": 1.2827,
      "step": 10910
    },
    {
      "epoch": 1.752306828211506,
      "grad_norm": 0.6866394877433777,
      "learning_rate": 7.778410491284987e-06,
      "loss": 1.3347,
      "step": 10920
    },
    {
      "epoch": 1.7539115782716843,
      "grad_norm": 0.4786531925201416,
      "learning_rate": 7.76152057542352e-06,
      "loss": 1.3696,
      "step": 10930
    },
    {
      "epoch": 1.7555163283318622,
      "grad_norm": 0.8172760009765625,
      "learning_rate": 7.744637379439034e-06,
      "loss": 1.2188,
      "step": 10940
    },
    {
      "epoch": 1.7571210783920406,
      "grad_norm": 0.3819113075733185,
      "learning_rate": 7.7277609540146e-06,
      "loss": 1.2037,
      "step": 10950
    },
    {
      "epoch": 1.7587258284522185,
      "grad_norm": 0.35200268030166626,
      "learning_rate": 7.710891349812955e-06,
      "loss": 1.1671,
      "step": 10960
    },
    {
      "epoch": 1.7603305785123968,
      "grad_norm": 0.3769153952598572,
      "learning_rate": 7.694028617476367e-06,
      "loss": 1.2848,
      "step": 10970
    },
    {
      "epoch": 1.7619353285725747,
      "grad_norm": 0.6316832304000854,
      "learning_rate": 7.677172807626466e-06,
      "loss": 1.4366,
      "step": 10980
    },
    {
      "epoch": 1.763540078632753,
      "grad_norm": 0.3961732089519501,
      "learning_rate": 7.660323970864107e-06,
      "loss": 1.3316,
      "step": 10990
    },
    {
      "epoch": 1.765144828692931,
      "grad_norm": 0.6283671855926514,
      "learning_rate": 7.643482157769207e-06,
      "loss": 1.2858,
      "step": 11000
    },
    {
      "epoch": 1.7667495787531093,
      "grad_norm": 0.6095404028892517,
      "learning_rate": 7.626647418900609e-06,
      "loss": 1.4104,
      "step": 11010
    },
    {
      "epoch": 1.7683543288132872,
      "grad_norm": 0.5168508887290955,
      "learning_rate": 7.609819804795902e-06,
      "loss": 1.4231,
      "step": 11020
    },
    {
      "epoch": 1.7699590788734656,
      "grad_norm": 0.47013169527053833,
      "learning_rate": 7.592999365971303e-06,
      "loss": 1.3148,
      "step": 11030
    },
    {
      "epoch": 1.7715638289336435,
      "grad_norm": 0.46109142899513245,
      "learning_rate": 7.576186152921476e-06,
      "loss": 1.2762,
      "step": 11040
    },
    {
      "epoch": 1.7731685789938219,
      "grad_norm": 0.7143042683601379,
      "learning_rate": 7.5593802161194065e-06,
      "loss": 1.2455,
      "step": 11050
    },
    {
      "epoch": 1.7747733290539998,
      "grad_norm": 0.4510422945022583,
      "learning_rate": 7.5425816060162215e-06,
      "loss": 1.2338,
      "step": 11060
    },
    {
      "epoch": 1.776378079114178,
      "grad_norm": 0.6079107522964478,
      "learning_rate": 7.52579037304107e-06,
      "loss": 1.2181,
      "step": 11070
    },
    {
      "epoch": 1.777982829174356,
      "grad_norm": 0.6734358668327332,
      "learning_rate": 7.509006567600941e-06,
      "loss": 1.3018,
      "step": 11080
    },
    {
      "epoch": 1.7795875792345344,
      "grad_norm": 0.41367560625076294,
      "learning_rate": 7.49223024008053e-06,
      "loss": 1.2004,
      "step": 11090
    },
    {
      "epoch": 1.7811923292947123,
      "grad_norm": 0.5479249954223633,
      "learning_rate": 7.475461440842092e-06,
      "loss": 1.4317,
      "step": 11100
    },
    {
      "epoch": 1.7827970793548906,
      "grad_norm": 0.8279992341995239,
      "learning_rate": 7.458700220225268e-06,
      "loss": 1.2973,
      "step": 11110
    },
    {
      "epoch": 1.7844018294150685,
      "grad_norm": 0.5492921471595764,
      "learning_rate": 7.441946628546965e-06,
      "loss": 1.3057,
      "step": 11120
    },
    {
      "epoch": 1.7860065794752469,
      "grad_norm": 0.525579571723938,
      "learning_rate": 7.425200716101169e-06,
      "loss": 1.1552,
      "step": 11130
    },
    {
      "epoch": 1.7876113295354248,
      "grad_norm": 0.5571953654289246,
      "learning_rate": 7.408462533158831e-06,
      "loss": 1.3348,
      "step": 11140
    },
    {
      "epoch": 1.7892160795956031,
      "grad_norm": 0.44689229130744934,
      "learning_rate": 7.391732129967683e-06,
      "loss": 1.214,
      "step": 11150
    },
    {
      "epoch": 1.790820829655781,
      "grad_norm": 0.32095175981521606,
      "learning_rate": 7.3750095567521196e-06,
      "loss": 1.2817,
      "step": 11160
    },
    {
      "epoch": 1.7924255797159594,
      "grad_norm": 0.6287011504173279,
      "learning_rate": 7.3582948637130095e-06,
      "loss": 1.2687,
      "step": 11170
    },
    {
      "epoch": 1.7940303297761373,
      "grad_norm": 0.4316258728504181,
      "learning_rate": 7.341588101027584e-06,
      "loss": 1.2326,
      "step": 11180
    },
    {
      "epoch": 1.7956350798363157,
      "grad_norm": 0.36761370301246643,
      "learning_rate": 7.324889318849251e-06,
      "loss": 1.393,
      "step": 11190
    },
    {
      "epoch": 1.7972398298964936,
      "grad_norm": 0.3727651536464691,
      "learning_rate": 7.308198567307477e-06,
      "loss": 1.2269,
      "step": 11200
    },
    {
      "epoch": 1.798844579956672,
      "grad_norm": 0.5051815509796143,
      "learning_rate": 7.291515896507606e-06,
      "loss": 1.2457,
      "step": 11210
    },
    {
      "epoch": 1.8004493300168498,
      "grad_norm": 0.4418484568595886,
      "learning_rate": 7.274841356530739e-06,
      "loss": 1.2191,
      "step": 11220
    },
    {
      "epoch": 1.8020540800770282,
      "grad_norm": 0.4545564651489258,
      "learning_rate": 7.258174997433549e-06,
      "loss": 1.1564,
      "step": 11230
    },
    {
      "epoch": 1.803658830137206,
      "grad_norm": 0.6294673085212708,
      "learning_rate": 7.241516869248174e-06,
      "loss": 1.3425,
      "step": 11240
    },
    {
      "epoch": 1.8052635801973844,
      "grad_norm": 0.4129815101623535,
      "learning_rate": 7.224867021982018e-06,
      "loss": 1.2557,
      "step": 11250
    },
    {
      "epoch": 1.8068683302575623,
      "grad_norm": 0.371139794588089,
      "learning_rate": 7.208225505617648e-06,
      "loss": 1.3069,
      "step": 11260
    },
    {
      "epoch": 1.8084730803177407,
      "grad_norm": 0.48662349581718445,
      "learning_rate": 7.191592370112604e-06,
      "loss": 1.1918,
      "step": 11270
    },
    {
      "epoch": 1.8100778303779186,
      "grad_norm": 0.6558789014816284,
      "learning_rate": 7.174967665399282e-06,
      "loss": 1.1918,
      "step": 11280
    },
    {
      "epoch": 1.8116825804380967,
      "grad_norm": 0.4134206771850586,
      "learning_rate": 7.158351441384752e-06,
      "loss": 1.2686,
      "step": 11290
    },
    {
      "epoch": 1.8132873304982748,
      "grad_norm": 0.6505715847015381,
      "learning_rate": 7.141743747950647e-06,
      "loss": 1.3168,
      "step": 11300
    },
    {
      "epoch": 1.814892080558453,
      "grad_norm": 0.5894173383712769,
      "learning_rate": 7.125144634952965e-06,
      "loss": 1.2122,
      "step": 11310
    },
    {
      "epoch": 1.816496830618631,
      "grad_norm": 0.6591395139694214,
      "learning_rate": 7.108554152221969e-06,
      "loss": 1.2684,
      "step": 11320
    },
    {
      "epoch": 1.8181015806788092,
      "grad_norm": 0.5875928401947021,
      "learning_rate": 7.091972349562004e-06,
      "loss": 1.3269,
      "step": 11330
    },
    {
      "epoch": 1.8197063307389874,
      "grad_norm": 0.739879846572876,
      "learning_rate": 7.075399276751356e-06,
      "loss": 1.5329,
      "step": 11340
    },
    {
      "epoch": 1.8213110807991655,
      "grad_norm": 0.358539342880249,
      "learning_rate": 7.058834983542109e-06,
      "loss": 1.296,
      "step": 11350
    },
    {
      "epoch": 1.8229158308593436,
      "grad_norm": 0.5323147773742676,
      "learning_rate": 7.04227951965998e-06,
      "loss": 1.2891,
      "step": 11360
    },
    {
      "epoch": 1.8245205809195217,
      "grad_norm": 0.5676724314689636,
      "learning_rate": 7.025732934804202e-06,
      "loss": 1.3604,
      "step": 11370
    },
    {
      "epoch": 1.8261253309796999,
      "grad_norm": 0.5993578433990479,
      "learning_rate": 7.009195278647325e-06,
      "loss": 1.3605,
      "step": 11380
    },
    {
      "epoch": 1.827730081039878,
      "grad_norm": 0.4432379901409149,
      "learning_rate": 6.992666600835125e-06,
      "loss": 1.4691,
      "step": 11390
    },
    {
      "epoch": 1.8293348311000561,
      "grad_norm": 0.45297855138778687,
      "learning_rate": 6.976146950986398e-06,
      "loss": 1.2448,
      "step": 11400
    },
    {
      "epoch": 1.8309395811602343,
      "grad_norm": 0.4373244643211365,
      "learning_rate": 6.95963637869286e-06,
      "loss": 1.1384,
      "step": 11410
    },
    {
      "epoch": 1.8325443312204124,
      "grad_norm": 0.48302578926086426,
      "learning_rate": 6.94313493351896e-06,
      "loss": 1.312,
      "step": 11420
    },
    {
      "epoch": 1.8341490812805905,
      "grad_norm": 0.5795308947563171,
      "learning_rate": 6.92664266500176e-06,
      "loss": 1.2456,
      "step": 11430
    },
    {
      "epoch": 1.8357538313407686,
      "grad_norm": 0.5570203065872192,
      "learning_rate": 6.9101596226507625e-06,
      "loss": 1.2277,
      "step": 11440
    },
    {
      "epoch": 1.8373585814009468,
      "grad_norm": 0.4106871485710144,
      "learning_rate": 6.893685855947786e-06,
      "loss": 1.2248,
      "step": 11450
    },
    {
      "epoch": 1.838963331461125,
      "grad_norm": 0.3800872266292572,
      "learning_rate": 6.877221414346789e-06,
      "loss": 1.2717,
      "step": 11460
    },
    {
      "epoch": 1.840568081521303,
      "grad_norm": 0.49055901169776917,
      "learning_rate": 6.8607663472737505e-06,
      "loss": 1.225,
      "step": 11470
    },
    {
      "epoch": 1.8421728315814812,
      "grad_norm": 0.5742685198783875,
      "learning_rate": 6.844320704126494e-06,
      "loss": 1.285,
      "step": 11480
    },
    {
      "epoch": 1.8437775816416593,
      "grad_norm": 0.7320507168769836,
      "learning_rate": 6.827884534274567e-06,
      "loss": 1.3414,
      "step": 11490
    },
    {
      "epoch": 1.8453823317018374,
      "grad_norm": 0.2874715030193329,
      "learning_rate": 6.811457887059063e-06,
      "loss": 1.4825,
      "step": 11500
    },
    {
      "epoch": 1.8469870817620155,
      "grad_norm": 0.5561821460723877,
      "learning_rate": 6.795040811792504e-06,
      "loss": 1.3335,
      "step": 11510
    },
    {
      "epoch": 1.8485918318221937,
      "grad_norm": 0.5846020579338074,
      "learning_rate": 6.7786333577586615e-06,
      "loss": 1.2156,
      "step": 11520
    },
    {
      "epoch": 1.8501965818823718,
      "grad_norm": 0.5528136491775513,
      "learning_rate": 6.762235574212439e-06,
      "loss": 1.1673,
      "step": 11530
    },
    {
      "epoch": 1.85180133194255,
      "grad_norm": 0.3541504740715027,
      "learning_rate": 6.745847510379695e-06,
      "loss": 1.4387,
      "step": 11540
    },
    {
      "epoch": 1.853406082002728,
      "grad_norm": 0.34789222478866577,
      "learning_rate": 6.729469215457127e-06,
      "loss": 1.372,
      "step": 11550
    },
    {
      "epoch": 1.8550108320629062,
      "grad_norm": 0.5380761623382568,
      "learning_rate": 6.713100738612086e-06,
      "loss": 1.1702,
      "step": 11560
    },
    {
      "epoch": 1.8566155821230843,
      "grad_norm": 0.5303881764411926,
      "learning_rate": 6.696742128982469e-06,
      "loss": 1.2164,
      "step": 11570
    },
    {
      "epoch": 1.8582203321832624,
      "grad_norm": 0.5854052901268005,
      "learning_rate": 6.680393435676536e-06,
      "loss": 1.4423,
      "step": 11580
    },
    {
      "epoch": 1.8598250822434406,
      "grad_norm": 0.3337753415107727,
      "learning_rate": 6.664054707772789e-06,
      "loss": 1.3979,
      "step": 11590
    },
    {
      "epoch": 1.8614298323036187,
      "grad_norm": 0.7466180920600891,
      "learning_rate": 6.647725994319806e-06,
      "loss": 1.3125,
      "step": 11600
    },
    {
      "epoch": 1.8630345823637968,
      "grad_norm": 0.34337541460990906,
      "learning_rate": 6.631407344336111e-06,
      "loss": 1.2354,
      "step": 11610
    },
    {
      "epoch": 1.864639332423975,
      "grad_norm": 0.4028712809085846,
      "learning_rate": 6.615098806810007e-06,
      "loss": 1.2602,
      "step": 11620
    },
    {
      "epoch": 1.866244082484153,
      "grad_norm": 0.6535418629646301,
      "learning_rate": 6.5988004306994505e-06,
      "loss": 1.3773,
      "step": 11630
    },
    {
      "epoch": 1.8678488325443312,
      "grad_norm": 0.4747299253940582,
      "learning_rate": 6.582512264931886e-06,
      "loss": 1.2729,
      "step": 11640
    },
    {
      "epoch": 1.8694535826045093,
      "grad_norm": 0.5783270001411438,
      "learning_rate": 6.566234358404102e-06,
      "loss": 1.3973,
      "step": 11650
    },
    {
      "epoch": 1.8710583326646875,
      "grad_norm": 0.4734252095222473,
      "learning_rate": 6.549966759982108e-06,
      "loss": 1.2882,
      "step": 11660
    },
    {
      "epoch": 1.8726630827248656,
      "grad_norm": 0.4707244336605072,
      "learning_rate": 6.533709518500946e-06,
      "loss": 1.4396,
      "step": 11670
    },
    {
      "epoch": 1.8742678327850437,
      "grad_norm": 0.4928357005119324,
      "learning_rate": 6.517462682764583e-06,
      "loss": 1.0749,
      "step": 11680
    },
    {
      "epoch": 1.8758725828452218,
      "grad_norm": 0.40285977721214294,
      "learning_rate": 6.50122630154574e-06,
      "loss": 1.2805,
      "step": 11690
    },
    {
      "epoch": 1.8774773329054,
      "grad_norm": 0.4155314266681671,
      "learning_rate": 6.485000423585759e-06,
      "loss": 1.2612,
      "step": 11700
    },
    {
      "epoch": 1.879082082965578,
      "grad_norm": 0.44745147228240967,
      "learning_rate": 6.468785097594442e-06,
      "loss": 1.2906,
      "step": 11710
    },
    {
      "epoch": 1.8806868330257562,
      "grad_norm": 0.49821171164512634,
      "learning_rate": 6.452580372249929e-06,
      "loss": 1.1497,
      "step": 11720
    },
    {
      "epoch": 1.8822915830859344,
      "grad_norm": 0.5866856575012207,
      "learning_rate": 6.43638629619852e-06,
      "loss": 1.405,
      "step": 11730
    },
    {
      "epoch": 1.8838963331461125,
      "grad_norm": 0.5094614624977112,
      "learning_rate": 6.420202918054563e-06,
      "loss": 1.1851,
      "step": 11740
    },
    {
      "epoch": 1.8855010832062906,
      "grad_norm": 0.5514557957649231,
      "learning_rate": 6.404030286400274e-06,
      "loss": 1.2924,
      "step": 11750
    },
    {
      "epoch": 1.8871058332664687,
      "grad_norm": 0.5219709277153015,
      "learning_rate": 6.387868449785626e-06,
      "loss": 1.2223,
      "step": 11760
    },
    {
      "epoch": 1.8887105833266469,
      "grad_norm": 0.507422924041748,
      "learning_rate": 6.3717174567281656e-06,
      "loss": 1.3775,
      "step": 11770
    },
    {
      "epoch": 1.890315333386825,
      "grad_norm": 0.40702423453330994,
      "learning_rate": 6.355577355712911e-06,
      "loss": 1.2125,
      "step": 11780
    },
    {
      "epoch": 1.8919200834470031,
      "grad_norm": 0.7126702070236206,
      "learning_rate": 6.339448195192157e-06,
      "loss": 1.3784,
      "step": 11790
    },
    {
      "epoch": 1.8935248335071813,
      "grad_norm": 0.52977454662323,
      "learning_rate": 6.323330023585379e-06,
      "loss": 1.3971,
      "step": 11800
    },
    {
      "epoch": 1.8951295835673594,
      "grad_norm": 0.43204614520072937,
      "learning_rate": 6.307222889279041e-06,
      "loss": 1.1834,
      "step": 11810
    },
    {
      "epoch": 1.8967343336275375,
      "grad_norm": 0.5170060396194458,
      "learning_rate": 6.291126840626498e-06,
      "loss": 1.2533,
      "step": 11820
    },
    {
      "epoch": 1.8983390836877156,
      "grad_norm": 0.5977076888084412,
      "learning_rate": 6.2750419259478e-06,
      "loss": 1.2744,
      "step": 11830
    },
    {
      "epoch": 1.8999438337478938,
      "grad_norm": 0.7378869652748108,
      "learning_rate": 6.258968193529598e-06,
      "loss": 1.2861,
      "step": 11840
    },
    {
      "epoch": 1.901548583808072,
      "grad_norm": 0.39628249406814575,
      "learning_rate": 6.242905691624952e-06,
      "loss": 1.3821,
      "step": 11850
    },
    {
      "epoch": 1.90315333386825,
      "grad_norm": 0.4712900221347809,
      "learning_rate": 6.226854468453227e-06,
      "loss": 1.2107,
      "step": 11860
    },
    {
      "epoch": 1.9047580839284282,
      "grad_norm": 0.8376707434654236,
      "learning_rate": 6.210814572199912e-06,
      "loss": 1.2916,
      "step": 11870
    },
    {
      "epoch": 1.9063628339886063,
      "grad_norm": 0.589645504951477,
      "learning_rate": 6.19478605101651e-06,
      "loss": 1.2471,
      "step": 11880
    },
    {
      "epoch": 1.9079675840487844,
      "grad_norm": 0.5634622573852539,
      "learning_rate": 6.17876895302036e-06,
      "loss": 1.1044,
      "step": 11890
    },
    {
      "epoch": 1.9095723341089625,
      "grad_norm": 0.6380563974380493,
      "learning_rate": 6.162763326294525e-06,
      "loss": 1.1816,
      "step": 11900
    },
    {
      "epoch": 1.9111770841691407,
      "grad_norm": 0.537203311920166,
      "learning_rate": 6.146769218887615e-06,
      "loss": 1.2895,
      "step": 11910
    },
    {
      "epoch": 1.9127818342293188,
      "grad_norm": 0.7563451528549194,
      "learning_rate": 6.130786678813669e-06,
      "loss": 1.4434,
      "step": 11920
    },
    {
      "epoch": 1.914386584289497,
      "grad_norm": 0.39798450469970703,
      "learning_rate": 6.114815754052002e-06,
      "loss": 1.1186,
      "step": 11930
    },
    {
      "epoch": 1.915991334349675,
      "grad_norm": 0.5859978199005127,
      "learning_rate": 6.0988564925470565e-06,
      "loss": 1.2253,
      "step": 11940
    },
    {
      "epoch": 1.9175960844098532,
      "grad_norm": 0.5101495981216431,
      "learning_rate": 6.082908942208261e-06,
      "loss": 1.3134,
      "step": 11950
    },
    {
      "epoch": 1.9192008344700313,
      "grad_norm": 0.6529114842414856,
      "learning_rate": 6.0669731509098895e-06,
      "loss": 1.3555,
      "step": 11960
    },
    {
      "epoch": 1.9208055845302094,
      "grad_norm": 0.7944371700286865,
      "learning_rate": 6.051049166490917e-06,
      "loss": 1.3724,
      "step": 11970
    },
    {
      "epoch": 1.9224103345903876,
      "grad_norm": 0.6208010315895081,
      "learning_rate": 6.03513703675487e-06,
      "loss": 1.3231,
      "step": 11980
    },
    {
      "epoch": 1.9240150846505657,
      "grad_norm": 0.38422515988349915,
      "learning_rate": 6.019236809469693e-06,
      "loss": 1.2217,
      "step": 11990
    },
    {
      "epoch": 1.9256198347107438,
      "grad_norm": 0.3641115725040436,
      "learning_rate": 6.0033485323675946e-06,
      "loss": 1.3817,
      "step": 12000
    },
    {
      "epoch": 1.927224584770922,
      "grad_norm": 0.5047890543937683,
      "learning_rate": 5.987472253144911e-06,
      "loss": 1.4024,
      "step": 12010
    },
    {
      "epoch": 1.9288293348311,
      "grad_norm": 0.5633889436721802,
      "learning_rate": 5.971608019461961e-06,
      "loss": 1.1811,
      "step": 12020
    },
    {
      "epoch": 1.9304340848912782,
      "grad_norm": 0.5705041885375977,
      "learning_rate": 5.955755878942907e-06,
      "loss": 1.3279,
      "step": 12030
    },
    {
      "epoch": 1.9320388349514563,
      "grad_norm": 0.9632352590560913,
      "learning_rate": 5.939915879175597e-06,
      "loss": 1.4205,
      "step": 12040
    },
    {
      "epoch": 1.9336435850116345,
      "grad_norm": 0.4464355707168579,
      "learning_rate": 5.924088067711449e-06,
      "loss": 1.1164,
      "step": 12050
    },
    {
      "epoch": 1.9352483350718126,
      "grad_norm": 0.6112291812896729,
      "learning_rate": 5.908272492065272e-06,
      "loss": 1.2076,
      "step": 12060
    },
    {
      "epoch": 1.9368530851319907,
      "grad_norm": 0.45659881830215454,
      "learning_rate": 5.892469199715163e-06,
      "loss": 1.3557,
      "step": 12070
    },
    {
      "epoch": 1.9384578351921689,
      "grad_norm": 0.38872668147087097,
      "learning_rate": 5.8766782381023275e-06,
      "loss": 1.1482,
      "step": 12080
    },
    {
      "epoch": 1.940062585252347,
      "grad_norm": 0.48537006974220276,
      "learning_rate": 5.860899654630972e-06,
      "loss": 1.2655,
      "step": 12090
    },
    {
      "epoch": 1.9416673353125251,
      "grad_norm": 0.5485859513282776,
      "learning_rate": 5.845133496668123e-06,
      "loss": 1.4044,
      "step": 12100
    },
    {
      "epoch": 1.9432720853727032,
      "grad_norm": 0.49417558312416077,
      "learning_rate": 5.829379811543529e-06,
      "loss": 1.2109,
      "step": 12110
    },
    {
      "epoch": 1.9448768354328814,
      "grad_norm": 0.4521615505218506,
      "learning_rate": 5.813638646549473e-06,
      "loss": 1.1542,
      "step": 12120
    },
    {
      "epoch": 1.9464815854930595,
      "grad_norm": 0.41364559531211853,
      "learning_rate": 5.797910048940673e-06,
      "loss": 1.2462,
      "step": 12130
    },
    {
      "epoch": 1.9480863355532376,
      "grad_norm": 0.5391426086425781,
      "learning_rate": 5.782194065934101e-06,
      "loss": 1.2402,
      "step": 12140
    },
    {
      "epoch": 1.9496910856134158,
      "grad_norm": 0.40889647603034973,
      "learning_rate": 5.766490744708877e-06,
      "loss": 1.3727,
      "step": 12150
    },
    {
      "epoch": 1.9512958356735939,
      "grad_norm": 0.6610537171363831,
      "learning_rate": 5.750800132406096e-06,
      "loss": 1.0631,
      "step": 12160
    },
    {
      "epoch": 1.952900585733772,
      "grad_norm": 0.5043777227401733,
      "learning_rate": 5.735122276128717e-06,
      "loss": 1.2527,
      "step": 12170
    },
    {
      "epoch": 1.9545053357939501,
      "grad_norm": 0.6659494638442993,
      "learning_rate": 5.7194572229413866e-06,
      "loss": 1.1272,
      "step": 12180
    },
    {
      "epoch": 1.9561100858541283,
      "grad_norm": 0.743131697177887,
      "learning_rate": 5.7038050198703365e-06,
      "loss": 1.2838,
      "step": 12190
    },
    {
      "epoch": 1.9577148359143064,
      "grad_norm": 0.4084281623363495,
      "learning_rate": 5.688165713903204e-06,
      "loss": 1.3122,
      "step": 12200
    },
    {
      "epoch": 1.9593195859744845,
      "grad_norm": 0.6288772821426392,
      "learning_rate": 5.6725393519889275e-06,
      "loss": 1.2311,
      "step": 12210
    },
    {
      "epoch": 1.9609243360346627,
      "grad_norm": 0.6304981112480164,
      "learning_rate": 5.6569259810375686e-06,
      "loss": 1.251,
      "step": 12220
    },
    {
      "epoch": 1.9625290860948408,
      "grad_norm": 0.6155768036842346,
      "learning_rate": 5.641325647920208e-06,
      "loss": 1.3336,
      "step": 12230
    },
    {
      "epoch": 1.964133836155019,
      "grad_norm": 0.5068325400352478,
      "learning_rate": 5.6257383994687745e-06,
      "loss": 1.3921,
      "step": 12240
    },
    {
      "epoch": 1.965738586215197,
      "grad_norm": 0.4182339012622833,
      "learning_rate": 5.610164282475925e-06,
      "loss": 1.2467,
      "step": 12250
    },
    {
      "epoch": 1.9673433362753752,
      "grad_norm": 0.6401615738868713,
      "learning_rate": 5.594603343694889e-06,
      "loss": 1.4289,
      "step": 12260
    },
    {
      "epoch": 1.968948086335553,
      "grad_norm": 0.6725279092788696,
      "learning_rate": 5.579055629839344e-06,
      "loss": 1.205,
      "step": 12270
    },
    {
      "epoch": 1.9705528363957314,
      "grad_norm": 0.5423653721809387,
      "learning_rate": 5.563521187583254e-06,
      "loss": 1.2668,
      "step": 12280
    },
    {
      "epoch": 1.9721575864559093,
      "grad_norm": 0.5271467566490173,
      "learning_rate": 5.548000063560757e-06,
      "loss": 1.2236,
      "step": 12290
    },
    {
      "epoch": 1.9737623365160877,
      "grad_norm": 0.36739709973335266,
      "learning_rate": 5.532492304365995e-06,
      "loss": 1.3192,
      "step": 12300
    },
    {
      "epoch": 1.9753670865762656,
      "grad_norm": 0.608930230140686,
      "learning_rate": 5.516997956553003e-06,
      "loss": 1.3134,
      "step": 12310
    },
    {
      "epoch": 1.976971836636444,
      "grad_norm": 0.5082205533981323,
      "learning_rate": 5.501517066635541e-06,
      "loss": 1.1858,
      "step": 12320
    },
    {
      "epoch": 1.9785765866966218,
      "grad_norm": 0.3333296477794647,
      "learning_rate": 5.486049681086984e-06,
      "loss": 1.2533,
      "step": 12330
    },
    {
      "epoch": 1.9801813367568002,
      "grad_norm": 0.4584592878818512,
      "learning_rate": 5.470595846340152e-06,
      "loss": 1.2911,
      "step": 12340
    },
    {
      "epoch": 1.981786086816978,
      "grad_norm": 0.4483330249786377,
      "learning_rate": 5.455155608787195e-06,
      "loss": 1.2942,
      "step": 12350
    },
    {
      "epoch": 1.9833908368771564,
      "grad_norm": 0.6970025897026062,
      "learning_rate": 5.439729014779447e-06,
      "loss": 1.2964,
      "step": 12360
    },
    {
      "epoch": 1.9849955869373344,
      "grad_norm": 0.37287676334381104,
      "learning_rate": 5.424316110627272e-06,
      "loss": 1.2598,
      "step": 12370
    },
    {
      "epoch": 1.9866003369975127,
      "grad_norm": 0.4495922327041626,
      "learning_rate": 5.408916942599953e-06,
      "loss": 1.2951,
      "step": 12380
    },
    {
      "epoch": 1.9882050870576906,
      "grad_norm": 0.6824597120285034,
      "learning_rate": 5.3935315569255205e-06,
      "loss": 1.3447,
      "step": 12390
    },
    {
      "epoch": 1.989809837117869,
      "grad_norm": 0.42082539200782776,
      "learning_rate": 5.378159999790648e-06,
      "loss": 1.2248,
      "step": 12400
    },
    {
      "epoch": 1.9914145871780469,
      "grad_norm": 0.5878294110298157,
      "learning_rate": 5.3628023173404805e-06,
      "loss": 1.3231,
      "step": 12410
    },
    {
      "epoch": 1.9930193372382252,
      "grad_norm": 0.5531538128852844,
      "learning_rate": 5.347458555678524e-06,
      "loss": 1.2489,
      "step": 12420
    },
    {
      "epoch": 1.9946240872984031,
      "grad_norm": 0.45372524857521057,
      "learning_rate": 5.332128760866483e-06,
      "loss": 1.2782,
      "step": 12430
    },
    {
      "epoch": 1.9962288373585815,
      "grad_norm": 0.3124426603317261,
      "learning_rate": 5.316812978924146e-06,
      "loss": 1.2618,
      "step": 12440
    },
    {
      "epoch": 1.9978335874187594,
      "grad_norm": 0.4132457375526428,
      "learning_rate": 5.301511255829221e-06,
      "loss": 1.2182,
      "step": 12450
    },
    {
      "epoch": 1.9994383374789377,
      "grad_norm": 0.5237779021263123,
      "learning_rate": 5.2862236375172275e-06,
      "loss": 1.2882,
      "step": 12460
    }
  ],
  "logging_steps": 10,
  "max_steps": 18693,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.6888813516735488e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
