{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 2500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004,
      "grad_norm": 0.27177536487579346,
      "learning_rate": 6.666666666666667e-06,
      "loss": 1.6939,
      "step": 10
    },
    {
      "epoch": 0.008,
      "grad_norm": 0.3818785846233368,
      "learning_rate": 1.3333333333333333e-05,
      "loss": 1.4816,
      "step": 20
    },
    {
      "epoch": 0.012,
      "grad_norm": 0.22772298753261566,
      "learning_rate": 2e-05,
      "loss": 1.5766,
      "step": 30
    },
    {
      "epoch": 0.016,
      "grad_norm": 0.4213930666446686,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 1.5678,
      "step": 40
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.47981420159339905,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 1.6405,
      "step": 50
    },
    {
      "epoch": 0.024,
      "grad_norm": 0.25610190629959106,
      "learning_rate": 4e-05,
      "loss": 1.5137,
      "step": 60
    },
    {
      "epoch": 0.028,
      "grad_norm": 0.27451273798942566,
      "learning_rate": 4.666666666666667e-05,
      "loss": 1.4014,
      "step": 70
    },
    {
      "epoch": 0.032,
      "grad_norm": 0.16767928004264832,
      "learning_rate": 4.999947552503497e-05,
      "loss": 1.4413,
      "step": 80
    },
    {
      "epoch": 0.036,
      "grad_norm": 0.1825791448354721,
      "learning_rate": 4.999527985734932e-05,
      "loss": 1.4353,
      "step": 90
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.3041122853755951,
      "learning_rate": 4.998688922613788e-05,
      "loss": 1.3509,
      "step": 100
    },
    {
      "epoch": 0.044,
      "grad_norm": 0.2771057188510895,
      "learning_rate": 4.99743050396022e-05,
      "loss": 1.3441,
      "step": 110
    },
    {
      "epoch": 0.048,
      "grad_norm": 0.24629250168800354,
      "learning_rate": 4.995752940974918e-05,
      "loss": 1.3452,
      "step": 120
    },
    {
      "epoch": 0.052,
      "grad_norm": 0.2657657265663147,
      "learning_rate": 4.993656515203662e-05,
      "loss": 1.2903,
      "step": 130
    },
    {
      "epoch": 0.056,
      "grad_norm": 0.1957617551088333,
      "learning_rate": 4.991141578490066e-05,
      "loss": 1.1604,
      "step": 140
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.2528464198112488,
      "learning_rate": 4.988208552916535e-05,
      "loss": 1.3106,
      "step": 150
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.2216881513595581,
      "learning_rate": 4.98485793073342e-05,
      "loss": 1.1814,
      "step": 160
    },
    {
      "epoch": 0.068,
      "grad_norm": 0.20330893993377686,
      "learning_rate": 4.981090274276406e-05,
      "loss": 1.1801,
      "step": 170
    },
    {
      "epoch": 0.072,
      "grad_norm": 0.2787298560142517,
      "learning_rate": 4.976906215872138e-05,
      "loss": 1.2426,
      "step": 180
    },
    {
      "epoch": 0.076,
      "grad_norm": 0.19418348371982574,
      "learning_rate": 4.972306457732091e-05,
      "loss": 1.2134,
      "step": 190
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.2378280907869339,
      "learning_rate": 4.967291771834727e-05,
      "loss": 1.242,
      "step": 200
    },
    {
      "epoch": 0.084,
      "grad_norm": 0.2275894731283188,
      "learning_rate": 4.9618629997959235e-05,
      "loss": 1.1301,
      "step": 210
    },
    {
      "epoch": 0.088,
      "grad_norm": 0.19401583075523376,
      "learning_rate": 4.956021052727731e-05,
      "loss": 1.2157,
      "step": 220
    },
    {
      "epoch": 0.092,
      "grad_norm": 0.19474568963050842,
      "learning_rate": 4.949766911085461e-05,
      "loss": 1.1582,
      "step": 230
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.21102893352508545,
      "learning_rate": 4.943101624503132e-05,
      "loss": 1.2403,
      "step": 240
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.2520506978034973,
      "learning_rate": 4.936026311617316e-05,
      "loss": 1.2233,
      "step": 250
    },
    {
      "epoch": 0.104,
      "grad_norm": 0.21648573875427246,
      "learning_rate": 4.928542159879386e-05,
      "loss": 1.1142,
      "step": 260
    },
    {
      "epoch": 0.108,
      "grad_norm": 0.34347930550575256,
      "learning_rate": 4.92065042535624e-05,
      "loss": 1.0985,
      "step": 270
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.30133816599845886,
      "learning_rate": 4.912352432519484e-05,
      "loss": 1.1852,
      "step": 280
    },
    {
      "epoch": 0.116,
      "grad_norm": 0.26407337188720703,
      "learning_rate": 4.90364957402315e-05,
      "loss": 1.1366,
      "step": 290
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.31515562534332275,
      "learning_rate": 4.894543310469968e-05,
      "loss": 1.1423,
      "step": 300
    },
    {
      "epoch": 0.124,
      "grad_norm": 0.21556760370731354,
      "learning_rate": 4.885035170166228e-05,
      "loss": 1.0483,
      "step": 310
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.3008078932762146,
      "learning_rate": 4.87512674886529e-05,
      "loss": 1.1752,
      "step": 320
    },
    {
      "epoch": 0.132,
      "grad_norm": 0.222821444272995,
      "learning_rate": 4.8648197094997616e-05,
      "loss": 1.1894,
      "step": 330
    },
    {
      "epoch": 0.136,
      "grad_norm": 0.31937819719314575,
      "learning_rate": 4.854115781902414e-05,
      "loss": 1.1274,
      "step": 340
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.23936820030212402,
      "learning_rate": 4.8430167625158595e-05,
      "loss": 1.1384,
      "step": 350
    },
    {
      "epoch": 0.144,
      "grad_norm": 0.16530609130859375,
      "learning_rate": 4.8315245140910556e-05,
      "loss": 1.1424,
      "step": 360
    },
    {
      "epoch": 0.148,
      "grad_norm": 0.2619812488555908,
      "learning_rate": 4.819640965374681e-05,
      "loss": 1.157,
      "step": 370
    },
    {
      "epoch": 0.152,
      "grad_norm": 0.2097531408071518,
      "learning_rate": 4.80736811078543e-05,
      "loss": 1.2123,
      "step": 380
    },
    {
      "epoch": 0.156,
      "grad_norm": 0.20912957191467285,
      "learning_rate": 4.794708010079289e-05,
      "loss": 1.106,
      "step": 390
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.21262823045253754,
      "learning_rate": 4.781662788003851e-05,
      "loss": 1.0795,
      "step": 400
    },
    {
      "epoch": 0.164,
      "grad_norm": 0.26737797260284424,
      "learning_rate": 4.768234633941716e-05,
      "loss": 1.1125,
      "step": 410
    },
    {
      "epoch": 0.168,
      "grad_norm": 0.2532369792461395,
      "learning_rate": 4.7544258015430463e-05,
      "loss": 1.1625,
      "step": 420
    },
    {
      "epoch": 0.172,
      "grad_norm": 0.2835770845413208,
      "learning_rate": 4.740238608347336e-05,
      "loss": 1.1302,
      "step": 430
    },
    {
      "epoch": 0.176,
      "grad_norm": 0.18970386683940887,
      "learning_rate": 4.72567543539446e-05,
      "loss": 1.2279,
      "step": 440
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.28140342235565186,
      "learning_rate": 4.710738726825059e-05,
      "loss": 1.1729,
      "step": 450
    },
    {
      "epoch": 0.184,
      "grad_norm": 0.31961628794670105,
      "learning_rate": 4.695430989470343e-05,
      "loss": 1.1253,
      "step": 460
    },
    {
      "epoch": 0.188,
      "grad_norm": 0.29139986634254456,
      "learning_rate": 4.679754792431368e-05,
      "loss": 1.1184,
      "step": 470
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.4169776737689972,
      "learning_rate": 4.663712766647862e-05,
      "loss": 1.1013,
      "step": 480
    },
    {
      "epoch": 0.196,
      "grad_norm": 0.2674017548561096,
      "learning_rate": 4.647307604456674e-05,
      "loss": 1.084,
      "step": 490
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.2771216034889221,
      "learning_rate": 4.630542059139924e-05,
      "loss": 1.0572,
      "step": 500
    },
    {
      "epoch": 0.204,
      "grad_norm": 0.32692205905914307,
      "learning_rate": 4.613418944462907e-05,
      "loss": 1.1486,
      "step": 510
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.2505573332309723,
      "learning_rate": 4.595941134201871e-05,
      "loss": 1.1786,
      "step": 520
    },
    {
      "epoch": 0.212,
      "grad_norm": 0.31922250986099243,
      "learning_rate": 4.578111561661702e-05,
      "loss": 1.0476,
      "step": 530
    },
    {
      "epoch": 0.216,
      "grad_norm": 0.26551496982574463,
      "learning_rate": 4.5599332191836316e-05,
      "loss": 1.1302,
      "step": 540
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.23947811126708984,
      "learning_rate": 4.541409157643027e-05,
      "loss": 1.1156,
      "step": 550
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.2848946452140808,
      "learning_rate": 4.522542485937369e-05,
      "loss": 1.0954,
      "step": 560
    },
    {
      "epoch": 0.228,
      "grad_norm": 0.3319222331047058,
      "learning_rate": 4.503336370464476e-05,
      "loss": 1.1359,
      "step": 570
    },
    {
      "epoch": 0.232,
      "grad_norm": 0.32594794034957886,
      "learning_rate": 4.4837940345910925e-05,
      "loss": 1.1259,
      "step": 580
    },
    {
      "epoch": 0.236,
      "grad_norm": 0.2675435245037079,
      "learning_rate": 4.463918758111912e-05,
      "loss": 0.994,
      "step": 590
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.2270670384168625,
      "learning_rate": 4.443713876699124e-05,
      "loss": 1.0599,
      "step": 600
    },
    {
      "epoch": 0.244,
      "grad_norm": 0.2574318051338196,
      "learning_rate": 4.4231827813425885e-05,
      "loss": 1.1644,
      "step": 610
    },
    {
      "epoch": 0.248,
      "grad_norm": 0.30103927850723267,
      "learning_rate": 4.402328917780728e-05,
      "loss": 1.2356,
      "step": 620
    },
    {
      "epoch": 0.252,
      "grad_norm": 0.4182167053222656,
      "learning_rate": 4.3811557859222254e-05,
      "loss": 1.1616,
      "step": 630
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.3168014883995056,
      "learning_rate": 4.3596669392586365e-05,
      "loss": 1.1147,
      "step": 640
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.35073772072792053,
      "learning_rate": 4.337865984268001e-05,
      "loss": 1.1341,
      "step": 650
    },
    {
      "epoch": 0.264,
      "grad_norm": 0.27826863527297974,
      "learning_rate": 4.3157565798095753e-05,
      "loss": 1.1182,
      "step": 660
    },
    {
      "epoch": 0.268,
      "grad_norm": 0.24274395406246185,
      "learning_rate": 4.2933424365097564e-05,
      "loss": 1.0701,
      "step": 670
    },
    {
      "epoch": 0.272,
      "grad_norm": 0.2727891802787781,
      "learning_rate": 4.2706273161393327e-05,
      "loss": 1.0736,
      "step": 680
    },
    {
      "epoch": 0.276,
      "grad_norm": 0.2819693088531494,
      "learning_rate": 4.247615030982144e-05,
      "loss": 1.1217,
      "step": 690
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.27005934715270996,
      "learning_rate": 4.224309443195261e-05,
      "loss": 1.0881,
      "step": 700
    },
    {
      "epoch": 0.284,
      "grad_norm": 0.2749914824962616,
      "learning_rate": 4.200714464160804e-05,
      "loss": 1.0882,
      "step": 710
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.26775506138801575,
      "learning_rate": 4.176834053829492e-05,
      "loss": 1.1109,
      "step": 720
    },
    {
      "epoch": 0.292,
      "grad_norm": 0.44893166422843933,
      "learning_rate": 4.1526722200560445e-05,
      "loss": 1.0841,
      "step": 730
    },
    {
      "epoch": 0.296,
      "grad_norm": 0.3855229616165161,
      "learning_rate": 4.128233017926538e-05,
      "loss": 1.1122,
      "step": 740
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.2974766194820404,
      "learning_rate": 4.10352054907785e-05,
      "loss": 1.0849,
      "step": 750
    },
    {
      "epoch": 0.304,
      "grad_norm": 0.32584065198898315,
      "learning_rate": 4.0785389610092686e-05,
      "loss": 1.2596,
      "step": 760
    },
    {
      "epoch": 0.308,
      "grad_norm": 0.2776174545288086,
      "learning_rate": 4.053292446386422e-05,
      "loss": 1.0731,
      "step": 770
    },
    {
      "epoch": 0.312,
      "grad_norm": 0.27137264609336853,
      "learning_rate": 4.027785242337626e-05,
      "loss": 1.0296,
      "step": 780
    },
    {
      "epoch": 0.316,
      "grad_norm": 0.32308536767959595,
      "learning_rate": 4.0020216297427594e-05,
      "loss": 1.1767,
      "step": 790
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3214084804058075,
      "learning_rate": 3.976005932514807e-05,
      "loss": 1.0697,
      "step": 800
    },
    {
      "epoch": 0.324,
      "grad_norm": 0.3059333860874176,
      "learning_rate": 3.949742516874175e-05,
      "loss": 1.2297,
      "step": 810
    },
    {
      "epoch": 0.328,
      "grad_norm": 0.32866525650024414,
      "learning_rate": 3.923235790615907e-05,
      "loss": 1.0767,
      "step": 820
    },
    {
      "epoch": 0.332,
      "grad_norm": 0.17191040515899658,
      "learning_rate": 3.896490202369924e-05,
      "loss": 0.9897,
      "step": 830
    },
    {
      "epoch": 0.336,
      "grad_norm": 0.3551265001296997,
      "learning_rate": 3.8695102408544076e-05,
      "loss": 1.0955,
      "step": 840
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.42184653878211975,
      "learning_rate": 3.84230043412246e-05,
      "loss": 1.1169,
      "step": 850
    },
    {
      "epoch": 0.344,
      "grad_norm": 0.32929810881614685,
      "learning_rate": 3.814865348802157e-05,
      "loss": 1.1464,
      "step": 860
    },
    {
      "epoch": 0.348,
      "grad_norm": 0.3468882739543915,
      "learning_rate": 3.787209589330134e-05,
      "loss": 1.2195,
      "step": 870
    },
    {
      "epoch": 0.352,
      "grad_norm": 0.39434200525283813,
      "learning_rate": 3.759337797178816e-05,
      "loss": 1.0745,
      "step": 880
    },
    {
      "epoch": 0.356,
      "grad_norm": 0.4239484965801239,
      "learning_rate": 3.731254650077446e-05,
      "loss": 1.13,
      "step": 890
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.2884383201599121,
      "learning_rate": 3.702964861227013e-05,
      "loss": 1.1322,
      "step": 900
    },
    {
      "epoch": 0.364,
      "grad_norm": 0.28761956095695496,
      "learning_rate": 3.6744731785092395e-05,
      "loss": 1.1374,
      "step": 910
    },
    {
      "epoch": 0.368,
      "grad_norm": 0.28928011655807495,
      "learning_rate": 3.645784383689742e-05,
      "loss": 1.1005,
      "step": 920
    },
    {
      "epoch": 0.372,
      "grad_norm": 0.2760242521762848,
      "learning_rate": 3.616903291615506e-05,
      "loss": 0.9901,
      "step": 930
    },
    {
      "epoch": 0.376,
      "grad_norm": 0.24726168811321259,
      "learning_rate": 3.5878347494068084e-05,
      "loss": 1.1175,
      "step": 940
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.2470572292804718,
      "learning_rate": 3.5585836356437264e-05,
      "loss": 1.0971,
      "step": 950
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.39661580324172974,
      "learning_rate": 3.52915485954736e-05,
      "loss": 1.0997,
      "step": 960
    },
    {
      "epoch": 0.388,
      "grad_norm": 0.260030061006546,
      "learning_rate": 3.4995533601559226e-05,
      "loss": 1.0047,
      "step": 970
    },
    {
      "epoch": 0.392,
      "grad_norm": 0.332827091217041,
      "learning_rate": 3.4697841054958165e-05,
      "loss": 1.0337,
      "step": 980
    },
    {
      "epoch": 0.396,
      "grad_norm": 0.3859623968601227,
      "learning_rate": 3.4398520917478476e-05,
      "loss": 1.0369,
      "step": 990
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.39973536133766174,
      "learning_rate": 3.409762342408719e-05,
      "loss": 1.1512,
      "step": 1000
    },
    {
      "epoch": 0.404,
      "grad_norm": 0.3598465323448181,
      "learning_rate": 3.379519907447931e-05,
      "loss": 1.1336,
      "step": 1010
    },
    {
      "epoch": 0.408,
      "grad_norm": 0.38931113481521606,
      "learning_rate": 3.349129862460251e-05,
      "loss": 1.0907,
      "step": 1020
    },
    {
      "epoch": 0.412,
      "grad_norm": 0.3561212718486786,
      "learning_rate": 3.3185973078138664e-05,
      "loss": 1.1034,
      "step": 1030
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.4245721101760864,
      "learning_rate": 3.287927367794397e-05,
      "loss": 1.1005,
      "step": 1040
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.3057941496372223,
      "learning_rate": 3.2571251897448765e-05,
      "loss": 1.0544,
      "step": 1050
    },
    {
      "epoch": 0.424,
      "grad_norm": 0.3157004714012146,
      "learning_rate": 3.226195943201883e-05,
      "loss": 1.1375,
      "step": 1060
    },
    {
      "epoch": 0.428,
      "grad_norm": 0.4616083800792694,
      "learning_rate": 3.1951448190279255e-05,
      "loss": 1.0293,
      "step": 1070
    },
    {
      "epoch": 0.432,
      "grad_norm": 0.28941047191619873,
      "learning_rate": 3.163977028540263e-05,
      "loss": 1.0987,
      "step": 1080
    },
    {
      "epoch": 0.436,
      "grad_norm": 0.3314313292503357,
      "learning_rate": 3.1326978026362904e-05,
      "loss": 1.1798,
      "step": 1090
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.2553110420703888,
      "learning_rate": 3.101312390915634e-05,
      "loss": 1.0715,
      "step": 1100
    },
    {
      "epoch": 0.444,
      "grad_norm": 0.3473363518714905,
      "learning_rate": 3.069826060799109e-05,
      "loss": 1.031,
      "step": 1110
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.43489590287208557,
      "learning_rate": 3.0382440966446875e-05,
      "loss": 1.1015,
      "step": 1120
    },
    {
      "epoch": 0.452,
      "grad_norm": 0.3750501573085785,
      "learning_rate": 3.0065717988606257e-05,
      "loss": 1.0412,
      "step": 1130
    },
    {
      "epoch": 0.456,
      "grad_norm": 0.33799242973327637,
      "learning_rate": 2.9748144830158924e-05,
      "loss": 1.1512,
      "step": 1140
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.3069237172603607,
      "learning_rate": 2.9429774789480575e-05,
      "loss": 1.1298,
      "step": 1150
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.3091396689414978,
      "learning_rate": 2.9110661298687824e-05,
      "loss": 1.0992,
      "step": 1160
    },
    {
      "epoch": 0.468,
      "grad_norm": 0.4092029631137848,
      "learning_rate": 2.8790857914670698e-05,
      "loss": 1.0798,
      "step": 1170
    },
    {
      "epoch": 0.472,
      "grad_norm": 0.388576865196228,
      "learning_rate": 2.8470418310104173e-05,
      "loss": 1.107,
      "step": 1180
    },
    {
      "epoch": 0.476,
      "grad_norm": 0.3081146776676178,
      "learning_rate": 2.814939626444023e-05,
      "loss": 1.0474,
      "step": 1190
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.28704115748405457,
      "learning_rate": 2.782784565488211e-05,
      "loss": 1.0167,
      "step": 1200
    },
    {
      "epoch": 0.484,
      "grad_norm": 0.29155370593070984,
      "learning_rate": 2.7505820447342028e-05,
      "loss": 1.0565,
      "step": 1210
    },
    {
      "epoch": 0.488,
      "grad_norm": 0.44309261441230774,
      "learning_rate": 2.71833746873841e-05,
      "loss": 1.1781,
      "step": 1220
    },
    {
      "epoch": 0.492,
      "grad_norm": 0.40963900089263916,
      "learning_rate": 2.686056249115385e-05,
      "loss": 1.0662,
      "step": 1230
    },
    {
      "epoch": 0.496,
      "grad_norm": 0.3097870349884033,
      "learning_rate": 2.6537438036295875e-05,
      "loss": 1.0643,
      "step": 1240
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.3374674320220947,
      "learning_rate": 2.621405555286121e-05,
      "loss": 1.1869,
      "step": 1250
    },
    {
      "epoch": 0.504,
      "grad_norm": 0.29257938265800476,
      "learning_rate": 2.5890469314205897e-05,
      "loss": 1.1081,
      "step": 1260
    },
    {
      "epoch": 0.508,
      "grad_norm": 0.3749138116836548,
      "learning_rate": 2.556673362788225e-05,
      "loss": 1.0809,
      "step": 1270
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.4699561297893524,
      "learning_rate": 2.5242902826524434e-05,
      "loss": 1.0866,
      "step": 1280
    },
    {
      "epoch": 0.516,
      "grad_norm": 0.3546701967716217,
      "learning_rate": 2.4919031258729786e-05,
      "loss": 1.1695,
      "step": 1290
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.31299662590026855,
      "learning_rate": 2.4595173279937464e-05,
      "loss": 1.12,
      "step": 1300
    },
    {
      "epoch": 0.524,
      "grad_norm": 0.26003164052963257,
      "learning_rate": 2.4271383243306016e-05,
      "loss": 1.0753,
      "step": 1310
    },
    {
      "epoch": 0.528,
      "grad_norm": 0.25696471333503723,
      "learning_rate": 2.3947715490591206e-05,
      "loss": 1.0569,
      "step": 1320
    },
    {
      "epoch": 0.532,
      "grad_norm": 0.2811177968978882,
      "learning_rate": 2.362422434302588e-05,
      "loss": 1.1072,
      "step": 1330
    },
    {
      "epoch": 0.536,
      "grad_norm": 0.3838948607444763,
      "learning_rate": 2.3300964092203207e-05,
      "loss": 1.0769,
      "step": 1340
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.3760908544063568,
      "learning_rate": 2.29779889909649e-05,
      "loss": 1.0838,
      "step": 1350
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.4155043661594391,
      "learning_rate": 2.2655353244295928e-05,
      "loss": 1.0564,
      "step": 1360
    },
    {
      "epoch": 0.548,
      "grad_norm": 0.269986629486084,
      "learning_rate": 2.2333111000227342e-05,
      "loss": 1.0725,
      "step": 1370
    },
    {
      "epoch": 0.552,
      "grad_norm": 0.2856642007827759,
      "learning_rate": 2.201131634074853e-05,
      "loss": 1.039,
      "step": 1380
    },
    {
      "epoch": 0.556,
      "grad_norm": 0.30481886863708496,
      "learning_rate": 2.169002327273068e-05,
      "loss": 1.0602,
      "step": 1390
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.2857995331287384,
      "learning_rate": 2.136928571886275e-05,
      "loss": 1.0526,
      "step": 1400
    },
    {
      "epoch": 0.564,
      "grad_norm": 0.32070085406303406,
      "learning_rate": 2.1049157508601642e-05,
      "loss": 1.0067,
      "step": 1410
    },
    {
      "epoch": 0.568,
      "grad_norm": 0.3715701103210449,
      "learning_rate": 2.072969236913799e-05,
      "loss": 1.1405,
      "step": 1420
    },
    {
      "epoch": 0.572,
      "grad_norm": 0.24840740859508514,
      "learning_rate": 2.04109439163791e-05,
      "loss": 1.1126,
      "step": 1430
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.4117615222930908,
      "learning_rate": 2.0092965645950564e-05,
      "loss": 1.0727,
      "step": 1440
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.449322372674942,
      "learning_rate": 1.9775810924218125e-05,
      "loss": 1.132,
      "step": 1450
    },
    {
      "epoch": 0.584,
      "grad_norm": 0.28644195199012756,
      "learning_rate": 1.945953297933115e-05,
      "loss": 1.0225,
      "step": 1460
    },
    {
      "epoch": 0.588,
      "grad_norm": 0.45531103014945984,
      "learning_rate": 1.9144184892289337e-05,
      "loss": 1.0902,
      "step": 1470
    },
    {
      "epoch": 0.592,
      "grad_norm": 0.38306936621665955,
      "learning_rate": 1.882981958803414e-05,
      "loss": 1.0569,
      "step": 1480
    },
    {
      "epoch": 0.596,
      "grad_norm": 0.29347705841064453,
      "learning_rate": 1.8516489826566376e-05,
      "loss": 1.0327,
      "step": 1490
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.4917737543582916,
      "learning_rate": 1.820424819409143e-05,
      "loss": 1.0661,
      "step": 1500
    },
    {
      "epoch": 0.604,
      "grad_norm": 0.4259710907936096,
      "learning_rate": 1.7893147094193786e-05,
      "loss": 1.1078,
      "step": 1510
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.3538530468940735,
      "learning_rate": 1.7583238739042086e-05,
      "loss": 1.0944,
      "step": 1520
    },
    {
      "epoch": 0.612,
      "grad_norm": 0.4406505823135376,
      "learning_rate": 1.7274575140626318e-05,
      "loss": 1.0048,
      "step": 1530
    },
    {
      "epoch": 0.616,
      "grad_norm": 0.3803732097148895,
      "learning_rate": 1.6967208102028697e-05,
      "loss": 1.1288,
      "step": 1540
    },
    {
      "epoch": 0.62,
      "grad_norm": 0.3329049050807953,
      "learning_rate": 1.666118920872949e-05,
      "loss": 1.1013,
      "step": 1550
    },
    {
      "epoch": 0.624,
      "grad_norm": 0.3979591429233551,
      "learning_rate": 1.635656981994943e-05,
      "loss": 1.1896,
      "step": 1560
    },
    {
      "epoch": 0.628,
      "grad_norm": 0.3722856640815735,
      "learning_rate": 1.60534010600301e-05,
      "loss": 1.0623,
      "step": 1570
    },
    {
      "epoch": 0.632,
      "grad_norm": 0.20345443487167358,
      "learning_rate": 1.5751733809853704e-05,
      "loss": 1.0342,
      "step": 1580
    },
    {
      "epoch": 0.636,
      "grad_norm": 0.34590592980384827,
      "learning_rate": 1.545161869830371e-05,
      "loss": 1.0935,
      "step": 1590
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.2810020446777344,
      "learning_rate": 1.5153106093767827e-05,
      "loss": 1.101,
      "step": 1600
    },
    {
      "epoch": 0.644,
      "grad_norm": 0.4703897535800934,
      "learning_rate": 1.4856246095684622e-05,
      "loss": 1.0053,
      "step": 1610
    },
    {
      "epoch": 0.648,
      "grad_norm": 0.2699468731880188,
      "learning_rate": 1.4561088526135375e-05,
      "loss": 1.1505,
      "step": 1620
    },
    {
      "epoch": 0.652,
      "grad_norm": 0.2942810654640198,
      "learning_rate": 1.4267682921482356e-05,
      "loss": 1.1255,
      "step": 1630
    },
    {
      "epoch": 0.656,
      "grad_norm": 0.36969250440597534,
      "learning_rate": 1.3976078524055203e-05,
      "loss": 1.0824,
      "step": 1640
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.5482453107833862,
      "learning_rate": 1.368632427388653e-05,
      "loss": 1.0508,
      "step": 1650
    },
    {
      "epoch": 0.664,
      "grad_norm": 0.4142816364765167,
      "learning_rate": 1.3398468800498293e-05,
      "loss": 1.0861,
      "step": 1660
    },
    {
      "epoch": 0.668,
      "grad_norm": 0.21996323764324188,
      "learning_rate": 1.3112560414740315e-05,
      "loss": 0.9844,
      "step": 1670
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.32251793146133423,
      "learning_rate": 1.2828647100682261e-05,
      "loss": 1.1412,
      "step": 1680
    },
    {
      "epoch": 0.676,
      "grad_norm": 0.3700939118862152,
      "learning_rate": 1.2546776507560468e-05,
      "loss": 1.0598,
      "step": 1690
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.2834911048412323,
      "learning_rate": 1.2266995941780934e-05,
      "loss": 1.0477,
      "step": 1700
    },
    {
      "epoch": 0.684,
      "grad_norm": 0.3970465660095215,
      "learning_rate": 1.1989352358979888e-05,
      "loss": 1.0624,
      "step": 1710
    },
    {
      "epoch": 0.688,
      "grad_norm": 0.3341314494609833,
      "learning_rate": 1.1713892356143239e-05,
      "loss": 1.0905,
      "step": 1720
    },
    {
      "epoch": 0.692,
      "grad_norm": 0.3667237162590027,
      "learning_rate": 1.1440662163786167e-05,
      "loss": 1.1751,
      "step": 1730
    },
    {
      "epoch": 0.696,
      "grad_norm": 0.34809210896492004,
      "learning_rate": 1.1169707638194238e-05,
      "loss": 1.1476,
      "step": 1740
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.2850727140903473,
      "learning_rate": 1.0901074253727336e-05,
      "loss": 1.0048,
      "step": 1750
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.3482169210910797,
      "learning_rate": 1.0634807095187737e-05,
      "loss": 1.0454,
      "step": 1760
    },
    {
      "epoch": 0.708,
      "grad_norm": 0.42491817474365234,
      "learning_rate": 1.0370950850253449e-05,
      "loss": 1.059,
      "step": 1770
    },
    {
      "epoch": 0.712,
      "grad_norm": 0.4422051012516022,
      "learning_rate": 1.0109549801978305e-05,
      "loss": 1.0852,
      "step": 1780
    },
    {
      "epoch": 0.716,
      "grad_norm": 0.3246915340423584,
      "learning_rate": 9.850647821359918e-06,
      "loss": 0.9691,
      "step": 1790
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.4847804307937622,
      "learning_rate": 9.594288359976817e-06,
      "loss": 1.1041,
      "step": 1800
    },
    {
      "epoch": 0.724,
      "grad_norm": 0.33785170316696167,
      "learning_rate": 9.340514442695952e-06,
      "loss": 1.1043,
      "step": 1810
    },
    {
      "epoch": 0.728,
      "grad_norm": 0.4399304687976837,
      "learning_rate": 9.0893686604518e-06,
      "loss": 1.0603,
      "step": 1820
    },
    {
      "epoch": 0.732,
      "grad_norm": 0.3489610552787781,
      "learning_rate": 8.840893163098331e-06,
      "loss": 1.0223,
      "step": 1830
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.3958871066570282,
      "learning_rate": 8.595129652335019e-06,
      "loss": 0.9588,
      "step": 1840
    },
    {
      "epoch": 0.74,
      "grad_norm": 0.48820510506629944,
      "learning_rate": 8.352119374707978e-06,
      "loss": 1.1553,
      "step": 1850
    },
    {
      "epoch": 0.744,
      "grad_norm": 0.351626992225647,
      "learning_rate": 8.111903114687591e-06,
      "loss": 1.0202,
      "step": 1860
    },
    {
      "epoch": 0.748,
      "grad_norm": 0.4208831191062927,
      "learning_rate": 7.87452118782363e-06,
      "loss": 1.1011,
      "step": 1870
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.4033498167991638,
      "learning_rate": 7.640013433979093e-06,
      "loss": 1.0688,
      "step": 1880
    },
    {
      "epoch": 0.756,
      "grad_norm": 0.41373950242996216,
      "learning_rate": 7.408419210643847e-06,
      "loss": 1.0757,
      "step": 1890
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.3726571202278137,
      "learning_rate": 7.179777386329276e-06,
      "loss": 1.0648,
      "step": 1900
    },
    {
      "epoch": 0.764,
      "grad_norm": 0.32734206318855286,
      "learning_rate": 6.9541263340449496e-06,
      "loss": 0.9912,
      "step": 1910
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.29287397861480713,
      "learning_rate": 6.731503924858518e-06,
      "loss": 1.0234,
      "step": 1920
    },
    {
      "epoch": 0.772,
      "grad_norm": 0.4402100741863251,
      "learning_rate": 6.511947521539738e-06,
      "loss": 1.0307,
      "step": 1930
    },
    {
      "epoch": 0.776,
      "grad_norm": 0.3708447217941284,
      "learning_rate": 6.295493972289904e-06,
      "loss": 1.112,
      "step": 1940
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.31207171082496643,
      "learning_rate": 6.082179604557617e-06,
      "loss": 1.0149,
      "step": 1950
    },
    {
      "epoch": 0.784,
      "grad_norm": 0.26059845089912415,
      "learning_rate": 5.872040218941929e-06,
      "loss": 0.9744,
      "step": 1960
    },
    {
      "epoch": 0.788,
      "grad_norm": 0.3804650902748108,
      "learning_rate": 5.665111083183905e-06,
      "loss": 1.011,
      "step": 1970
    },
    {
      "epoch": 0.792,
      "grad_norm": 0.26637816429138184,
      "learning_rate": 5.46142692624764e-06,
      "loss": 1.0811,
      "step": 1980
    },
    {
      "epoch": 0.796,
      "grad_norm": 0.307365357875824,
      "learning_rate": 5.261021932491714e-06,
      "loss": 0.9915,
      "step": 1990
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.2714247703552246,
      "learning_rate": 5.063929735931985e-06,
      "loss": 1.0188,
      "step": 2000
    },
    {
      "epoch": 0.804,
      "grad_norm": 0.3013599216938019,
      "learning_rate": 4.870183414596794e-06,
      "loss": 1.0898,
      "step": 2010
    },
    {
      "epoch": 0.808,
      "grad_norm": 0.3360036313533783,
      "learning_rate": 4.679815484975505e-06,
      "loss": 1.0612,
      "step": 2020
    },
    {
      "epoch": 0.812,
      "grad_norm": 0.31419017910957336,
      "learning_rate": 4.492857896561204e-06,
      "loss": 1.0452,
      "step": 2030
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.343980610370636,
      "learning_rate": 4.309342026488653e-06,
      "loss": 1.0447,
      "step": 2040
    },
    {
      "epoch": 0.82,
      "grad_norm": 0.3915833830833435,
      "learning_rate": 4.129298674268225e-06,
      "loss": 1.0675,
      "step": 2050
    },
    {
      "epoch": 0.824,
      "grad_norm": 0.30664101243019104,
      "learning_rate": 3.952758056616826e-06,
      "loss": 1.0805,
      "step": 2060
    },
    {
      "epoch": 0.828,
      "grad_norm": 0.45886868238449097,
      "learning_rate": 3.7797498023866396e-06,
      "loss": 1.0419,
      "step": 2070
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.3857685625553131,
      "learning_rate": 3.6103029475924726e-06,
      "loss": 1.05,
      "step": 2080
    },
    {
      "epoch": 0.836,
      "grad_norm": 0.3398388624191284,
      "learning_rate": 3.4444459305386507e-06,
      "loss": 1.0069,
      "step": 2090
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.3795624077320099,
      "learning_rate": 3.2822065870462217e-06,
      "loss": 1.0852,
      "step": 2100
    },
    {
      "epoch": 0.844,
      "grad_norm": 0.4275623857975006,
      "learning_rate": 3.1236121457812544e-06,
      "loss": 1.0586,
      "step": 2110
    },
    {
      "epoch": 0.848,
      "grad_norm": 0.2906014621257782,
      "learning_rate": 2.9686892236850337e-06,
      "loss": 1.0324,
      "step": 2120
    },
    {
      "epoch": 0.852,
      "grad_norm": 0.33475586771965027,
      "learning_rate": 2.8174638215069493e-06,
      "loss": 1.0607,
      "step": 2130
    },
    {
      "epoch": 0.856,
      "grad_norm": 0.42739367485046387,
      "learning_rate": 2.6699613194407725e-06,
      "loss": 1.1031,
      "step": 2140
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.25649696588516235,
      "learning_rate": 2.52620647286512e-06,
      "loss": 1.0456,
      "step": 2150
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.3834601640701294,
      "learning_rate": 2.3862234081887036e-06,
      "loss": 1.1068,
      "step": 2160
    },
    {
      "epoch": 0.868,
      "grad_norm": 0.3306742012500763,
      "learning_rate": 2.250035618801241e-06,
      "loss": 1.0559,
      "step": 2170
    },
    {
      "epoch": 0.872,
      "grad_norm": 0.3469555974006653,
      "learning_rate": 2.117665961130513e-06,
      "loss": 1.1513,
      "step": 2180
    },
    {
      "epoch": 0.876,
      "grad_norm": 0.3433113992214203,
      "learning_rate": 1.9891366508064003e-06,
      "loss": 1.1123,
      "step": 2190
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.44862210750579834,
      "learning_rate": 1.864469258932397e-06,
      "loss": 1.0536,
      "step": 2200
    },
    {
      "epoch": 0.884,
      "grad_norm": 0.2918873429298401,
      "learning_rate": 1.7436847084653456e-06,
      "loss": 1.011,
      "step": 2210
    },
    {
      "epoch": 0.888,
      "grad_norm": 0.31593647599220276,
      "learning_rate": 1.626803270703936e-06,
      "loss": 1.076,
      "step": 2220
    },
    {
      "epoch": 0.892,
      "grad_norm": 0.44069114327430725,
      "learning_rate": 1.5138445618865544e-06,
      "loss": 1.0647,
      "step": 2230
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.46397459506988525,
      "learning_rate": 1.4048275398990896e-06,
      "loss": 1.1326,
      "step": 2240
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.42001307010650635,
      "learning_rate": 1.2997705010932393e-06,
      "loss": 1.0379,
      "step": 2250
    },
    {
      "epoch": 0.904,
      "grad_norm": 0.40556302666664124,
      "learning_rate": 1.1986910772158104e-06,
      "loss": 1.1433,
      "step": 2260
    },
    {
      "epoch": 0.908,
      "grad_norm": 0.3313983976840973,
      "learning_rate": 1.1016062324496008e-06,
      "loss": 1.0921,
      "step": 2270
    },
    {
      "epoch": 0.912,
      "grad_norm": 0.43848997354507446,
      "learning_rate": 1.0085322605662666e-06,
      "loss": 1.0489,
      "step": 2280
    },
    {
      "epoch": 0.916,
      "grad_norm": 0.352563738822937,
      "learning_rate": 9.194847821917623e-07,
      "loss": 1.1178,
      "step": 2290
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.32622119784355164,
      "learning_rate": 8.344787421847217e-07,
      "loss": 1.0765,
      "step": 2300
    },
    {
      "epoch": 0.924,
      "grad_norm": 0.4348568022251129,
      "learning_rate": 7.535284071282455e-07,
      "loss": 1.1194,
      "step": 2310
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.36828094720840454,
      "learning_rate": 6.766473629355452e-07,
      "loss": 0.9935,
      "step": 2320
    },
    {
      "epoch": 0.932,
      "grad_norm": 0.46253129839897156,
      "learning_rate": 6.038485125698295e-07,
      "loss": 1.0689,
      "step": 2330
    },
    {
      "epoch": 0.936,
      "grad_norm": 0.26117345690727234,
      "learning_rate": 5.351440738787794e-07,
      "loss": 1.1038,
      "step": 2340
    },
    {
      "epoch": 0.94,
      "grad_norm": 0.391824871301651,
      "learning_rate": 4.7054557754402373e-07,
      "loss": 1.016,
      "step": 2350
    },
    {
      "epoch": 0.944,
      "grad_norm": 0.402846097946167,
      "learning_rate": 4.100638651459543e-07,
      "loss": 0.9913,
      "step": 2360
    },
    {
      "epoch": 0.948,
      "grad_norm": 0.49564021825790405,
      "learning_rate": 3.5370908734417006e-07,
      "loss": 1.0507,
      "step": 2370
    },
    {
      "epoch": 0.952,
      "grad_norm": 0.40204668045043945,
      "learning_rate": 3.014907021739011e-07,
      "loss": 1.0953,
      "step": 2380
    },
    {
      "epoch": 0.956,
      "grad_norm": 0.26411548256874084,
      "learning_rate": 2.534174734586503e-07,
      "loss": 0.9431,
      "step": 2390
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.37419161200523376,
      "learning_rate": 2.094974693393731e-07,
      "loss": 1.0572,
      "step": 2400
    },
    {
      "epoch": 0.964,
      "grad_norm": 0.35387536883354187,
      "learning_rate": 1.6973806092038525e-07,
      "loss": 0.987,
      "step": 2410
    },
    {
      "epoch": 0.968,
      "grad_norm": 0.38669371604919434,
      "learning_rate": 1.3414592103228595e-07,
      "loss": 1.1014,
      "step": 2420
    },
    {
      "epoch": 0.972,
      "grad_norm": 0.2583492696285248,
      "learning_rate": 1.0272702311203696e-07,
      "loss": 1.1025,
      "step": 2430
    },
    {
      "epoch": 0.976,
      "grad_norm": 0.3807677626609802,
      "learning_rate": 7.54866402004506e-08,
      "loss": 1.0269,
      "step": 2440
    },
    {
      "epoch": 0.98,
      "grad_norm": 0.41734778881073,
      "learning_rate": 5.242934405720879e-08,
      "loss": 0.9948,
      "step": 2450
    },
    {
      "epoch": 0.984,
      "grad_norm": 0.38812553882598877,
      "learning_rate": 3.355900439359072e-08,
      "loss": 1.1484,
      "step": 2460
    },
    {
      "epoch": 0.988,
      "grad_norm": 0.33868902921676636,
      "learning_rate": 1.8878788223009036e-08,
      "loss": 1.0134,
      "step": 2470
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.4277910590171814,
      "learning_rate": 8.39115932949608e-09,
      "loss": 1.1648,
      "step": 2480
    },
    {
      "epoch": 0.996,
      "grad_norm": 0.3350001573562622,
      "learning_rate": 2.0978778542041222e-09,
      "loss": 1.0827,
      "step": 2490
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.30823850631713867,
      "learning_rate": 0.0,
      "loss": 1.0299,
      "step": 2500
    }
  ],
  "logging_steps": 10,
  "max_steps": 2500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3456028281415680.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
