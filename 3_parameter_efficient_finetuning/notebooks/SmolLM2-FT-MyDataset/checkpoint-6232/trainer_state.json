{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 6232,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0016047500601781273,
      "grad_norm": 0.3481806814670563,
      "learning_rate": 3.5650623885918005e-07,
      "loss": 2.0275,
      "step": 10
    },
    {
      "epoch": 0.0032095001203562546,
      "grad_norm": 0.27435800433158875,
      "learning_rate": 7.130124777183601e-07,
      "loss": 1.7784,
      "step": 20
    },
    {
      "epoch": 0.004814250180534382,
      "grad_norm": 0.2910098433494568,
      "learning_rate": 1.0695187165775401e-06,
      "loss": 1.7868,
      "step": 30
    },
    {
      "epoch": 0.006419000240712509,
      "grad_norm": 0.3374997675418854,
      "learning_rate": 1.4260249554367202e-06,
      "loss": 1.7637,
      "step": 40
    },
    {
      "epoch": 0.008023750300890637,
      "grad_norm": 0.5533764362335205,
      "learning_rate": 1.7825311942959003e-06,
      "loss": 1.7994,
      "step": 50
    },
    {
      "epoch": 0.009628500361068763,
      "grad_norm": 0.3769804835319519,
      "learning_rate": 2.1390374331550802e-06,
      "loss": 1.8867,
      "step": 60
    },
    {
      "epoch": 0.01123325042124689,
      "grad_norm": 0.3294832408428192,
      "learning_rate": 2.4955436720142603e-06,
      "loss": 1.8388,
      "step": 70
    },
    {
      "epoch": 0.012838000481425018,
      "grad_norm": 0.28214165568351746,
      "learning_rate": 2.8520499108734404e-06,
      "loss": 1.6355,
      "step": 80
    },
    {
      "epoch": 0.014442750541603145,
      "grad_norm": 0.28274163603782654,
      "learning_rate": 3.2085561497326205e-06,
      "loss": 1.7754,
      "step": 90
    },
    {
      "epoch": 0.016047500601781273,
      "grad_norm": 0.3549898862838745,
      "learning_rate": 3.5650623885918006e-06,
      "loss": 1.6496,
      "step": 100
    },
    {
      "epoch": 0.0176522506619594,
      "grad_norm": 0.2647390365600586,
      "learning_rate": 3.92156862745098e-06,
      "loss": 1.5751,
      "step": 110
    },
    {
      "epoch": 0.019257000722137527,
      "grad_norm": 0.3015369772911072,
      "learning_rate": 4.2780748663101604e-06,
      "loss": 1.8334,
      "step": 120
    },
    {
      "epoch": 0.020861750782315655,
      "grad_norm": 0.2643004357814789,
      "learning_rate": 4.6345811051693405e-06,
      "loss": 1.8201,
      "step": 130
    },
    {
      "epoch": 0.02246650084249378,
      "grad_norm": 0.4140813946723938,
      "learning_rate": 4.991087344028521e-06,
      "loss": 1.7839,
      "step": 140
    },
    {
      "epoch": 0.02407125090267191,
      "grad_norm": 0.3582390248775482,
      "learning_rate": 5.347593582887702e-06,
      "loss": 1.668,
      "step": 150
    },
    {
      "epoch": 0.025676000962850037,
      "grad_norm": 0.5730404853820801,
      "learning_rate": 5.704099821746881e-06,
      "loss": 1.9012,
      "step": 160
    },
    {
      "epoch": 0.027280751023028165,
      "grad_norm": 0.46824926137924194,
      "learning_rate": 6.060606060606061e-06,
      "loss": 1.8621,
      "step": 170
    },
    {
      "epoch": 0.02888550108320629,
      "grad_norm": 0.46423736214637756,
      "learning_rate": 6.417112299465241e-06,
      "loss": 1.8651,
      "step": 180
    },
    {
      "epoch": 0.03049025114338442,
      "grad_norm": 0.34394699335098267,
      "learning_rate": 6.773618538324421e-06,
      "loss": 1.9437,
      "step": 190
    },
    {
      "epoch": 0.03209500120356255,
      "grad_norm": 0.5196558833122253,
      "learning_rate": 7.130124777183601e-06,
      "loss": 1.9508,
      "step": 200
    },
    {
      "epoch": 0.033699751263740675,
      "grad_norm": 0.8910748958587646,
      "learning_rate": 7.486631016042781e-06,
      "loss": 1.9862,
      "step": 210
    },
    {
      "epoch": 0.0353045013239188,
      "grad_norm": 0.6707438826560974,
      "learning_rate": 7.84313725490196e-06,
      "loss": 1.6518,
      "step": 220
    },
    {
      "epoch": 0.036909251384096925,
      "grad_norm": 0.428229957818985,
      "learning_rate": 8.19964349376114e-06,
      "loss": 1.5906,
      "step": 230
    },
    {
      "epoch": 0.03851400144427505,
      "grad_norm": 0.39312443137168884,
      "learning_rate": 8.556149732620321e-06,
      "loss": 1.7584,
      "step": 240
    },
    {
      "epoch": 0.04011875150445318,
      "grad_norm": 0.42399024963378906,
      "learning_rate": 8.912655971479501e-06,
      "loss": 1.6653,
      "step": 250
    },
    {
      "epoch": 0.04172350156463131,
      "grad_norm": 0.44612210988998413,
      "learning_rate": 9.269162210338681e-06,
      "loss": 1.8681,
      "step": 260
    },
    {
      "epoch": 0.04332825162480944,
      "grad_norm": 0.7041329741477966,
      "learning_rate": 9.625668449197861e-06,
      "loss": 1.6439,
      "step": 270
    },
    {
      "epoch": 0.04493300168498756,
      "grad_norm": 0.7503124475479126,
      "learning_rate": 9.982174688057041e-06,
      "loss": 1.6185,
      "step": 280
    },
    {
      "epoch": 0.04653775174516569,
      "grad_norm": 0.5278136134147644,
      "learning_rate": 1.0338680926916223e-05,
      "loss": 1.8324,
      "step": 290
    },
    {
      "epoch": 0.04814250180534382,
      "grad_norm": 0.42845892906188965,
      "learning_rate": 1.0695187165775403e-05,
      "loss": 1.7182,
      "step": 300
    },
    {
      "epoch": 0.049747251865521945,
      "grad_norm": 0.32218316197395325,
      "learning_rate": 1.1051693404634583e-05,
      "loss": 1.9951,
      "step": 310
    },
    {
      "epoch": 0.05135200192570007,
      "grad_norm": 0.21394136548042297,
      "learning_rate": 1.1408199643493762e-05,
      "loss": 1.648,
      "step": 320
    },
    {
      "epoch": 0.0529567519858782,
      "grad_norm": 0.2552504241466522,
      "learning_rate": 1.1764705882352942e-05,
      "loss": 1.6926,
      "step": 330
    },
    {
      "epoch": 0.05456150204605633,
      "grad_norm": 0.43248167634010315,
      "learning_rate": 1.2121212121212122e-05,
      "loss": 1.863,
      "step": 340
    },
    {
      "epoch": 0.05616625210623445,
      "grad_norm": 0.28484341502189636,
      "learning_rate": 1.2477718360071302e-05,
      "loss": 1.7311,
      "step": 350
    },
    {
      "epoch": 0.05777100216641258,
      "grad_norm": 0.18368053436279297,
      "learning_rate": 1.2834224598930482e-05,
      "loss": 1.6479,
      "step": 360
    },
    {
      "epoch": 0.05937575222659071,
      "grad_norm": 0.17929795384407043,
      "learning_rate": 1.3190730837789662e-05,
      "loss": 1.6374,
      "step": 370
    },
    {
      "epoch": 0.06098050228676884,
      "grad_norm": 0.14017082750797272,
      "learning_rate": 1.3547237076648842e-05,
      "loss": 1.7078,
      "step": 380
    },
    {
      "epoch": 0.06258525234694697,
      "grad_norm": 0.22329741716384888,
      "learning_rate": 1.3903743315508022e-05,
      "loss": 1.6731,
      "step": 390
    },
    {
      "epoch": 0.0641900024071251,
      "grad_norm": 0.14382880926132202,
      "learning_rate": 1.4260249554367203e-05,
      "loss": 1.5604,
      "step": 400
    },
    {
      "epoch": 0.06579475246730322,
      "grad_norm": 0.3925539553165436,
      "learning_rate": 1.4616755793226383e-05,
      "loss": 1.53,
      "step": 410
    },
    {
      "epoch": 0.06739950252748135,
      "grad_norm": 0.27906155586242676,
      "learning_rate": 1.4973262032085563e-05,
      "loss": 1.5849,
      "step": 420
    },
    {
      "epoch": 0.06900425258765948,
      "grad_norm": 0.18232017755508423,
      "learning_rate": 1.532976827094474e-05,
      "loss": 1.3326,
      "step": 430
    },
    {
      "epoch": 0.0706090026478376,
      "grad_norm": 0.23918840289115906,
      "learning_rate": 1.568627450980392e-05,
      "loss": 1.5074,
      "step": 440
    },
    {
      "epoch": 0.07221375270801572,
      "grad_norm": 0.2625289261341095,
      "learning_rate": 1.60427807486631e-05,
      "loss": 1.6655,
      "step": 450
    },
    {
      "epoch": 0.07381850276819385,
      "grad_norm": 0.3620847165584564,
      "learning_rate": 1.639928698752228e-05,
      "loss": 1.66,
      "step": 460
    },
    {
      "epoch": 0.07542325282837198,
      "grad_norm": 0.23106391727924347,
      "learning_rate": 1.675579322638146e-05,
      "loss": 1.4607,
      "step": 470
    },
    {
      "epoch": 0.0770280028885501,
      "grad_norm": 0.3901979327201843,
      "learning_rate": 1.7112299465240642e-05,
      "loss": 1.4881,
      "step": 480
    },
    {
      "epoch": 0.07863275294872824,
      "grad_norm": 0.23092664778232574,
      "learning_rate": 1.7468805704099822e-05,
      "loss": 1.6274,
      "step": 490
    },
    {
      "epoch": 0.08023750300890636,
      "grad_norm": 0.23557554185390472,
      "learning_rate": 1.7825311942959002e-05,
      "loss": 1.4452,
      "step": 500
    },
    {
      "epoch": 0.08184225306908449,
      "grad_norm": 0.3031589090824127,
      "learning_rate": 1.8181818181818182e-05,
      "loss": 1.5062,
      "step": 510
    },
    {
      "epoch": 0.08344700312926262,
      "grad_norm": 0.3062126338481903,
      "learning_rate": 1.8538324420677362e-05,
      "loss": 1.4598,
      "step": 520
    },
    {
      "epoch": 0.08505175318944075,
      "grad_norm": 0.34174180030822754,
      "learning_rate": 1.8894830659536542e-05,
      "loss": 1.4588,
      "step": 530
    },
    {
      "epoch": 0.08665650324961888,
      "grad_norm": 0.24502912163734436,
      "learning_rate": 1.9251336898395722e-05,
      "loss": 1.5626,
      "step": 540
    },
    {
      "epoch": 0.088261253309797,
      "grad_norm": 0.2255953699350357,
      "learning_rate": 1.9607843137254903e-05,
      "loss": 1.4311,
      "step": 550
    },
    {
      "epoch": 0.08986600336997512,
      "grad_norm": 0.31927159428596497,
      "learning_rate": 1.9964349376114083e-05,
      "loss": 1.558,
      "step": 560
    },
    {
      "epoch": 0.09147075343015325,
      "grad_norm": 0.2991087734699249,
      "learning_rate": 1.9999987841968625e-05,
      "loss": 1.4276,
      "step": 570
    },
    {
      "epoch": 0.09307550349033138,
      "grad_norm": 0.21444474160671234,
      "learning_rate": 1.9999945814243798e-05,
      "loss": 1.4296,
      "step": 580
    },
    {
      "epoch": 0.0946802535505095,
      "grad_norm": 0.27173665165901184,
      "learning_rate": 1.9999873766852508e-05,
      "loss": 1.5291,
      "step": 590
    },
    {
      "epoch": 0.09628500361068763,
      "grad_norm": 0.2554818093776703,
      "learning_rate": 1.999977170001103e-05,
      "loss": 1.4119,
      "step": 600
    },
    {
      "epoch": 0.09788975367086576,
      "grad_norm": 0.5347756743431091,
      "learning_rate": 1.999963961402578e-05,
      "loss": 1.5833,
      "step": 610
    },
    {
      "epoch": 0.09949450373104389,
      "grad_norm": 0.2503623962402344,
      "learning_rate": 1.999947750929327e-05,
      "loss": 1.5966,
      "step": 620
    },
    {
      "epoch": 0.10109925379122202,
      "grad_norm": 0.24172484874725342,
      "learning_rate": 1.9999285386300132e-05,
      "loss": 1.5476,
      "step": 630
    },
    {
      "epoch": 0.10270400385140015,
      "grad_norm": 0.44592422246932983,
      "learning_rate": 1.9999063245623124e-05,
      "loss": 1.5053,
      "step": 640
    },
    {
      "epoch": 0.10430875391157828,
      "grad_norm": 0.29498621821403503,
      "learning_rate": 1.9998811087929107e-05,
      "loss": 1.5095,
      "step": 650
    },
    {
      "epoch": 0.1059135039717564,
      "grad_norm": 0.22031773626804352,
      "learning_rate": 1.999852891397505e-05,
      "loss": 1.5511,
      "step": 660
    },
    {
      "epoch": 0.10751825403193453,
      "grad_norm": 0.2750484347343445,
      "learning_rate": 1.9998216724608038e-05,
      "loss": 1.4374,
      "step": 670
    },
    {
      "epoch": 0.10912300409211266,
      "grad_norm": 0.16369891166687012,
      "learning_rate": 1.9997874520765257e-05,
      "loss": 1.4311,
      "step": 680
    },
    {
      "epoch": 0.11072775415229077,
      "grad_norm": 0.30632859468460083,
      "learning_rate": 1.9997502303473997e-05,
      "loss": 1.3998,
      "step": 690
    },
    {
      "epoch": 0.1123325042124689,
      "grad_norm": 0.2544844448566437,
      "learning_rate": 1.999710007385165e-05,
      "loss": 1.4906,
      "step": 700
    },
    {
      "epoch": 0.11393725427264703,
      "grad_norm": 0.27073752880096436,
      "learning_rate": 1.9996667833105697e-05,
      "loss": 1.5101,
      "step": 710
    },
    {
      "epoch": 0.11554200433282516,
      "grad_norm": 0.2245398908853531,
      "learning_rate": 1.9996205582533723e-05,
      "loss": 1.3774,
      "step": 720
    },
    {
      "epoch": 0.11714675439300329,
      "grad_norm": 0.19440914690494537,
      "learning_rate": 1.9995713323523395e-05,
      "loss": 1.3311,
      "step": 730
    },
    {
      "epoch": 0.11875150445318142,
      "grad_norm": 0.3126305639743805,
      "learning_rate": 1.9995191057552463e-05,
      "loss": 1.3695,
      "step": 740
    },
    {
      "epoch": 0.12035625451335955,
      "grad_norm": 0.23222993314266205,
      "learning_rate": 1.9994638786188765e-05,
      "loss": 1.2686,
      "step": 750
    },
    {
      "epoch": 0.12196100457353767,
      "grad_norm": 0.21145564317703247,
      "learning_rate": 1.9994056511090206e-05,
      "loss": 1.4826,
      "step": 760
    },
    {
      "epoch": 0.1235657546337158,
      "grad_norm": 0.3231908679008484,
      "learning_rate": 1.999344423400477e-05,
      "loss": 1.4589,
      "step": 770
    },
    {
      "epoch": 0.12517050469389393,
      "grad_norm": 0.3717208802700043,
      "learning_rate": 1.99928019567705e-05,
      "loss": 1.3377,
      "step": 780
    },
    {
      "epoch": 0.12677525475407206,
      "grad_norm": 0.43220949172973633,
      "learning_rate": 1.99921296813155e-05,
      "loss": 1.5013,
      "step": 790
    },
    {
      "epoch": 0.1283800048142502,
      "grad_norm": 0.3270035982131958,
      "learning_rate": 1.9991427409657927e-05,
      "loss": 1.3934,
      "step": 800
    },
    {
      "epoch": 0.12998475487442832,
      "grad_norm": 0.30780377984046936,
      "learning_rate": 1.9990695143906e-05,
      "loss": 1.2953,
      "step": 810
    },
    {
      "epoch": 0.13158950493460644,
      "grad_norm": 0.33227553963661194,
      "learning_rate": 1.9989932886257956e-05,
      "loss": 1.439,
      "step": 820
    },
    {
      "epoch": 0.13319425499478457,
      "grad_norm": 0.28366976976394653,
      "learning_rate": 1.9989140639002087e-05,
      "loss": 1.3491,
      "step": 830
    },
    {
      "epoch": 0.1347990050549627,
      "grad_norm": 0.26644396781921387,
      "learning_rate": 1.9988318404516704e-05,
      "loss": 1.511,
      "step": 840
    },
    {
      "epoch": 0.13640375511514083,
      "grad_norm": 0.4942858815193176,
      "learning_rate": 1.9987466185270136e-05,
      "loss": 1.357,
      "step": 850
    },
    {
      "epoch": 0.13800850517531896,
      "grad_norm": 0.3311348557472229,
      "learning_rate": 1.9986583983820735e-05,
      "loss": 1.3618,
      "step": 860
    },
    {
      "epoch": 0.13961325523549706,
      "grad_norm": 0.31968429684638977,
      "learning_rate": 1.9985671802816856e-05,
      "loss": 1.4922,
      "step": 870
    },
    {
      "epoch": 0.1412180052956752,
      "grad_norm": 0.3222774267196655,
      "learning_rate": 1.9984729644996847e-05,
      "loss": 1.4004,
      "step": 880
    },
    {
      "epoch": 0.14282275535585331,
      "grad_norm": 0.18249015510082245,
      "learning_rate": 1.9983757513189052e-05,
      "loss": 1.5577,
      "step": 890
    },
    {
      "epoch": 0.14442750541603144,
      "grad_norm": 0.42832791805267334,
      "learning_rate": 1.9982755410311797e-05,
      "loss": 1.5892,
      "step": 900
    },
    {
      "epoch": 0.14603225547620957,
      "grad_norm": 0.18397381901741028,
      "learning_rate": 1.9981723339373368e-05,
      "loss": 1.3315,
      "step": 910
    },
    {
      "epoch": 0.1476370055363877,
      "grad_norm": 0.3339751064777374,
      "learning_rate": 1.9980661303472037e-05,
      "loss": 1.5259,
      "step": 920
    },
    {
      "epoch": 0.14924175559656583,
      "grad_norm": 0.3031497001647949,
      "learning_rate": 1.9979569305796007e-05,
      "loss": 1.4001,
      "step": 930
    },
    {
      "epoch": 0.15084650565674396,
      "grad_norm": 0.405518114566803,
      "learning_rate": 1.997844734962344e-05,
      "loss": 1.3445,
      "step": 940
    },
    {
      "epoch": 0.15245125571692208,
      "grad_norm": 0.47668471932411194,
      "learning_rate": 1.9977295438322436e-05,
      "loss": 1.5786,
      "step": 950
    },
    {
      "epoch": 0.1540560057771002,
      "grad_norm": 0.3258664011955261,
      "learning_rate": 1.9976113575351e-05,
      "loss": 1.4733,
      "step": 960
    },
    {
      "epoch": 0.15566075583727834,
      "grad_norm": 0.3526577651500702,
      "learning_rate": 1.9974901764257076e-05,
      "loss": 1.4762,
      "step": 970
    },
    {
      "epoch": 0.15726550589745647,
      "grad_norm": 0.46706467866897583,
      "learning_rate": 1.9973660008678495e-05,
      "loss": 1.3709,
      "step": 980
    },
    {
      "epoch": 0.1588702559576346,
      "grad_norm": 0.21115006506443024,
      "learning_rate": 1.9972388312342985e-05,
      "loss": 1.2211,
      "step": 990
    },
    {
      "epoch": 0.16047500601781273,
      "grad_norm": 0.3447129428386688,
      "learning_rate": 1.9971086679068158e-05,
      "loss": 1.4605,
      "step": 1000
    },
    {
      "epoch": 0.16207975607799086,
      "grad_norm": 0.4207737445831299,
      "learning_rate": 1.9969755112761498e-05,
      "loss": 1.4411,
      "step": 1010
    },
    {
      "epoch": 0.16368450613816898,
      "grad_norm": 0.2579144835472107,
      "learning_rate": 1.9968393617420338e-05,
      "loss": 1.64,
      "step": 1020
    },
    {
      "epoch": 0.1652892561983471,
      "grad_norm": 0.344101220369339,
      "learning_rate": 1.996700219713187e-05,
      "loss": 1.4166,
      "step": 1030
    },
    {
      "epoch": 0.16689400625852524,
      "grad_norm": 0.23667895793914795,
      "learning_rate": 1.996558085607311e-05,
      "loss": 1.3532,
      "step": 1040
    },
    {
      "epoch": 0.16849875631870337,
      "grad_norm": 0.21985171735286713,
      "learning_rate": 1.99641295985109e-05,
      "loss": 1.243,
      "step": 1050
    },
    {
      "epoch": 0.1701035063788815,
      "grad_norm": 0.27326464653015137,
      "learning_rate": 1.996264842880189e-05,
      "loss": 1.3649,
      "step": 1060
    },
    {
      "epoch": 0.17170825643905963,
      "grad_norm": 0.4023990035057068,
      "learning_rate": 1.996113735139253e-05,
      "loss": 1.3713,
      "step": 1070
    },
    {
      "epoch": 0.17331300649923775,
      "grad_norm": 0.3184084892272949,
      "learning_rate": 1.9959596370819044e-05,
      "loss": 1.6325,
      "step": 1080
    },
    {
      "epoch": 0.17491775655941588,
      "grad_norm": 0.26201358437538147,
      "learning_rate": 1.9958025491707433e-05,
      "loss": 1.3561,
      "step": 1090
    },
    {
      "epoch": 0.176522506619594,
      "grad_norm": 0.26962459087371826,
      "learning_rate": 1.9956424718773446e-05,
      "loss": 1.3779,
      "step": 1100
    },
    {
      "epoch": 0.17812725667977214,
      "grad_norm": 0.4136592149734497,
      "learning_rate": 1.995479405682258e-05,
      "loss": 1.3318,
      "step": 1110
    },
    {
      "epoch": 0.17973200673995024,
      "grad_norm": 0.270411878824234,
      "learning_rate": 1.995313351075005e-05,
      "loss": 1.4766,
      "step": 1120
    },
    {
      "epoch": 0.18133675680012837,
      "grad_norm": 0.29305052757263184,
      "learning_rate": 1.9951443085540788e-05,
      "loss": 1.2422,
      "step": 1130
    },
    {
      "epoch": 0.1829415068603065,
      "grad_norm": 0.19487319886684418,
      "learning_rate": 1.9949722786269423e-05,
      "loss": 1.1858,
      "step": 1140
    },
    {
      "epoch": 0.18454625692048462,
      "grad_norm": 0.3168809413909912,
      "learning_rate": 1.9947972618100263e-05,
      "loss": 1.3227,
      "step": 1150
    },
    {
      "epoch": 0.18615100698066275,
      "grad_norm": 0.2984825074672699,
      "learning_rate": 1.9946192586287282e-05,
      "loss": 1.3995,
      "step": 1160
    },
    {
      "epoch": 0.18775575704084088,
      "grad_norm": 0.3263907730579376,
      "learning_rate": 1.994438269617411e-05,
      "loss": 1.3973,
      "step": 1170
    },
    {
      "epoch": 0.189360507101019,
      "grad_norm": 0.44990864396095276,
      "learning_rate": 1.9942542953193998e-05,
      "loss": 1.5862,
      "step": 1180
    },
    {
      "epoch": 0.19096525716119714,
      "grad_norm": 0.2634500563144684,
      "learning_rate": 1.994067336286983e-05,
      "loss": 1.3844,
      "step": 1190
    },
    {
      "epoch": 0.19257000722137527,
      "grad_norm": 0.24371641874313354,
      "learning_rate": 1.993877393081408e-05,
      "loss": 1.4164,
      "step": 1200
    },
    {
      "epoch": 0.1941747572815534,
      "grad_norm": 0.3149561882019043,
      "learning_rate": 1.9936844662728812e-05,
      "loss": 1.4246,
      "step": 1210
    },
    {
      "epoch": 0.19577950734173152,
      "grad_norm": 0.4185996353626251,
      "learning_rate": 1.993488556440566e-05,
      "loss": 1.4373,
      "step": 1220
    },
    {
      "epoch": 0.19738425740190965,
      "grad_norm": 0.22970063984394073,
      "learning_rate": 1.9932896641725797e-05,
      "loss": 1.3437,
      "step": 1230
    },
    {
      "epoch": 0.19898900746208778,
      "grad_norm": 0.2679067850112915,
      "learning_rate": 1.9930877900659938e-05,
      "loss": 1.3521,
      "step": 1240
    },
    {
      "epoch": 0.2005937575222659,
      "grad_norm": 0.2405499666929245,
      "learning_rate": 1.992882934726831e-05,
      "loss": 1.5418,
      "step": 1250
    },
    {
      "epoch": 0.20219850758244404,
      "grad_norm": 0.28226134181022644,
      "learning_rate": 1.992675098770063e-05,
      "loss": 1.3583,
      "step": 1260
    },
    {
      "epoch": 0.20380325764262217,
      "grad_norm": 0.2068435102701187,
      "learning_rate": 1.9924642828196107e-05,
      "loss": 1.3112,
      "step": 1270
    },
    {
      "epoch": 0.2054080077028003,
      "grad_norm": 0.40549182891845703,
      "learning_rate": 1.9922504875083394e-05,
      "loss": 1.4267,
      "step": 1280
    },
    {
      "epoch": 0.20701275776297842,
      "grad_norm": 0.38925135135650635,
      "learning_rate": 1.9920337134780588e-05,
      "loss": 1.3663,
      "step": 1290
    },
    {
      "epoch": 0.20861750782315655,
      "grad_norm": 0.3278457224369049,
      "learning_rate": 1.9918139613795217e-05,
      "loss": 1.4885,
      "step": 1300
    },
    {
      "epoch": 0.21022225788333468,
      "grad_norm": 0.25548163056373596,
      "learning_rate": 1.991591231872419e-05,
      "loss": 1.3177,
      "step": 1310
    },
    {
      "epoch": 0.2118270079435128,
      "grad_norm": 0.2191590666770935,
      "learning_rate": 1.9913655256253815e-05,
      "loss": 1.3191,
      "step": 1320
    },
    {
      "epoch": 0.21343175800369094,
      "grad_norm": 0.3952718675136566,
      "learning_rate": 1.9911368433159754e-05,
      "loss": 1.4215,
      "step": 1330
    },
    {
      "epoch": 0.21503650806386906,
      "grad_norm": 0.40167179703712463,
      "learning_rate": 1.990905185630701e-05,
      "loss": 1.5291,
      "step": 1340
    },
    {
      "epoch": 0.2166412581240472,
      "grad_norm": 0.44336745142936707,
      "learning_rate": 1.990670553264991e-05,
      "loss": 1.37,
      "step": 1350
    },
    {
      "epoch": 0.21824600818422532,
      "grad_norm": 0.4026157557964325,
      "learning_rate": 1.9904329469232076e-05,
      "loss": 1.4131,
      "step": 1360
    },
    {
      "epoch": 0.21985075824440342,
      "grad_norm": 0.33255305886268616,
      "learning_rate": 1.990192367318641e-05,
      "loss": 1.4972,
      "step": 1370
    },
    {
      "epoch": 0.22145550830458155,
      "grad_norm": 0.28011998534202576,
      "learning_rate": 1.989948815173507e-05,
      "loss": 1.3647,
      "step": 1380
    },
    {
      "epoch": 0.22306025836475968,
      "grad_norm": 0.23420965671539307,
      "learning_rate": 1.9897022912189445e-05,
      "loss": 1.3953,
      "step": 1390
    },
    {
      "epoch": 0.2246650084249378,
      "grad_norm": 0.386967271566391,
      "learning_rate": 1.989452796195015e-05,
      "loss": 1.3783,
      "step": 1400
    },
    {
      "epoch": 0.22626975848511593,
      "grad_norm": 0.26505544781684875,
      "learning_rate": 1.989200330850698e-05,
      "loss": 1.4478,
      "step": 1410
    },
    {
      "epoch": 0.22787450854529406,
      "grad_norm": 0.22895698249340057,
      "learning_rate": 1.9889448959438903e-05,
      "loss": 1.4864,
      "step": 1420
    },
    {
      "epoch": 0.2294792586054722,
      "grad_norm": 0.27550992369651794,
      "learning_rate": 1.988686492241403e-05,
      "loss": 1.4158,
      "step": 1430
    },
    {
      "epoch": 0.23108400866565032,
      "grad_norm": 0.4306904375553131,
      "learning_rate": 1.9884251205189593e-05,
      "loss": 1.3682,
      "step": 1440
    },
    {
      "epoch": 0.23268875872582845,
      "grad_norm": 0.21296507120132446,
      "learning_rate": 1.9881607815611927e-05,
      "loss": 1.3884,
      "step": 1450
    },
    {
      "epoch": 0.23429350878600658,
      "grad_norm": 0.24282608926296234,
      "learning_rate": 1.9878934761616447e-05,
      "loss": 1.2864,
      "step": 1460
    },
    {
      "epoch": 0.2358982588461847,
      "grad_norm": 0.36954039335250854,
      "learning_rate": 1.9876232051227613e-05,
      "loss": 1.4983,
      "step": 1470
    },
    {
      "epoch": 0.23750300890636283,
      "grad_norm": 0.34447595477104187,
      "learning_rate": 1.9873499692558914e-05,
      "loss": 1.4084,
      "step": 1480
    },
    {
      "epoch": 0.23910775896654096,
      "grad_norm": 0.423593133687973,
      "learning_rate": 1.9870737693812846e-05,
      "loss": 1.35,
      "step": 1490
    },
    {
      "epoch": 0.2407125090267191,
      "grad_norm": 0.38388440012931824,
      "learning_rate": 1.9867946063280882e-05,
      "loss": 1.389,
      "step": 1500
    },
    {
      "epoch": 0.24231725908689722,
      "grad_norm": 0.3835993707180023,
      "learning_rate": 1.9865124809343447e-05,
      "loss": 1.2998,
      "step": 1510
    },
    {
      "epoch": 0.24392200914707535,
      "grad_norm": 0.6537964344024658,
      "learning_rate": 1.9862273940469898e-05,
      "loss": 1.3418,
      "step": 1520
    },
    {
      "epoch": 0.24552675920725348,
      "grad_norm": 0.29857540130615234,
      "learning_rate": 1.9859393465218497e-05,
      "loss": 1.4264,
      "step": 1530
    },
    {
      "epoch": 0.2471315092674316,
      "grad_norm": 0.36309733986854553,
      "learning_rate": 1.985648339223638e-05,
      "loss": 1.4351,
      "step": 1540
    },
    {
      "epoch": 0.24873625932760973,
      "grad_norm": 0.30575835704803467,
      "learning_rate": 1.9853543730259535e-05,
      "loss": 1.4307,
      "step": 1550
    },
    {
      "epoch": 0.25034100938778786,
      "grad_norm": 0.286000519990921,
      "learning_rate": 1.9850574488112776e-05,
      "loss": 1.3838,
      "step": 1560
    },
    {
      "epoch": 0.251945759447966,
      "grad_norm": 0.2919764220714569,
      "learning_rate": 1.9847575674709723e-05,
      "loss": 1.3995,
      "step": 1570
    },
    {
      "epoch": 0.2535505095081441,
      "grad_norm": 0.30116719007492065,
      "learning_rate": 1.9844547299052756e-05,
      "loss": 1.3908,
      "step": 1580
    },
    {
      "epoch": 0.25515525956832225,
      "grad_norm": 0.3683610260486603,
      "learning_rate": 1.9841489370233012e-05,
      "loss": 1.3468,
      "step": 1590
    },
    {
      "epoch": 0.2567600096285004,
      "grad_norm": 0.32669150829315186,
      "learning_rate": 1.9838401897430336e-05,
      "loss": 1.2323,
      "step": 1600
    },
    {
      "epoch": 0.2583647596886785,
      "grad_norm": 0.3483133316040039,
      "learning_rate": 1.9835284889913275e-05,
      "loss": 1.3231,
      "step": 1610
    },
    {
      "epoch": 0.25996950974885663,
      "grad_norm": 0.3334028422832489,
      "learning_rate": 1.9832138357039024e-05,
      "loss": 1.3346,
      "step": 1620
    },
    {
      "epoch": 0.26157425980903476,
      "grad_norm": 0.2740734815597534,
      "learning_rate": 1.982896230825343e-05,
      "loss": 1.275,
      "step": 1630
    },
    {
      "epoch": 0.2631790098692129,
      "grad_norm": 0.21739724278450012,
      "learning_rate": 1.982575675309093e-05,
      "loss": 1.3771,
      "step": 1640
    },
    {
      "epoch": 0.264783759929391,
      "grad_norm": 0.3791095018386841,
      "learning_rate": 1.982252170117455e-05,
      "loss": 1.3938,
      "step": 1650
    },
    {
      "epoch": 0.26638850998956914,
      "grad_norm": 0.4676331579685211,
      "learning_rate": 1.981925716221586e-05,
      "loss": 1.4098,
      "step": 1660
    },
    {
      "epoch": 0.2679932600497473,
      "grad_norm": 0.42060697078704834,
      "learning_rate": 1.9815963146014948e-05,
      "loss": 1.489,
      "step": 1670
    },
    {
      "epoch": 0.2695980101099254,
      "grad_norm": 0.3207416534423828,
      "learning_rate": 1.9812639662460396e-05,
      "loss": 1.5135,
      "step": 1680
    },
    {
      "epoch": 0.27120276017010353,
      "grad_norm": 0.19730353355407715,
      "learning_rate": 1.9809286721529246e-05,
      "loss": 1.5137,
      "step": 1690
    },
    {
      "epoch": 0.27280751023028166,
      "grad_norm": 0.22617162764072418,
      "learning_rate": 1.980590433328697e-05,
      "loss": 1.4917,
      "step": 1700
    },
    {
      "epoch": 0.2744122602904598,
      "grad_norm": 0.3663794994354248,
      "learning_rate": 1.9802492507887434e-05,
      "loss": 1.3597,
      "step": 1710
    },
    {
      "epoch": 0.2760170103506379,
      "grad_norm": 0.3326999843120575,
      "learning_rate": 1.9799051255572884e-05,
      "loss": 1.2681,
      "step": 1720
    },
    {
      "epoch": 0.27762176041081604,
      "grad_norm": 0.3930642008781433,
      "learning_rate": 1.97955805866739e-05,
      "loss": 1.501,
      "step": 1730
    },
    {
      "epoch": 0.2792265104709941,
      "grad_norm": 0.34715524315834045,
      "learning_rate": 1.9792080511609372e-05,
      "loss": 1.3983,
      "step": 1740
    },
    {
      "epoch": 0.28083126053117224,
      "grad_norm": 0.36794325709342957,
      "learning_rate": 1.9788551040886465e-05,
      "loss": 1.378,
      "step": 1750
    },
    {
      "epoch": 0.2824360105913504,
      "grad_norm": 0.2995903193950653,
      "learning_rate": 1.9784992185100585e-05,
      "loss": 1.4939,
      "step": 1760
    },
    {
      "epoch": 0.2840407606515285,
      "grad_norm": 0.2723531723022461,
      "learning_rate": 1.9781403954935365e-05,
      "loss": 1.4785,
      "step": 1770
    },
    {
      "epoch": 0.28564551071170663,
      "grad_norm": 0.3530333638191223,
      "learning_rate": 1.97777863611626e-05,
      "loss": 1.4255,
      "step": 1780
    },
    {
      "epoch": 0.28725026077188476,
      "grad_norm": 0.3557887077331543,
      "learning_rate": 1.9774139414642256e-05,
      "loss": 1.381,
      "step": 1790
    },
    {
      "epoch": 0.2888550108320629,
      "grad_norm": 0.3029628098011017,
      "learning_rate": 1.9770463126322396e-05,
      "loss": 1.3856,
      "step": 1800
    },
    {
      "epoch": 0.290459760892241,
      "grad_norm": 0.30022427439689636,
      "learning_rate": 1.976675750723918e-05,
      "loss": 1.2598,
      "step": 1810
    },
    {
      "epoch": 0.29206451095241914,
      "grad_norm": 0.25942111015319824,
      "learning_rate": 1.976302256851681e-05,
      "loss": 1.369,
      "step": 1820
    },
    {
      "epoch": 0.29366926101259727,
      "grad_norm": 0.39943525195121765,
      "learning_rate": 1.9759258321367506e-05,
      "loss": 1.2573,
      "step": 1830
    },
    {
      "epoch": 0.2952740110727754,
      "grad_norm": 0.28279179334640503,
      "learning_rate": 1.9755464777091477e-05,
      "loss": 1.4102,
      "step": 1840
    },
    {
      "epoch": 0.29687876113295353,
      "grad_norm": 0.31728804111480713,
      "learning_rate": 1.9751641947076877e-05,
      "loss": 1.3843,
      "step": 1850
    },
    {
      "epoch": 0.29848351119313166,
      "grad_norm": 0.39161691069602966,
      "learning_rate": 1.974778984279978e-05,
      "loss": 1.3455,
      "step": 1860
    },
    {
      "epoch": 0.3000882612533098,
      "grad_norm": 0.40414389967918396,
      "learning_rate": 1.9743908475824134e-05,
      "loss": 1.3299,
      "step": 1870
    },
    {
      "epoch": 0.3016930113134879,
      "grad_norm": 0.3219362497329712,
      "learning_rate": 1.9739997857801737e-05,
      "loss": 1.3351,
      "step": 1880
    },
    {
      "epoch": 0.30329776137366604,
      "grad_norm": 0.4149847626686096,
      "learning_rate": 1.9736058000472195e-05,
      "loss": 1.2271,
      "step": 1890
    },
    {
      "epoch": 0.30490251143384417,
      "grad_norm": 0.2929013967514038,
      "learning_rate": 1.9732088915662895e-05,
      "loss": 1.2845,
      "step": 1900
    },
    {
      "epoch": 0.3065072614940223,
      "grad_norm": 0.23451751470565796,
      "learning_rate": 1.972809061528896e-05,
      "loss": 1.5366,
      "step": 1910
    },
    {
      "epoch": 0.3081120115542004,
      "grad_norm": 0.46130135655403137,
      "learning_rate": 1.972406311135322e-05,
      "loss": 1.338,
      "step": 1920
    },
    {
      "epoch": 0.30971676161437856,
      "grad_norm": 0.2804974615573883,
      "learning_rate": 1.9720006415946175e-05,
      "loss": 1.4128,
      "step": 1930
    },
    {
      "epoch": 0.3113215116745567,
      "grad_norm": 0.36125385761260986,
      "learning_rate": 1.9715920541245956e-05,
      "loss": 1.3309,
      "step": 1940
    },
    {
      "epoch": 0.3129262617347348,
      "grad_norm": 0.40560418367385864,
      "learning_rate": 1.9711805499518287e-05,
      "loss": 1.5499,
      "step": 1950
    },
    {
      "epoch": 0.31453101179491294,
      "grad_norm": 0.17646387219429016,
      "learning_rate": 1.970766130311645e-05,
      "loss": 1.5559,
      "step": 1960
    },
    {
      "epoch": 0.31613576185509107,
      "grad_norm": 0.3691346049308777,
      "learning_rate": 1.9703487964481255e-05,
      "loss": 1.3178,
      "step": 1970
    },
    {
      "epoch": 0.3177405119152692,
      "grad_norm": 0.2070036679506302,
      "learning_rate": 1.9699285496140992e-05,
      "loss": 1.3373,
      "step": 1980
    },
    {
      "epoch": 0.3193452619754473,
      "grad_norm": 0.5338124632835388,
      "learning_rate": 1.9695053910711402e-05,
      "loss": 1.4328,
      "step": 1990
    },
    {
      "epoch": 0.32095001203562545,
      "grad_norm": 0.2903488874435425,
      "learning_rate": 1.969079322089563e-05,
      "loss": 1.4666,
      "step": 2000
    },
    {
      "epoch": 0.3225547620958036,
      "grad_norm": 0.3406471312046051,
      "learning_rate": 1.9686503439484193e-05,
      "loss": 1.522,
      "step": 2010
    },
    {
      "epoch": 0.3241595121559817,
      "grad_norm": 0.3346569836139679,
      "learning_rate": 1.9682184579354943e-05,
      "loss": 1.2533,
      "step": 2020
    },
    {
      "epoch": 0.32576426221615984,
      "grad_norm": 0.467851847410202,
      "learning_rate": 1.9677836653473025e-05,
      "loss": 1.2884,
      "step": 2030
    },
    {
      "epoch": 0.32736901227633797,
      "grad_norm": 0.25201156735420227,
      "learning_rate": 1.967345967489084e-05,
      "loss": 1.2345,
      "step": 2040
    },
    {
      "epoch": 0.3289737623365161,
      "grad_norm": 0.292625367641449,
      "learning_rate": 1.9669053656747998e-05,
      "loss": 1.2452,
      "step": 2050
    },
    {
      "epoch": 0.3305785123966942,
      "grad_norm": 0.3019048571586609,
      "learning_rate": 1.9664618612271292e-05,
      "loss": 1.4723,
      "step": 2060
    },
    {
      "epoch": 0.33218326245687235,
      "grad_norm": 0.28457310795783997,
      "learning_rate": 1.966015455477465e-05,
      "loss": 1.5676,
      "step": 2070
    },
    {
      "epoch": 0.3337880125170505,
      "grad_norm": 0.2934150695800781,
      "learning_rate": 1.9655661497659096e-05,
      "loss": 1.5,
      "step": 2080
    },
    {
      "epoch": 0.3353927625772286,
      "grad_norm": 0.2713722884654999,
      "learning_rate": 1.9651139454412707e-05,
      "loss": 1.3849,
      "step": 2090
    },
    {
      "epoch": 0.33699751263740674,
      "grad_norm": 0.35259222984313965,
      "learning_rate": 1.964658843861059e-05,
      "loss": 1.3197,
      "step": 2100
    },
    {
      "epoch": 0.33860226269758487,
      "grad_norm": 0.23005594313144684,
      "learning_rate": 1.9642008463914807e-05,
      "loss": 1.3221,
      "step": 2110
    },
    {
      "epoch": 0.340207012757763,
      "grad_norm": 0.30540376901626587,
      "learning_rate": 1.9637399544074368e-05,
      "loss": 1.4508,
      "step": 2120
    },
    {
      "epoch": 0.3418117628179411,
      "grad_norm": 0.40802201628685,
      "learning_rate": 1.963276169292517e-05,
      "loss": 1.3976,
      "step": 2130
    },
    {
      "epoch": 0.34341651287811925,
      "grad_norm": 0.42711758613586426,
      "learning_rate": 1.962809492438997e-05,
      "loss": 1.3909,
      "step": 2140
    },
    {
      "epoch": 0.3450212629382974,
      "grad_norm": 0.26663872599601746,
      "learning_rate": 1.9623399252478316e-05,
      "loss": 1.3637,
      "step": 2150
    },
    {
      "epoch": 0.3466260129984755,
      "grad_norm": 0.49782994389533997,
      "learning_rate": 1.9618674691286537e-05,
      "loss": 1.3991,
      "step": 2160
    },
    {
      "epoch": 0.34823076305865364,
      "grad_norm": 0.34774404764175415,
      "learning_rate": 1.961392125499769e-05,
      "loss": 1.4745,
      "step": 2170
    },
    {
      "epoch": 0.34983551311883176,
      "grad_norm": 0.4350658059120178,
      "learning_rate": 1.960913895788151e-05,
      "loss": 1.3528,
      "step": 2180
    },
    {
      "epoch": 0.3514402631790099,
      "grad_norm": 0.30385681986808777,
      "learning_rate": 1.9604327814294363e-05,
      "loss": 1.2378,
      "step": 2190
    },
    {
      "epoch": 0.353045013239188,
      "grad_norm": 0.2511212229728699,
      "learning_rate": 1.959948783867923e-05,
      "loss": 1.2355,
      "step": 2200
    },
    {
      "epoch": 0.35464976329936615,
      "grad_norm": 0.30395057797431946,
      "learning_rate": 1.959461904556563e-05,
      "loss": 1.2358,
      "step": 2210
    },
    {
      "epoch": 0.3562545133595443,
      "grad_norm": 0.457220196723938,
      "learning_rate": 1.9589721449569595e-05,
      "loss": 1.2964,
      "step": 2220
    },
    {
      "epoch": 0.35785926341972235,
      "grad_norm": 0.272195965051651,
      "learning_rate": 1.9584795065393633e-05,
      "loss": 1.2718,
      "step": 2230
    },
    {
      "epoch": 0.3594640134799005,
      "grad_norm": 0.3350317180156708,
      "learning_rate": 1.9579839907826655e-05,
      "loss": 1.2571,
      "step": 2240
    },
    {
      "epoch": 0.3610687635400786,
      "grad_norm": 0.351938933134079,
      "learning_rate": 1.957485599174396e-05,
      "loss": 1.3015,
      "step": 2250
    },
    {
      "epoch": 0.36267351360025674,
      "grad_norm": 0.37047067284584045,
      "learning_rate": 1.9569843332107186e-05,
      "loss": 1.2551,
      "step": 2260
    },
    {
      "epoch": 0.36427826366043486,
      "grad_norm": 0.2948170304298401,
      "learning_rate": 1.9564801943964246e-05,
      "loss": 1.3673,
      "step": 2270
    },
    {
      "epoch": 0.365883013720613,
      "grad_norm": 0.4895157516002655,
      "learning_rate": 1.9559731842449303e-05,
      "loss": 1.4032,
      "step": 2280
    },
    {
      "epoch": 0.3674877637807911,
      "grad_norm": 0.29684463143348694,
      "learning_rate": 1.9554633042782717e-05,
      "loss": 1.356,
      "step": 2290
    },
    {
      "epoch": 0.36909251384096925,
      "grad_norm": 0.3872864246368408,
      "learning_rate": 1.9549505560270993e-05,
      "loss": 1.3124,
      "step": 2300
    },
    {
      "epoch": 0.3706972639011474,
      "grad_norm": 0.39776426553726196,
      "learning_rate": 1.954434941030675e-05,
      "loss": 1.3806,
      "step": 2310
    },
    {
      "epoch": 0.3723020139613255,
      "grad_norm": 0.2617858648300171,
      "learning_rate": 1.9539164608368657e-05,
      "loss": 1.3603,
      "step": 2320
    },
    {
      "epoch": 0.37390676402150363,
      "grad_norm": 0.38514503836631775,
      "learning_rate": 1.953395117002141e-05,
      "loss": 1.4355,
      "step": 2330
    },
    {
      "epoch": 0.37551151408168176,
      "grad_norm": 0.30052679777145386,
      "learning_rate": 1.952870911091565e-05,
      "loss": 1.3452,
      "step": 2340
    },
    {
      "epoch": 0.3771162641418599,
      "grad_norm": 0.3276200592517853,
      "learning_rate": 1.952343844678796e-05,
      "loss": 1.3827,
      "step": 2350
    },
    {
      "epoch": 0.378721014202038,
      "grad_norm": 0.2065112441778183,
      "learning_rate": 1.9518139193460775e-05,
      "loss": 1.218,
      "step": 2360
    },
    {
      "epoch": 0.38032576426221615,
      "grad_norm": 0.3966623544692993,
      "learning_rate": 1.9512811366842367e-05,
      "loss": 1.4419,
      "step": 2370
    },
    {
      "epoch": 0.3819305143223943,
      "grad_norm": 0.3066747784614563,
      "learning_rate": 1.950745498292678e-05,
      "loss": 1.6141,
      "step": 2380
    },
    {
      "epoch": 0.3835352643825724,
      "grad_norm": 0.4463857412338257,
      "learning_rate": 1.950207005779379e-05,
      "loss": 1.4721,
      "step": 2390
    },
    {
      "epoch": 0.38514001444275053,
      "grad_norm": 0.41368722915649414,
      "learning_rate": 1.9496656607608845e-05,
      "loss": 1.3954,
      "step": 2400
    },
    {
      "epoch": 0.38674476450292866,
      "grad_norm": 0.3056279718875885,
      "learning_rate": 1.949121464862303e-05,
      "loss": 1.3686,
      "step": 2410
    },
    {
      "epoch": 0.3883495145631068,
      "grad_norm": 0.5210683941841125,
      "learning_rate": 1.9485744197173016e-05,
      "loss": 1.5396,
      "step": 2420
    },
    {
      "epoch": 0.3899542646232849,
      "grad_norm": 0.35678398609161377,
      "learning_rate": 1.9480245269681006e-05,
      "loss": 1.2616,
      "step": 2430
    },
    {
      "epoch": 0.39155901468346305,
      "grad_norm": 0.3954680263996124,
      "learning_rate": 1.9474717882654682e-05,
      "loss": 1.2884,
      "step": 2440
    },
    {
      "epoch": 0.3931637647436412,
      "grad_norm": 0.412992924451828,
      "learning_rate": 1.9469162052687166e-05,
      "loss": 1.5022,
      "step": 2450
    },
    {
      "epoch": 0.3947685148038193,
      "grad_norm": 0.43660473823547363,
      "learning_rate": 1.946357779645697e-05,
      "loss": 1.1959,
      "step": 2460
    },
    {
      "epoch": 0.39637326486399743,
      "grad_norm": 0.35781991481781006,
      "learning_rate": 1.945796513072793e-05,
      "loss": 1.2859,
      "step": 2470
    },
    {
      "epoch": 0.39797801492417556,
      "grad_norm": 0.3486938774585724,
      "learning_rate": 1.945232407234918e-05,
      "loss": 1.3424,
      "step": 2480
    },
    {
      "epoch": 0.3995827649843537,
      "grad_norm": 0.41157066822052,
      "learning_rate": 1.9446654638255066e-05,
      "loss": 1.3515,
      "step": 2490
    },
    {
      "epoch": 0.4011875150445318,
      "grad_norm": 0.2521686851978302,
      "learning_rate": 1.944095684546515e-05,
      "loss": 1.2965,
      "step": 2500
    },
    {
      "epoch": 0.40279226510470995,
      "grad_norm": 0.3465510308742523,
      "learning_rate": 1.9435230711084093e-05,
      "loss": 1.3103,
      "step": 2510
    },
    {
      "epoch": 0.4043970151648881,
      "grad_norm": 0.4512653350830078,
      "learning_rate": 1.9429476252301667e-05,
      "loss": 1.3535,
      "step": 2520
    },
    {
      "epoch": 0.4060017652250662,
      "grad_norm": 0.22823373973369598,
      "learning_rate": 1.942369348639265e-05,
      "loss": 1.2815,
      "step": 2530
    },
    {
      "epoch": 0.40760651528524433,
      "grad_norm": 0.2904421389102936,
      "learning_rate": 1.9417882430716806e-05,
      "loss": 1.274,
      "step": 2540
    },
    {
      "epoch": 0.40921126534542246,
      "grad_norm": 0.22718197107315063,
      "learning_rate": 1.9412043102718826e-05,
      "loss": 1.3225,
      "step": 2550
    },
    {
      "epoch": 0.4108160154056006,
      "grad_norm": 0.36589524149894714,
      "learning_rate": 1.9406175519928277e-05,
      "loss": 1.3205,
      "step": 2560
    },
    {
      "epoch": 0.4124207654657787,
      "grad_norm": 0.2226024568080902,
      "learning_rate": 1.940027969995954e-05,
      "loss": 1.3326,
      "step": 2570
    },
    {
      "epoch": 0.41402551552595684,
      "grad_norm": 0.32647380232810974,
      "learning_rate": 1.9394355660511764e-05,
      "loss": 1.3379,
      "step": 2580
    },
    {
      "epoch": 0.415630265586135,
      "grad_norm": 0.4311791658401489,
      "learning_rate": 1.9388403419368815e-05,
      "loss": 1.3571,
      "step": 2590
    },
    {
      "epoch": 0.4172350156463131,
      "grad_norm": 0.3705790638923645,
      "learning_rate": 1.938242299439922e-05,
      "loss": 1.3533,
      "step": 2600
    },
    {
      "epoch": 0.41883976570649123,
      "grad_norm": 0.243331179022789,
      "learning_rate": 1.937641440355611e-05,
      "loss": 1.4036,
      "step": 2610
    },
    {
      "epoch": 0.42044451576666936,
      "grad_norm": 0.4500161111354828,
      "learning_rate": 1.9370377664877174e-05,
      "loss": 1.4308,
      "step": 2620
    },
    {
      "epoch": 0.4220492658268475,
      "grad_norm": 0.3864496052265167,
      "learning_rate": 1.9364312796484602e-05,
      "loss": 1.3605,
      "step": 2630
    },
    {
      "epoch": 0.4236540158870256,
      "grad_norm": 0.33515220880508423,
      "learning_rate": 1.9358219816585022e-05,
      "loss": 1.3077,
      "step": 2640
    },
    {
      "epoch": 0.42525876594720374,
      "grad_norm": 0.5244264006614685,
      "learning_rate": 1.9352098743469453e-05,
      "loss": 1.2898,
      "step": 2650
    },
    {
      "epoch": 0.42686351600738187,
      "grad_norm": 0.31695449352264404,
      "learning_rate": 1.9345949595513257e-05,
      "loss": 1.4166,
      "step": 2660
    },
    {
      "epoch": 0.42846826606756,
      "grad_norm": 0.30906620621681213,
      "learning_rate": 1.9339772391176065e-05,
      "loss": 1.5144,
      "step": 2670
    },
    {
      "epoch": 0.43007301612773813,
      "grad_norm": 0.39018145203590393,
      "learning_rate": 1.9333567149001742e-05,
      "loss": 1.4156,
      "step": 2680
    },
    {
      "epoch": 0.43167776618791626,
      "grad_norm": 0.5267777442932129,
      "learning_rate": 1.932733388761832e-05,
      "loss": 1.4698,
      "step": 2690
    },
    {
      "epoch": 0.4332825162480944,
      "grad_norm": 0.4009230434894562,
      "learning_rate": 1.9321072625737943e-05,
      "loss": 1.3226,
      "step": 2700
    },
    {
      "epoch": 0.4348872663082725,
      "grad_norm": 0.3111720383167267,
      "learning_rate": 1.931478338215681e-05,
      "loss": 1.4184,
      "step": 2710
    },
    {
      "epoch": 0.43649201636845064,
      "grad_norm": 0.31122878193855286,
      "learning_rate": 1.930846617575513e-05,
      "loss": 1.2398,
      "step": 2720
    },
    {
      "epoch": 0.4380967664286287,
      "grad_norm": 0.40437036752700806,
      "learning_rate": 1.9302121025497037e-05,
      "loss": 1.3129,
      "step": 2730
    },
    {
      "epoch": 0.43970151648880684,
      "grad_norm": 0.3509606420993805,
      "learning_rate": 1.9295747950430575e-05,
      "loss": 1.3335,
      "step": 2740
    },
    {
      "epoch": 0.44130626654898497,
      "grad_norm": 0.3115660548210144,
      "learning_rate": 1.9289346969687598e-05,
      "loss": 1.3304,
      "step": 2750
    },
    {
      "epoch": 0.4429110166091631,
      "grad_norm": 0.30947375297546387,
      "learning_rate": 1.928291810248374e-05,
      "loss": 1.2904,
      "step": 2760
    },
    {
      "epoch": 0.44451576666934123,
      "grad_norm": 0.3383250832557678,
      "learning_rate": 1.927646136811836e-05,
      "loss": 1.3329,
      "step": 2770
    },
    {
      "epoch": 0.44612051672951936,
      "grad_norm": 0.4008086323738098,
      "learning_rate": 1.9269976785974456e-05,
      "loss": 1.364,
      "step": 2780
    },
    {
      "epoch": 0.4477252667896975,
      "grad_norm": 0.28436827659606934,
      "learning_rate": 1.9263464375518634e-05,
      "loss": 1.3141,
      "step": 2790
    },
    {
      "epoch": 0.4493300168498756,
      "grad_norm": 0.40010377764701843,
      "learning_rate": 1.9256924156301046e-05,
      "loss": 1.332,
      "step": 2800
    },
    {
      "epoch": 0.45093476691005374,
      "grad_norm": 0.37946265935897827,
      "learning_rate": 1.9250356147955308e-05,
      "loss": 1.2775,
      "step": 2810
    },
    {
      "epoch": 0.45253951697023187,
      "grad_norm": 0.3174775540828705,
      "learning_rate": 1.9243760370198475e-05,
      "loss": 1.4392,
      "step": 2820
    },
    {
      "epoch": 0.45414426703041,
      "grad_norm": 0.3594072461128235,
      "learning_rate": 1.9237136842830953e-05,
      "loss": 1.4264,
      "step": 2830
    },
    {
      "epoch": 0.4557490170905881,
      "grad_norm": 0.32715851068496704,
      "learning_rate": 1.923048558573647e-05,
      "loss": 1.3317,
      "step": 2840
    },
    {
      "epoch": 0.45735376715076625,
      "grad_norm": 0.30426010489463806,
      "learning_rate": 1.9223806618881974e-05,
      "loss": 1.2423,
      "step": 2850
    },
    {
      "epoch": 0.4589585172109444,
      "grad_norm": 0.31703969836235046,
      "learning_rate": 1.9217099962317614e-05,
      "loss": 1.199,
      "step": 2860
    },
    {
      "epoch": 0.4605632672711225,
      "grad_norm": 0.2574061155319214,
      "learning_rate": 1.9210365636176664e-05,
      "loss": 1.458,
      "step": 2870
    },
    {
      "epoch": 0.46216801733130064,
      "grad_norm": 0.3669300079345703,
      "learning_rate": 1.9203603660675445e-05,
      "loss": 1.1514,
      "step": 2880
    },
    {
      "epoch": 0.46377276739147877,
      "grad_norm": 0.5132482647895813,
      "learning_rate": 1.91968140561133e-05,
      "loss": 1.3781,
      "step": 2890
    },
    {
      "epoch": 0.4653775174516569,
      "grad_norm": 0.4987383186817169,
      "learning_rate": 1.9189996842872504e-05,
      "loss": 1.2753,
      "step": 2900
    },
    {
      "epoch": 0.466982267511835,
      "grad_norm": 0.6567516922950745,
      "learning_rate": 1.9183152041418212e-05,
      "loss": 1.331,
      "step": 2910
    },
    {
      "epoch": 0.46858701757201315,
      "grad_norm": 0.457297146320343,
      "learning_rate": 1.9176279672298403e-05,
      "loss": 1.2382,
      "step": 2920
    },
    {
      "epoch": 0.4701917676321913,
      "grad_norm": 0.3900405764579773,
      "learning_rate": 1.9169379756143814e-05,
      "loss": 1.3317,
      "step": 2930
    },
    {
      "epoch": 0.4717965176923694,
      "grad_norm": 0.46646952629089355,
      "learning_rate": 1.916245231366787e-05,
      "loss": 1.1852,
      "step": 2940
    },
    {
      "epoch": 0.47340126775254754,
      "grad_norm": 0.2655135691165924,
      "learning_rate": 1.9155497365666642e-05,
      "loss": 1.2231,
      "step": 2950
    },
    {
      "epoch": 0.47500601781272567,
      "grad_norm": 0.4266279637813568,
      "learning_rate": 1.9148514933018758e-05,
      "loss": 1.4414,
      "step": 2960
    },
    {
      "epoch": 0.4766107678729038,
      "grad_norm": 0.4702107906341553,
      "learning_rate": 1.9141505036685366e-05,
      "loss": 1.3614,
      "step": 2970
    },
    {
      "epoch": 0.4782155179330819,
      "grad_norm": 0.3613738715648651,
      "learning_rate": 1.9134467697710052e-05,
      "loss": 1.3396,
      "step": 2980
    },
    {
      "epoch": 0.47982026799326005,
      "grad_norm": 0.3401474952697754,
      "learning_rate": 1.912740293721879e-05,
      "loss": 1.5286,
      "step": 2990
    },
    {
      "epoch": 0.4814250180534382,
      "grad_norm": 0.3083174526691437,
      "learning_rate": 1.912031077641987e-05,
      "loss": 1.2264,
      "step": 3000
    },
    {
      "epoch": 0.4830297681136163,
      "grad_norm": 0.5213725566864014,
      "learning_rate": 1.9113191236603835e-05,
      "loss": 1.36,
      "step": 3010
    },
    {
      "epoch": 0.48463451817379444,
      "grad_norm": 0.3317253589630127,
      "learning_rate": 1.9106044339143427e-05,
      "loss": 1.4199,
      "step": 3020
    },
    {
      "epoch": 0.48623926823397257,
      "grad_norm": 0.548594057559967,
      "learning_rate": 1.9098870105493504e-05,
      "loss": 1.2182,
      "step": 3030
    },
    {
      "epoch": 0.4878440182941507,
      "grad_norm": 0.40180525183677673,
      "learning_rate": 1.9091668557190996e-05,
      "loss": 1.2334,
      "step": 3040
    },
    {
      "epoch": 0.4894487683543288,
      "grad_norm": 0.3728240430355072,
      "learning_rate": 1.9084439715854828e-05,
      "loss": 1.483,
      "step": 3050
    },
    {
      "epoch": 0.49105351841450695,
      "grad_norm": 0.30843567848205566,
      "learning_rate": 1.9077183603185858e-05,
      "loss": 1.5069,
      "step": 3060
    },
    {
      "epoch": 0.4926582684746851,
      "grad_norm": 0.3186185657978058,
      "learning_rate": 1.906990024096681e-05,
      "loss": 1.2054,
      "step": 3070
    },
    {
      "epoch": 0.4942630185348632,
      "grad_norm": 0.4824373424053192,
      "learning_rate": 1.9062589651062215e-05,
      "loss": 1.4438,
      "step": 3080
    },
    {
      "epoch": 0.49586776859504134,
      "grad_norm": 0.2819381356239319,
      "learning_rate": 1.9055251855418343e-05,
      "loss": 1.2917,
      "step": 3090
    },
    {
      "epoch": 0.49747251865521946,
      "grad_norm": 0.34851837158203125,
      "learning_rate": 1.9047886876063124e-05,
      "loss": 1.5048,
      "step": 3100
    },
    {
      "epoch": 0.4990772687153976,
      "grad_norm": 0.3761436641216278,
      "learning_rate": 1.90404947351061e-05,
      "loss": 1.2536,
      "step": 3110
    },
    {
      "epoch": 0.5006820187755757,
      "grad_norm": 0.27981412410736084,
      "learning_rate": 1.903307545473836e-05,
      "loss": 1.2497,
      "step": 3120
    },
    {
      "epoch": 0.5022867688357538,
      "grad_norm": 0.36180564761161804,
      "learning_rate": 1.902562905723245e-05,
      "loss": 1.3459,
      "step": 3130
    },
    {
      "epoch": 0.503891518895932,
      "grad_norm": 0.36484453082084656,
      "learning_rate": 1.901815556494233e-05,
      "loss": 1.4141,
      "step": 3140
    },
    {
      "epoch": 0.5054962689561101,
      "grad_norm": 0.23243507742881775,
      "learning_rate": 1.9010655000303296e-05,
      "loss": 1.4432,
      "step": 3150
    },
    {
      "epoch": 0.5071010190162882,
      "grad_norm": 0.35065749287605286,
      "learning_rate": 1.9003127385831915e-05,
      "loss": 1.3832,
      "step": 3160
    },
    {
      "epoch": 0.5087057690764664,
      "grad_norm": 0.4324915409088135,
      "learning_rate": 1.8995572744125957e-05,
      "loss": 1.4079,
      "step": 3170
    },
    {
      "epoch": 0.5103105191366445,
      "grad_norm": 0.4284380078315735,
      "learning_rate": 1.898799109786433e-05,
      "loss": 1.5292,
      "step": 3180
    },
    {
      "epoch": 0.5119152691968226,
      "grad_norm": 0.3151065707206726,
      "learning_rate": 1.8980382469807003e-05,
      "loss": 1.5696,
      "step": 3190
    },
    {
      "epoch": 0.5135200192570007,
      "grad_norm": 0.3540195822715759,
      "learning_rate": 1.8972746882794947e-05,
      "loss": 1.2148,
      "step": 3200
    },
    {
      "epoch": 0.5151247693171789,
      "grad_norm": 0.3250848352909088,
      "learning_rate": 1.8965084359750063e-05,
      "loss": 1.3675,
      "step": 3210
    },
    {
      "epoch": 0.516729519377357,
      "grad_norm": 0.5598359107971191,
      "learning_rate": 1.895739492367512e-05,
      "loss": 1.3954,
      "step": 3220
    },
    {
      "epoch": 0.5183342694375351,
      "grad_norm": 0.48755258321762085,
      "learning_rate": 1.8949678597653667e-05,
      "loss": 1.2994,
      "step": 3230
    },
    {
      "epoch": 0.5199390194977133,
      "grad_norm": 0.4555019438266754,
      "learning_rate": 1.8941935404849987e-05,
      "loss": 1.4163,
      "step": 3240
    },
    {
      "epoch": 0.5215437695578914,
      "grad_norm": 0.423035204410553,
      "learning_rate": 1.8934165368509012e-05,
      "loss": 1.3923,
      "step": 3250
    },
    {
      "epoch": 0.5231485196180695,
      "grad_norm": 0.3289142847061157,
      "learning_rate": 1.8926368511956256e-05,
      "loss": 1.3082,
      "step": 3260
    },
    {
      "epoch": 0.5247532696782476,
      "grad_norm": 0.49323341250419617,
      "learning_rate": 1.8918544858597755e-05,
      "loss": 1.4025,
      "step": 3270
    },
    {
      "epoch": 0.5263580197384258,
      "grad_norm": 0.3933897316455841,
      "learning_rate": 1.8910694431919974e-05,
      "loss": 1.3069,
      "step": 3280
    },
    {
      "epoch": 0.5279627697986039,
      "grad_norm": 0.3914484977722168,
      "learning_rate": 1.8902817255489766e-05,
      "loss": 1.4352,
      "step": 3290
    },
    {
      "epoch": 0.529567519858782,
      "grad_norm": 0.36485975980758667,
      "learning_rate": 1.8894913352954282e-05,
      "loss": 1.2946,
      "step": 3300
    },
    {
      "epoch": 0.5311722699189602,
      "grad_norm": 0.49147748947143555,
      "learning_rate": 1.8886982748040892e-05,
      "loss": 1.3534,
      "step": 3310
    },
    {
      "epoch": 0.5327770199791383,
      "grad_norm": 0.5096155405044556,
      "learning_rate": 1.8879025464557146e-05,
      "loss": 1.309,
      "step": 3320
    },
    {
      "epoch": 0.5343817700393164,
      "grad_norm": 0.3081822395324707,
      "learning_rate": 1.8871041526390673e-05,
      "loss": 1.3639,
      "step": 3330
    },
    {
      "epoch": 0.5359865200994945,
      "grad_norm": 0.3889482617378235,
      "learning_rate": 1.886303095750911e-05,
      "loss": 1.2441,
      "step": 3340
    },
    {
      "epoch": 0.5375912701596727,
      "grad_norm": 0.4356420040130615,
      "learning_rate": 1.885499378196006e-05,
      "loss": 1.3678,
      "step": 3350
    },
    {
      "epoch": 0.5391960202198508,
      "grad_norm": 0.40843820571899414,
      "learning_rate": 1.8846930023870977e-05,
      "loss": 1.309,
      "step": 3360
    },
    {
      "epoch": 0.5408007702800289,
      "grad_norm": 0.39451417326927185,
      "learning_rate": 1.883883970744913e-05,
      "loss": 1.2417,
      "step": 3370
    },
    {
      "epoch": 0.5424055203402071,
      "grad_norm": 0.3055882155895233,
      "learning_rate": 1.8830722856981508e-05,
      "loss": 1.2256,
      "step": 3380
    },
    {
      "epoch": 0.5440102704003852,
      "grad_norm": 0.4477522671222687,
      "learning_rate": 1.8822579496834762e-05,
      "loss": 1.4449,
      "step": 3390
    },
    {
      "epoch": 0.5456150204605633,
      "grad_norm": 0.36812475323677063,
      "learning_rate": 1.8814409651455115e-05,
      "loss": 1.2899,
      "step": 3400
    },
    {
      "epoch": 0.5472197705207414,
      "grad_norm": 0.38545629382133484,
      "learning_rate": 1.8806213345368304e-05,
      "loss": 1.1903,
      "step": 3410
    },
    {
      "epoch": 0.5488245205809196,
      "grad_norm": 0.35380756855010986,
      "learning_rate": 1.8797990603179505e-05,
      "loss": 1.4448,
      "step": 3420
    },
    {
      "epoch": 0.5504292706410977,
      "grad_norm": 0.506960391998291,
      "learning_rate": 1.8789741449573243e-05,
      "loss": 1.2862,
      "step": 3430
    },
    {
      "epoch": 0.5520340207012758,
      "grad_norm": 0.3036964535713196,
      "learning_rate": 1.878146590931334e-05,
      "loss": 1.2406,
      "step": 3440
    },
    {
      "epoch": 0.553638770761454,
      "grad_norm": 0.4081314504146576,
      "learning_rate": 1.877316400724282e-05,
      "loss": 1.4669,
      "step": 3450
    },
    {
      "epoch": 0.5552435208216321,
      "grad_norm": 0.35533151030540466,
      "learning_rate": 1.876483576828386e-05,
      "loss": 1.2666,
      "step": 3460
    },
    {
      "epoch": 0.5568482708818101,
      "grad_norm": 0.4648311138153076,
      "learning_rate": 1.8756481217437685e-05,
      "loss": 1.3472,
      "step": 3470
    },
    {
      "epoch": 0.5584530209419882,
      "grad_norm": 0.3758234679698944,
      "learning_rate": 1.874810037978452e-05,
      "loss": 1.3189,
      "step": 3480
    },
    {
      "epoch": 0.5600577710021664,
      "grad_norm": 0.34578830003738403,
      "learning_rate": 1.873969328048349e-05,
      "loss": 1.5464,
      "step": 3490
    },
    {
      "epoch": 0.5616625210623445,
      "grad_norm": 0.44013527035713196,
      "learning_rate": 1.8731259944772566e-05,
      "loss": 1.3269,
      "step": 3500
    },
    {
      "epoch": 0.5632672711225226,
      "grad_norm": 0.30117514729499817,
      "learning_rate": 1.872280039796848e-05,
      "loss": 1.2317,
      "step": 3510
    },
    {
      "epoch": 0.5648720211827007,
      "grad_norm": 0.33515483140945435,
      "learning_rate": 1.871431466546664e-05,
      "loss": 1.2923,
      "step": 3520
    },
    {
      "epoch": 0.5664767712428789,
      "grad_norm": 0.3113756477832794,
      "learning_rate": 1.870580277274108e-05,
      "loss": 1.286,
      "step": 3530
    },
    {
      "epoch": 0.568081521303057,
      "grad_norm": 0.42696085572242737,
      "learning_rate": 1.869726474534435e-05,
      "loss": 1.3726,
      "step": 3540
    },
    {
      "epoch": 0.5696862713632351,
      "grad_norm": 0.33821311593055725,
      "learning_rate": 1.8688700608907462e-05,
      "loss": 1.3283,
      "step": 3550
    },
    {
      "epoch": 0.5712910214234133,
      "grad_norm": 0.30294883251190186,
      "learning_rate": 1.8680110389139806e-05,
      "loss": 1.3961,
      "step": 3560
    },
    {
      "epoch": 0.5728957714835914,
      "grad_norm": 0.37252262234687805,
      "learning_rate": 1.8671494111829084e-05,
      "loss": 1.3105,
      "step": 3570
    },
    {
      "epoch": 0.5745005215437695,
      "grad_norm": 0.3752776086330414,
      "learning_rate": 1.8662851802841202e-05,
      "loss": 1.3839,
      "step": 3580
    },
    {
      "epoch": 0.5761052716039476,
      "grad_norm": 0.4236966371536255,
      "learning_rate": 1.865418348812023e-05,
      "loss": 1.2352,
      "step": 3590
    },
    {
      "epoch": 0.5777100216641258,
      "grad_norm": 0.5295116901397705,
      "learning_rate": 1.8645489193688303e-05,
      "loss": 1.5045,
      "step": 3600
    },
    {
      "epoch": 0.5793147717243039,
      "grad_norm": 0.32668522000312805,
      "learning_rate": 1.863676894564554e-05,
      "loss": 1.1554,
      "step": 3610
    },
    {
      "epoch": 0.580919521784482,
      "grad_norm": 0.3489832580089569,
      "learning_rate": 1.8628022770169975e-05,
      "loss": 1.3662,
      "step": 3620
    },
    {
      "epoch": 0.5825242718446602,
      "grad_norm": 0.4019912779331207,
      "learning_rate": 1.8619250693517478e-05,
      "loss": 1.3283,
      "step": 3630
    },
    {
      "epoch": 0.5841290219048383,
      "grad_norm": 0.6127420663833618,
      "learning_rate": 1.861045274202168e-05,
      "loss": 1.4119,
      "step": 3640
    },
    {
      "epoch": 0.5857337719650164,
      "grad_norm": 0.506712794303894,
      "learning_rate": 1.8601628942093874e-05,
      "loss": 1.3606,
      "step": 3650
    },
    {
      "epoch": 0.5873385220251945,
      "grad_norm": 0.34272444248199463,
      "learning_rate": 1.859277932022296e-05,
      "loss": 1.3022,
      "step": 3660
    },
    {
      "epoch": 0.5889432720853727,
      "grad_norm": 0.2564506530761719,
      "learning_rate": 1.858390390297535e-05,
      "loss": 1.3398,
      "step": 3670
    },
    {
      "epoch": 0.5905480221455508,
      "grad_norm": 0.3201383352279663,
      "learning_rate": 1.8575002716994894e-05,
      "loss": 1.1833,
      "step": 3680
    },
    {
      "epoch": 0.5921527722057289,
      "grad_norm": 0.26274386048316956,
      "learning_rate": 1.85660757890028e-05,
      "loss": 1.2,
      "step": 3690
    },
    {
      "epoch": 0.5937575222659071,
      "grad_norm": 0.4444594085216522,
      "learning_rate": 1.855712314579756e-05,
      "loss": 1.3535,
      "step": 3700
    },
    {
      "epoch": 0.5953622723260852,
      "grad_norm": 0.3849436640739441,
      "learning_rate": 1.8548144814254846e-05,
      "loss": 1.3507,
      "step": 3710
    },
    {
      "epoch": 0.5969670223862633,
      "grad_norm": 0.7471434473991394,
      "learning_rate": 1.8539140821327465e-05,
      "loss": 1.3687,
      "step": 3720
    },
    {
      "epoch": 0.5985717724464414,
      "grad_norm": 0.37937498092651367,
      "learning_rate": 1.8530111194045244e-05,
      "loss": 1.3297,
      "step": 3730
    },
    {
      "epoch": 0.6001765225066196,
      "grad_norm": 0.5485889315605164,
      "learning_rate": 1.852105595951497e-05,
      "loss": 1.2996,
      "step": 3740
    },
    {
      "epoch": 0.6017812725667977,
      "grad_norm": 0.344595342874527,
      "learning_rate": 1.8511975144920303e-05,
      "loss": 1.4174,
      "step": 3750
    },
    {
      "epoch": 0.6033860226269758,
      "grad_norm": 0.36519238352775574,
      "learning_rate": 1.8502868777521698e-05,
      "loss": 1.3573,
      "step": 3760
    },
    {
      "epoch": 0.604990772687154,
      "grad_norm": 0.33092305064201355,
      "learning_rate": 1.8493736884656308e-05,
      "loss": 1.1399,
      "step": 3770
    },
    {
      "epoch": 0.6065955227473321,
      "grad_norm": 0.6363629698753357,
      "learning_rate": 1.8484579493737922e-05,
      "loss": 1.5172,
      "step": 3780
    },
    {
      "epoch": 0.6082002728075102,
      "grad_norm": 0.5183701515197754,
      "learning_rate": 1.847539663225687e-05,
      "loss": 1.4047,
      "step": 3790
    },
    {
      "epoch": 0.6098050228676883,
      "grad_norm": 0.4549940824508667,
      "learning_rate": 1.8466188327779945e-05,
      "loss": 1.338,
      "step": 3800
    },
    {
      "epoch": 0.6114097729278665,
      "grad_norm": 0.4385157823562622,
      "learning_rate": 1.8456954607950323e-05,
      "loss": 1.4217,
      "step": 3810
    },
    {
      "epoch": 0.6130145229880446,
      "grad_norm": 0.3409535586833954,
      "learning_rate": 1.844769550048747e-05,
      "loss": 1.215,
      "step": 3820
    },
    {
      "epoch": 0.6146192730482227,
      "grad_norm": 0.38314902782440186,
      "learning_rate": 1.8438411033187072e-05,
      "loss": 1.347,
      "step": 3830
    },
    {
      "epoch": 0.6162240231084009,
      "grad_norm": 0.32588592171669006,
      "learning_rate": 1.8429101233920934e-05,
      "loss": 1.2749,
      "step": 3840
    },
    {
      "epoch": 0.617828773168579,
      "grad_norm": 0.3507879674434662,
      "learning_rate": 1.8419766130636922e-05,
      "loss": 1.2889,
      "step": 3850
    },
    {
      "epoch": 0.6194335232287571,
      "grad_norm": 0.4801709055900574,
      "learning_rate": 1.841040575135885e-05,
      "loss": 1.2979,
      "step": 3860
    },
    {
      "epoch": 0.6210382732889352,
      "grad_norm": 0.3517807126045227,
      "learning_rate": 1.840102012418642e-05,
      "loss": 1.3173,
      "step": 3870
    },
    {
      "epoch": 0.6226430233491134,
      "grad_norm": 0.28233009576797485,
      "learning_rate": 1.839160927729513e-05,
      "loss": 1.2639,
      "step": 3880
    },
    {
      "epoch": 0.6242477734092915,
      "grad_norm": 0.3936665654182434,
      "learning_rate": 1.838217323893617e-05,
      "loss": 1.4767,
      "step": 3890
    },
    {
      "epoch": 0.6258525234694696,
      "grad_norm": 0.42626455426216125,
      "learning_rate": 1.8372712037436377e-05,
      "loss": 1.4665,
      "step": 3900
    },
    {
      "epoch": 0.6274572735296478,
      "grad_norm": 0.36147841811180115,
      "learning_rate": 1.8363225701198105e-05,
      "loss": 1.3301,
      "step": 3910
    },
    {
      "epoch": 0.6290620235898259,
      "grad_norm": 0.48877590894699097,
      "learning_rate": 1.8353714258699185e-05,
      "loss": 1.4647,
      "step": 3920
    },
    {
      "epoch": 0.630666773650004,
      "grad_norm": 0.3290277421474457,
      "learning_rate": 1.8344177738492797e-05,
      "loss": 1.4444,
      "step": 3930
    },
    {
      "epoch": 0.6322715237101821,
      "grad_norm": 0.35547274351119995,
      "learning_rate": 1.8334616169207414e-05,
      "loss": 1.353,
      "step": 3940
    },
    {
      "epoch": 0.6338762737703603,
      "grad_norm": 0.31548550724983215,
      "learning_rate": 1.8325029579546703e-05,
      "loss": 1.3747,
      "step": 3950
    },
    {
      "epoch": 0.6354810238305384,
      "grad_norm": 0.37399932742118835,
      "learning_rate": 1.831541799828944e-05,
      "loss": 1.222,
      "step": 3960
    },
    {
      "epoch": 0.6370857738907165,
      "grad_norm": 0.696702778339386,
      "learning_rate": 1.8305781454289436e-05,
      "loss": 1.3068,
      "step": 3970
    },
    {
      "epoch": 0.6386905239508947,
      "grad_norm": 0.4077337682247162,
      "learning_rate": 1.8296119976475422e-05,
      "loss": 1.3649,
      "step": 3980
    },
    {
      "epoch": 0.6402952740110728,
      "grad_norm": 0.5040619373321533,
      "learning_rate": 1.8286433593851e-05,
      "loss": 1.3536,
      "step": 3990
    },
    {
      "epoch": 0.6419000240712509,
      "grad_norm": 0.30516791343688965,
      "learning_rate": 1.827672233549451e-05,
      "loss": 1.3191,
      "step": 4000
    },
    {
      "epoch": 0.643504774131429,
      "grad_norm": 0.4528673589229584,
      "learning_rate": 1.8266986230559e-05,
      "loss": 1.3107,
      "step": 4010
    },
    {
      "epoch": 0.6451095241916072,
      "grad_norm": 0.37125346064567566,
      "learning_rate": 1.8257225308272078e-05,
      "loss": 1.1527,
      "step": 4020
    },
    {
      "epoch": 0.6467142742517853,
      "grad_norm": 0.5220421552658081,
      "learning_rate": 1.8247439597935873e-05,
      "loss": 1.3151,
      "step": 4030
    },
    {
      "epoch": 0.6483190243119634,
      "grad_norm": 0.5411961078643799,
      "learning_rate": 1.8237629128926914e-05,
      "loss": 1.2768,
      "step": 4040
    },
    {
      "epoch": 0.6499237743721415,
      "grad_norm": 0.32979291677474976,
      "learning_rate": 1.8227793930696068e-05,
      "loss": 1.2769,
      "step": 4050
    },
    {
      "epoch": 0.6515285244323197,
      "grad_norm": 0.7464665770530701,
      "learning_rate": 1.821793403276843e-05,
      "loss": 1.3573,
      "step": 4060
    },
    {
      "epoch": 0.6531332744924978,
      "grad_norm": 0.4306504726409912,
      "learning_rate": 1.8208049464743244e-05,
      "loss": 1.2734,
      "step": 4070
    },
    {
      "epoch": 0.6547380245526759,
      "grad_norm": 0.45659545063972473,
      "learning_rate": 1.8198140256293814e-05,
      "loss": 1.2771,
      "step": 4080
    },
    {
      "epoch": 0.6563427746128541,
      "grad_norm": 0.37459665536880493,
      "learning_rate": 1.8188206437167415e-05,
      "loss": 1.3551,
      "step": 4090
    },
    {
      "epoch": 0.6579475246730322,
      "grad_norm": 0.6561301946640015,
      "learning_rate": 1.8178248037185207e-05,
      "loss": 1.4558,
      "step": 4100
    },
    {
      "epoch": 0.6595522747332103,
      "grad_norm": 0.40747231245040894,
      "learning_rate": 1.8168265086242124e-05,
      "loss": 1.2322,
      "step": 4110
    },
    {
      "epoch": 0.6611570247933884,
      "grad_norm": 0.38931646943092346,
      "learning_rate": 1.8158257614306828e-05,
      "loss": 1.3496,
      "step": 4120
    },
    {
      "epoch": 0.6627617748535666,
      "grad_norm": 0.3700779676437378,
      "learning_rate": 1.8148225651421573e-05,
      "loss": 1.2368,
      "step": 4130
    },
    {
      "epoch": 0.6643665249137447,
      "grad_norm": 0.4402172565460205,
      "learning_rate": 1.813816922770214e-05,
      "loss": 1.3536,
      "step": 4140
    },
    {
      "epoch": 0.6659712749739228,
      "grad_norm": 0.3810122311115265,
      "learning_rate": 1.8128088373337738e-05,
      "loss": 1.3272,
      "step": 4150
    },
    {
      "epoch": 0.667576025034101,
      "grad_norm": 0.4991161823272705,
      "learning_rate": 1.8117983118590927e-05,
      "loss": 1.4764,
      "step": 4160
    },
    {
      "epoch": 0.6691807750942791,
      "grad_norm": 0.5510333776473999,
      "learning_rate": 1.8107853493797502e-05,
      "loss": 1.3793,
      "step": 4170
    },
    {
      "epoch": 0.6707855251544572,
      "grad_norm": 0.421845406293869,
      "learning_rate": 1.8097699529366425e-05,
      "loss": 1.3538,
      "step": 4180
    },
    {
      "epoch": 0.6723902752146353,
      "grad_norm": 0.47272321581840515,
      "learning_rate": 1.8087521255779728e-05,
      "loss": 1.3916,
      "step": 4190
    },
    {
      "epoch": 0.6739950252748135,
      "grad_norm": 0.4718872606754303,
      "learning_rate": 1.8077318703592413e-05,
      "loss": 1.4242,
      "step": 4200
    },
    {
      "epoch": 0.6755997753349916,
      "grad_norm": 0.28562572598457336,
      "learning_rate": 1.8067091903432362e-05,
      "loss": 1.3378,
      "step": 4210
    },
    {
      "epoch": 0.6772045253951697,
      "grad_norm": 0.4194621443748474,
      "learning_rate": 1.8056840886000263e-05,
      "loss": 1.3515,
      "step": 4220
    },
    {
      "epoch": 0.6788092754553479,
      "grad_norm": 0.5180320739746094,
      "learning_rate": 1.8046565682069488e-05,
      "loss": 1.3462,
      "step": 4230
    },
    {
      "epoch": 0.680414025515526,
      "grad_norm": 0.5235304832458496,
      "learning_rate": 1.8036266322486025e-05,
      "loss": 1.2596,
      "step": 4240
    },
    {
      "epoch": 0.6820187755757041,
      "grad_norm": 0.5107454061508179,
      "learning_rate": 1.8025942838168376e-05,
      "loss": 1.2346,
      "step": 4250
    },
    {
      "epoch": 0.6836235256358822,
      "grad_norm": 0.4136069118976593,
      "learning_rate": 1.8015595260107467e-05,
      "loss": 1.3906,
      "step": 4260
    },
    {
      "epoch": 0.6852282756960604,
      "grad_norm": 0.3837946653366089,
      "learning_rate": 1.800522361936655e-05,
      "loss": 1.2655,
      "step": 4270
    },
    {
      "epoch": 0.6868330257562385,
      "grad_norm": 0.5983788371086121,
      "learning_rate": 1.7994827947081108e-05,
      "loss": 1.3558,
      "step": 4280
    },
    {
      "epoch": 0.6884377758164166,
      "grad_norm": 0.26743337512016296,
      "learning_rate": 1.798440827445878e-05,
      "loss": 1.2114,
      "step": 4290
    },
    {
      "epoch": 0.6900425258765948,
      "grad_norm": 0.38096147775650024,
      "learning_rate": 1.797396463277924e-05,
      "loss": 1.3249,
      "step": 4300
    },
    {
      "epoch": 0.6916472759367729,
      "grad_norm": 0.5418678522109985,
      "learning_rate": 1.7963497053394118e-05,
      "loss": 1.3708,
      "step": 4310
    },
    {
      "epoch": 0.693252025996951,
      "grad_norm": 0.34386369585990906,
      "learning_rate": 1.795300556772692e-05,
      "loss": 1.5,
      "step": 4320
    },
    {
      "epoch": 0.6948567760571291,
      "grad_norm": 0.44043245911598206,
      "learning_rate": 1.794249020727289e-05,
      "loss": 1.3789,
      "step": 4330
    },
    {
      "epoch": 0.6964615261173073,
      "grad_norm": 0.44178494811058044,
      "learning_rate": 1.793195100359898e-05,
      "loss": 1.2944,
      "step": 4340
    },
    {
      "epoch": 0.6980662761774854,
      "grad_norm": 0.4453251361846924,
      "learning_rate": 1.7921387988343683e-05,
      "loss": 1.235,
      "step": 4350
    },
    {
      "epoch": 0.6996710262376635,
      "grad_norm": 0.4749120771884918,
      "learning_rate": 1.7910801193217e-05,
      "loss": 1.4486,
      "step": 4360
    },
    {
      "epoch": 0.7012757762978417,
      "grad_norm": 0.43452924489974976,
      "learning_rate": 1.7900190650000305e-05,
      "loss": 1.3148,
      "step": 4370
    },
    {
      "epoch": 0.7028805263580198,
      "grad_norm": 0.3879772424697876,
      "learning_rate": 1.7889556390546267e-05,
      "loss": 1.3008,
      "step": 4380
    },
    {
      "epoch": 0.7044852764181979,
      "grad_norm": 0.4637013375759125,
      "learning_rate": 1.7878898446778757e-05,
      "loss": 1.5488,
      "step": 4390
    },
    {
      "epoch": 0.706090026478376,
      "grad_norm": 0.27585384249687195,
      "learning_rate": 1.786821685069273e-05,
      "loss": 1.2449,
      "step": 4400
    },
    {
      "epoch": 0.7076947765385542,
      "grad_norm": 0.5484049916267395,
      "learning_rate": 1.785751163435416e-05,
      "loss": 1.519,
      "step": 4410
    },
    {
      "epoch": 0.7092995265987323,
      "grad_norm": 0.28094980120658875,
      "learning_rate": 1.7846782829899928e-05,
      "loss": 1.396,
      "step": 4420
    },
    {
      "epoch": 0.7109042766589104,
      "grad_norm": 0.5125242471694946,
      "learning_rate": 1.7836030469537717e-05,
      "loss": 1.2525,
      "step": 4430
    },
    {
      "epoch": 0.7125090267190886,
      "grad_norm": 0.39358553290367126,
      "learning_rate": 1.782525458554593e-05,
      "loss": 1.5223,
      "step": 4440
    },
    {
      "epoch": 0.7141137767792667,
      "grad_norm": 0.40496373176574707,
      "learning_rate": 1.7814455210273585e-05,
      "loss": 1.2904,
      "step": 4450
    },
    {
      "epoch": 0.7157185268394447,
      "grad_norm": 0.4594113826751709,
      "learning_rate": 1.7803632376140224e-05,
      "loss": 1.3437,
      "step": 4460
    },
    {
      "epoch": 0.7173232768996228,
      "grad_norm": 0.4577178955078125,
      "learning_rate": 1.7792786115635808e-05,
      "loss": 1.3009,
      "step": 4470
    },
    {
      "epoch": 0.718928026959801,
      "grad_norm": 0.31177616119384766,
      "learning_rate": 1.778191646132063e-05,
      "loss": 1.251,
      "step": 4480
    },
    {
      "epoch": 0.7205327770199791,
      "grad_norm": 0.5064173340797424,
      "learning_rate": 1.7771023445825203e-05,
      "loss": 1.4454,
      "step": 4490
    },
    {
      "epoch": 0.7221375270801572,
      "grad_norm": 0.5016399621963501,
      "learning_rate": 1.776010710185017e-05,
      "loss": 1.4249,
      "step": 4500
    },
    {
      "epoch": 0.7237422771403353,
      "grad_norm": 0.3784669041633606,
      "learning_rate": 1.7749167462166217e-05,
      "loss": 1.3686,
      "step": 4510
    },
    {
      "epoch": 0.7253470272005135,
      "grad_norm": 0.6547024250030518,
      "learning_rate": 1.7738204559613953e-05,
      "loss": 1.3508,
      "step": 4520
    },
    {
      "epoch": 0.7269517772606916,
      "grad_norm": 0.41100314259529114,
      "learning_rate": 1.7727218427103822e-05,
      "loss": 1.4067,
      "step": 4530
    },
    {
      "epoch": 0.7285565273208697,
      "grad_norm": 0.3411480188369751,
      "learning_rate": 1.7716209097616003e-05,
      "loss": 1.3073,
      "step": 4540
    },
    {
      "epoch": 0.7301612773810479,
      "grad_norm": 0.44814205169677734,
      "learning_rate": 1.7705176604200323e-05,
      "loss": 1.3775,
      "step": 4550
    },
    {
      "epoch": 0.731766027441226,
      "grad_norm": 0.4059377610683441,
      "learning_rate": 1.7694120979976132e-05,
      "loss": 1.4588,
      "step": 4560
    },
    {
      "epoch": 0.7333707775014041,
      "grad_norm": 0.44208186864852905,
      "learning_rate": 1.7683042258132232e-05,
      "loss": 1.3924,
      "step": 4570
    },
    {
      "epoch": 0.7349755275615822,
      "grad_norm": 0.4174703359603882,
      "learning_rate": 1.7671940471926746e-05,
      "loss": 1.2993,
      "step": 4580
    },
    {
      "epoch": 0.7365802776217604,
      "grad_norm": 0.4241965413093567,
      "learning_rate": 1.7660815654687055e-05,
      "loss": 1.363,
      "step": 4590
    },
    {
      "epoch": 0.7381850276819385,
      "grad_norm": 0.43813377618789673,
      "learning_rate": 1.764966783980967e-05,
      "loss": 1.1295,
      "step": 4600
    },
    {
      "epoch": 0.7397897777421166,
      "grad_norm": 0.4926077723503113,
      "learning_rate": 1.763849706076014e-05,
      "loss": 1.3185,
      "step": 4610
    },
    {
      "epoch": 0.7413945278022948,
      "grad_norm": 0.44836950302124023,
      "learning_rate": 1.762730335107295e-05,
      "loss": 1.3133,
      "step": 4620
    },
    {
      "epoch": 0.7429992778624729,
      "grad_norm": 0.3741202652454376,
      "learning_rate": 1.7616086744351423e-05,
      "loss": 1.3731,
      "step": 4630
    },
    {
      "epoch": 0.744604027922651,
      "grad_norm": 0.5487156510353088,
      "learning_rate": 1.7604847274267628e-05,
      "loss": 1.3456,
      "step": 4640
    },
    {
      "epoch": 0.7462087779828291,
      "grad_norm": 0.4102467894554138,
      "learning_rate": 1.7593584974562258e-05,
      "loss": 1.2209,
      "step": 4650
    },
    {
      "epoch": 0.7478135280430073,
      "grad_norm": 0.319533109664917,
      "learning_rate": 1.7582299879044548e-05,
      "loss": 1.4936,
      "step": 4660
    },
    {
      "epoch": 0.7494182781031854,
      "grad_norm": 0.3102225065231323,
      "learning_rate": 1.7570992021592154e-05,
      "loss": 1.2653,
      "step": 4670
    },
    {
      "epoch": 0.7510230281633635,
      "grad_norm": 0.40316125750541687,
      "learning_rate": 1.7559661436151082e-05,
      "loss": 1.2612,
      "step": 4680
    },
    {
      "epoch": 0.7526277782235417,
      "grad_norm": 0.27865055203437805,
      "learning_rate": 1.7548308156735544e-05,
      "loss": 1.4759,
      "step": 4690
    },
    {
      "epoch": 0.7542325282837198,
      "grad_norm": 0.37750911712646484,
      "learning_rate": 1.7536932217427898e-05,
      "loss": 1.2777,
      "step": 4700
    },
    {
      "epoch": 0.7558372783438979,
      "grad_norm": 0.5535004138946533,
      "learning_rate": 1.752553365237852e-05,
      "loss": 1.438,
      "step": 4710
    },
    {
      "epoch": 0.757442028404076,
      "grad_norm": 0.4563482999801636,
      "learning_rate": 1.7514112495805703e-05,
      "loss": 1.2838,
      "step": 4720
    },
    {
      "epoch": 0.7590467784642542,
      "grad_norm": 0.3439822793006897,
      "learning_rate": 1.7502668781995566e-05,
      "loss": 1.3012,
      "step": 4730
    },
    {
      "epoch": 0.7606515285244323,
      "grad_norm": 0.4144960939884186,
      "learning_rate": 1.7491202545301944e-05,
      "loss": 1.4224,
      "step": 4740
    },
    {
      "epoch": 0.7622562785846104,
      "grad_norm": 0.41869184374809265,
      "learning_rate": 1.7479713820146282e-05,
      "loss": 1.2688,
      "step": 4750
    },
    {
      "epoch": 0.7638610286447886,
      "grad_norm": 0.5026125907897949,
      "learning_rate": 1.7468202641017538e-05,
      "loss": 1.3464,
      "step": 4760
    },
    {
      "epoch": 0.7654657787049667,
      "grad_norm": 0.5020219087600708,
      "learning_rate": 1.7456669042472072e-05,
      "loss": 1.0694,
      "step": 4770
    },
    {
      "epoch": 0.7670705287651448,
      "grad_norm": 0.2963052988052368,
      "learning_rate": 1.7445113059133554e-05,
      "loss": 1.2345,
      "step": 4780
    },
    {
      "epoch": 0.7686752788253229,
      "grad_norm": 0.44063690304756165,
      "learning_rate": 1.7433534725692843e-05,
      "loss": 1.2226,
      "step": 4790
    },
    {
      "epoch": 0.7702800288855011,
      "grad_norm": 0.4285176992416382,
      "learning_rate": 1.7421934076907905e-05,
      "loss": 1.4068,
      "step": 4800
    },
    {
      "epoch": 0.7718847789456792,
      "grad_norm": 0.37804731726646423,
      "learning_rate": 1.7410311147603682e-05,
      "loss": 1.2514,
      "step": 4810
    },
    {
      "epoch": 0.7734895290058573,
      "grad_norm": 0.4041316509246826,
      "learning_rate": 1.7398665972672014e-05,
      "loss": 1.4336,
      "step": 4820
    },
    {
      "epoch": 0.7750942790660355,
      "grad_norm": 0.3655970096588135,
      "learning_rate": 1.7386998587071518e-05,
      "loss": 1.1238,
      "step": 4830
    },
    {
      "epoch": 0.7766990291262136,
      "grad_norm": 0.4350801408290863,
      "learning_rate": 1.7375309025827482e-05,
      "loss": 1.5054,
      "step": 4840
    },
    {
      "epoch": 0.7783037791863917,
      "grad_norm": 0.49292856454849243,
      "learning_rate": 1.7363597324031772e-05,
      "loss": 1.3391,
      "step": 4850
    },
    {
      "epoch": 0.7799085292465698,
      "grad_norm": 0.37051087617874146,
      "learning_rate": 1.7351863516842717e-05,
      "loss": 1.3629,
      "step": 4860
    },
    {
      "epoch": 0.781513279306748,
      "grad_norm": 0.4974030554294586,
      "learning_rate": 1.7340107639485006e-05,
      "loss": 1.2496,
      "step": 4870
    },
    {
      "epoch": 0.7831180293669261,
      "grad_norm": 0.4464688301086426,
      "learning_rate": 1.7328329727249577e-05,
      "loss": 1.3146,
      "step": 4880
    },
    {
      "epoch": 0.7847227794271042,
      "grad_norm": 0.3693033456802368,
      "learning_rate": 1.7316529815493532e-05,
      "loss": 1.3152,
      "step": 4890
    },
    {
      "epoch": 0.7863275294872824,
      "grad_norm": 0.4830872714519501,
      "learning_rate": 1.730470793963999e-05,
      "loss": 1.3206,
      "step": 4900
    },
    {
      "epoch": 0.7879322795474605,
      "grad_norm": 0.34010177850723267,
      "learning_rate": 1.7292864135178032e-05,
      "loss": 1.4691,
      "step": 4910
    },
    {
      "epoch": 0.7895370296076386,
      "grad_norm": 0.5918980836868286,
      "learning_rate": 1.728099843766255e-05,
      "loss": 1.2618,
      "step": 4920
    },
    {
      "epoch": 0.7911417796678167,
      "grad_norm": 0.3285658359527588,
      "learning_rate": 1.7269110882714167e-05,
      "loss": 1.3736,
      "step": 4930
    },
    {
      "epoch": 0.7927465297279949,
      "grad_norm": 0.44096946716308594,
      "learning_rate": 1.7257201506019127e-05,
      "loss": 1.3606,
      "step": 4940
    },
    {
      "epoch": 0.794351279788173,
      "grad_norm": 0.584700345993042,
      "learning_rate": 1.7245270343329162e-05,
      "loss": 1.2994,
      "step": 4950
    },
    {
      "epoch": 0.7959560298483511,
      "grad_norm": 0.47238895297050476,
      "learning_rate": 1.723331743046143e-05,
      "loss": 1.3257,
      "step": 4960
    },
    {
      "epoch": 0.7975607799085292,
      "grad_norm": 0.3651365637779236,
      "learning_rate": 1.722134280329836e-05,
      "loss": 1.2081,
      "step": 4970
    },
    {
      "epoch": 0.7991655299687074,
      "grad_norm": 0.49651721119880676,
      "learning_rate": 1.7209346497787593e-05,
      "loss": 1.2263,
      "step": 4980
    },
    {
      "epoch": 0.8007702800288855,
      "grad_norm": 0.3314235806465149,
      "learning_rate": 1.7197328549941818e-05,
      "loss": 1.2219,
      "step": 4990
    },
    {
      "epoch": 0.8023750300890636,
      "grad_norm": 0.384847491979599,
      "learning_rate": 1.718528899583872e-05,
      "loss": 1.1697,
      "step": 5000
    },
    {
      "epoch": 0.8039797801492418,
      "grad_norm": 0.5230315923690796,
      "learning_rate": 1.7173227871620827e-05,
      "loss": 1.5142,
      "step": 5010
    },
    {
      "epoch": 0.8055845302094199,
      "grad_norm": 0.42152613401412964,
      "learning_rate": 1.7161145213495434e-05,
      "loss": 1.357,
      "step": 5020
    },
    {
      "epoch": 0.807189280269598,
      "grad_norm": 0.41914135217666626,
      "learning_rate": 1.7149041057734474e-05,
      "loss": 1.2972,
      "step": 5030
    },
    {
      "epoch": 0.8087940303297761,
      "grad_norm": 0.4114096164703369,
      "learning_rate": 1.713691544067441e-05,
      "loss": 1.5291,
      "step": 5040
    },
    {
      "epoch": 0.8103987803899543,
      "grad_norm": 0.7391153573989868,
      "learning_rate": 1.712476839871614e-05,
      "loss": 1.4112,
      "step": 5050
    },
    {
      "epoch": 0.8120035304501324,
      "grad_norm": 0.4324323236942291,
      "learning_rate": 1.711259996832488e-05,
      "loss": 1.3118,
      "step": 5060
    },
    {
      "epoch": 0.8136082805103105,
      "grad_norm": 0.5286919474601746,
      "learning_rate": 1.7100410186030045e-05,
      "loss": 1.4575,
      "step": 5070
    },
    {
      "epoch": 0.8152130305704887,
      "grad_norm": 0.4221147298812866,
      "learning_rate": 1.7088199088425158e-05,
      "loss": 1.3758,
      "step": 5080
    },
    {
      "epoch": 0.8168177806306668,
      "grad_norm": 0.5743736624717712,
      "learning_rate": 1.707596671216772e-05,
      "loss": 1.4401,
      "step": 5090
    },
    {
      "epoch": 0.8184225306908449,
      "grad_norm": 0.3428259789943695,
      "learning_rate": 1.7063713093979118e-05,
      "loss": 1.3772,
      "step": 5100
    },
    {
      "epoch": 0.820027280751023,
      "grad_norm": 0.40434467792510986,
      "learning_rate": 1.7051438270644504e-05,
      "loss": 1.4265,
      "step": 5110
    },
    {
      "epoch": 0.8216320308112012,
      "grad_norm": 0.3157801628112793,
      "learning_rate": 1.7039142279012693e-05,
      "loss": 1.3497,
      "step": 5120
    },
    {
      "epoch": 0.8232367808713793,
      "grad_norm": 0.3540233075618744,
      "learning_rate": 1.7026825155996035e-05,
      "loss": 1.1807,
      "step": 5130
    },
    {
      "epoch": 0.8248415309315574,
      "grad_norm": 0.44661834836006165,
      "learning_rate": 1.7014486938570324e-05,
      "loss": 1.3529,
      "step": 5140
    },
    {
      "epoch": 0.8264462809917356,
      "grad_norm": 0.4605134129524231,
      "learning_rate": 1.700212766377468e-05,
      "loss": 1.3941,
      "step": 5150
    },
    {
      "epoch": 0.8280510310519137,
      "grad_norm": 0.44499823451042175,
      "learning_rate": 1.6989747368711432e-05,
      "loss": 1.3659,
      "step": 5160
    },
    {
      "epoch": 0.8296557811120918,
      "grad_norm": 0.7105720043182373,
      "learning_rate": 1.697734609054602e-05,
      "loss": 1.3627,
      "step": 5170
    },
    {
      "epoch": 0.83126053117227,
      "grad_norm": 0.3888545036315918,
      "learning_rate": 1.6964923866506865e-05,
      "loss": 1.3088,
      "step": 5180
    },
    {
      "epoch": 0.8328652812324481,
      "grad_norm": 0.4209115207195282,
      "learning_rate": 1.695248073388527e-05,
      "loss": 1.2464,
      "step": 5190
    },
    {
      "epoch": 0.8344700312926262,
      "grad_norm": 0.48704811930656433,
      "learning_rate": 1.6940016730035306e-05,
      "loss": 1.3356,
      "step": 5200
    },
    {
      "epoch": 0.8360747813528043,
      "grad_norm": 0.5031517148017883,
      "learning_rate": 1.69275318923737e-05,
      "loss": 1.3395,
      "step": 5210
    },
    {
      "epoch": 0.8376795314129825,
      "grad_norm": 0.43179312348365784,
      "learning_rate": 1.691502625837973e-05,
      "loss": 1.3407,
      "step": 5220
    },
    {
      "epoch": 0.8392842814731606,
      "grad_norm": 0.2716063857078552,
      "learning_rate": 1.690249986559508e-05,
      "loss": 1.3156,
      "step": 5230
    },
    {
      "epoch": 0.8408890315333387,
      "grad_norm": 0.42406779527664185,
      "learning_rate": 1.688995275162378e-05,
      "loss": 1.3187,
      "step": 5240
    },
    {
      "epoch": 0.8424937815935168,
      "grad_norm": 0.3839367926120758,
      "learning_rate": 1.6877384954132052e-05,
      "loss": 1.1937,
      "step": 5250
    },
    {
      "epoch": 0.844098531653695,
      "grad_norm": 0.49437153339385986,
      "learning_rate": 1.6864796510848197e-05,
      "loss": 1.2126,
      "step": 5260
    },
    {
      "epoch": 0.8457032817138731,
      "grad_norm": 0.287202924489975,
      "learning_rate": 1.685218745956252e-05,
      "loss": 1.3967,
      "step": 5270
    },
    {
      "epoch": 0.8473080317740512,
      "grad_norm": 0.3923187851905823,
      "learning_rate": 1.683955783812717e-05,
      "loss": 1.1879,
      "step": 5280
    },
    {
      "epoch": 0.8489127818342294,
      "grad_norm": 0.443006306886673,
      "learning_rate": 1.6826907684456055e-05,
      "loss": 1.447,
      "step": 5290
    },
    {
      "epoch": 0.8505175318944075,
      "grad_norm": 0.3437308371067047,
      "learning_rate": 1.6814237036524725e-05,
      "loss": 1.3741,
      "step": 5300
    },
    {
      "epoch": 0.8521222819545856,
      "grad_norm": 0.4169386327266693,
      "learning_rate": 1.6801545932370244e-05,
      "loss": 1.3657,
      "step": 5310
    },
    {
      "epoch": 0.8537270320147637,
      "grad_norm": 0.3671761453151703,
      "learning_rate": 1.6788834410091094e-05,
      "loss": 1.2365,
      "step": 5320
    },
    {
      "epoch": 0.8553317820749419,
      "grad_norm": 0.42742592096328735,
      "learning_rate": 1.677610250784704e-05,
      "loss": 1.3898,
      "step": 5330
    },
    {
      "epoch": 0.85693653213512,
      "grad_norm": 0.39841219782829285,
      "learning_rate": 1.6763350263859043e-05,
      "loss": 1.39,
      "step": 5340
    },
    {
      "epoch": 0.8585412821952981,
      "grad_norm": 0.6718493700027466,
      "learning_rate": 1.6750577716409115e-05,
      "loss": 1.3272,
      "step": 5350
    },
    {
      "epoch": 0.8601460322554763,
      "grad_norm": 0.43465569615364075,
      "learning_rate": 1.673778490384023e-05,
      "loss": 1.519,
      "step": 5360
    },
    {
      "epoch": 0.8617507823156544,
      "grad_norm": 0.526240348815918,
      "learning_rate": 1.6724971864556193e-05,
      "loss": 1.2687,
      "step": 5370
    },
    {
      "epoch": 0.8633555323758325,
      "grad_norm": 0.45785650610923767,
      "learning_rate": 1.6712138637021526e-05,
      "loss": 1.3477,
      "step": 5380
    },
    {
      "epoch": 0.8649602824360106,
      "grad_norm": 0.389891117811203,
      "learning_rate": 1.669928525976136e-05,
      "loss": 1.2942,
      "step": 5390
    },
    {
      "epoch": 0.8665650324961888,
      "grad_norm": 0.3290356993675232,
      "learning_rate": 1.6686411771361314e-05,
      "loss": 1.2516,
      "step": 5400
    },
    {
      "epoch": 0.8681697825563669,
      "grad_norm": 0.4714694023132324,
      "learning_rate": 1.667351821046738e-05,
      "loss": 1.3926,
      "step": 5410
    },
    {
      "epoch": 0.869774532616545,
      "grad_norm": 0.41370436549186707,
      "learning_rate": 1.666060461578581e-05,
      "loss": 1.1895,
      "step": 5420
    },
    {
      "epoch": 0.8713792826767232,
      "grad_norm": 0.3037577271461487,
      "learning_rate": 1.664767102608299e-05,
      "loss": 1.4118,
      "step": 5430
    },
    {
      "epoch": 0.8729840327369013,
      "grad_norm": 0.4214405417442322,
      "learning_rate": 1.6634717480185338e-05,
      "loss": 1.455,
      "step": 5440
    },
    {
      "epoch": 0.8745887827970793,
      "grad_norm": 0.5915951132774353,
      "learning_rate": 1.6621744016979176e-05,
      "loss": 1.4248,
      "step": 5450
    },
    {
      "epoch": 0.8761935328572574,
      "grad_norm": 0.45366013050079346,
      "learning_rate": 1.6608750675410624e-05,
      "loss": 1.3524,
      "step": 5460
    },
    {
      "epoch": 0.8777982829174356,
      "grad_norm": 0.3286932408809662,
      "learning_rate": 1.6595737494485463e-05,
      "loss": 1.2665,
      "step": 5470
    },
    {
      "epoch": 0.8794030329776137,
      "grad_norm": 0.39342668652534485,
      "learning_rate": 1.6582704513269048e-05,
      "loss": 1.2325,
      "step": 5480
    },
    {
      "epoch": 0.8810077830377918,
      "grad_norm": 0.5058841109275818,
      "learning_rate": 1.656965177088616e-05,
      "loss": 1.2939,
      "step": 5490
    },
    {
      "epoch": 0.8826125330979699,
      "grad_norm": 0.37228599190711975,
      "learning_rate": 1.655657930652091e-05,
      "loss": 1.2751,
      "step": 5500
    },
    {
      "epoch": 0.8842172831581481,
      "grad_norm": 0.32073843479156494,
      "learning_rate": 1.6543487159416615e-05,
      "loss": 1.308,
      "step": 5510
    },
    {
      "epoch": 0.8858220332183262,
      "grad_norm": 0.40155431628227234,
      "learning_rate": 1.6530375368875674e-05,
      "loss": 1.3307,
      "step": 5520
    },
    {
      "epoch": 0.8874267832785043,
      "grad_norm": 0.5695632100105286,
      "learning_rate": 1.6517243974259457e-05,
      "loss": 1.393,
      "step": 5530
    },
    {
      "epoch": 0.8890315333386825,
      "grad_norm": 0.48095759749412537,
      "learning_rate": 1.650409301498819e-05,
      "loss": 1.3773,
      "step": 5540
    },
    {
      "epoch": 0.8906362833988606,
      "grad_norm": 0.46708589792251587,
      "learning_rate": 1.649092253054083e-05,
      "loss": 1.4356,
      "step": 5550
    },
    {
      "epoch": 0.8922410334590387,
      "grad_norm": 0.29170000553131104,
      "learning_rate": 1.647773256045494e-05,
      "loss": 1.3835,
      "step": 5560
    },
    {
      "epoch": 0.8938457835192168,
      "grad_norm": 0.36648043990135193,
      "learning_rate": 1.646452314432659e-05,
      "loss": 1.2114,
      "step": 5570
    },
    {
      "epoch": 0.895450533579395,
      "grad_norm": 0.343148797750473,
      "learning_rate": 1.6451294321810215e-05,
      "loss": 1.2981,
      "step": 5580
    },
    {
      "epoch": 0.8970552836395731,
      "grad_norm": 0.4367126226425171,
      "learning_rate": 1.6438046132618522e-05,
      "loss": 1.1562,
      "step": 5590
    },
    {
      "epoch": 0.8986600336997512,
      "grad_norm": 0.4520427882671356,
      "learning_rate": 1.6424778616522345e-05,
      "loss": 1.4461,
      "step": 5600
    },
    {
      "epoch": 0.9002647837599294,
      "grad_norm": 0.49677371978759766,
      "learning_rate": 1.641149181335054e-05,
      "loss": 1.4926,
      "step": 5610
    },
    {
      "epoch": 0.9018695338201075,
      "grad_norm": 0.6070894002914429,
      "learning_rate": 1.639818576298986e-05,
      "loss": 1.3126,
      "step": 5620
    },
    {
      "epoch": 0.9034742838802856,
      "grad_norm": 0.3122079074382782,
      "learning_rate": 1.638486050538485e-05,
      "loss": 1.2197,
      "step": 5630
    },
    {
      "epoch": 0.9050790339404637,
      "grad_norm": 0.4353470504283905,
      "learning_rate": 1.6371516080537696e-05,
      "loss": 1.3893,
      "step": 5640
    },
    {
      "epoch": 0.9066837840006419,
      "grad_norm": 0.3354873061180115,
      "learning_rate": 1.635815252850814e-05,
      "loss": 1.4285,
      "step": 5650
    },
    {
      "epoch": 0.90828853406082,
      "grad_norm": 0.3952888250350952,
      "learning_rate": 1.634476988941333e-05,
      "loss": 1.1802,
      "step": 5660
    },
    {
      "epoch": 0.9098932841209981,
      "grad_norm": 0.4878421425819397,
      "learning_rate": 1.6331368203427732e-05,
      "loss": 1.239,
      "step": 5670
    },
    {
      "epoch": 0.9114980341811763,
      "grad_norm": 0.48459434509277344,
      "learning_rate": 1.6317947510782968e-05,
      "loss": 1.3353,
      "step": 5680
    },
    {
      "epoch": 0.9131027842413544,
      "grad_norm": 0.5296024680137634,
      "learning_rate": 1.6304507851767728e-05,
      "loss": 1.3325,
      "step": 5690
    },
    {
      "epoch": 0.9147075343015325,
      "grad_norm": 0.45877718925476074,
      "learning_rate": 1.6291049266727644e-05,
      "loss": 1.3223,
      "step": 5700
    },
    {
      "epoch": 0.9163122843617106,
      "grad_norm": 0.36395880579948425,
      "learning_rate": 1.627757179606515e-05,
      "loss": 1.3718,
      "step": 5710
    },
    {
      "epoch": 0.9179170344218888,
      "grad_norm": 0.6373873949050903,
      "learning_rate": 1.6264075480239394e-05,
      "loss": 1.3696,
      "step": 5720
    },
    {
      "epoch": 0.9195217844820669,
      "grad_norm": 0.5325868129730225,
      "learning_rate": 1.6250560359766078e-05,
      "loss": 1.4063,
      "step": 5730
    },
    {
      "epoch": 0.921126534542245,
      "grad_norm": 0.47153016924858093,
      "learning_rate": 1.6237026475217364e-05,
      "loss": 1.3867,
      "step": 5740
    },
    {
      "epoch": 0.9227312846024232,
      "grad_norm": 0.41277918219566345,
      "learning_rate": 1.6223473867221745e-05,
      "loss": 1.446,
      "step": 5750
    },
    {
      "epoch": 0.9243360346626013,
      "grad_norm": 0.5519567728042603,
      "learning_rate": 1.6209902576463913e-05,
      "loss": 1.3142,
      "step": 5760
    },
    {
      "epoch": 0.9259407847227794,
      "grad_norm": 0.6120237112045288,
      "learning_rate": 1.619631264368466e-05,
      "loss": 1.1825,
      "step": 5770
    },
    {
      "epoch": 0.9275455347829575,
      "grad_norm": 0.6467441916465759,
      "learning_rate": 1.6182704109680722e-05,
      "loss": 1.3095,
      "step": 5780
    },
    {
      "epoch": 0.9291502848431357,
      "grad_norm": 0.45790350437164307,
      "learning_rate": 1.6169077015304687e-05,
      "loss": 1.2986,
      "step": 5790
    },
    {
      "epoch": 0.9307550349033138,
      "grad_norm": 0.4265598952770233,
      "learning_rate": 1.6155431401464868e-05,
      "loss": 1.2973,
      "step": 5800
    },
    {
      "epoch": 0.9323597849634919,
      "grad_norm": 0.38908231258392334,
      "learning_rate": 1.6141767309125157e-05,
      "loss": 1.2323,
      "step": 5810
    },
    {
      "epoch": 0.93396453502367,
      "grad_norm": 0.8979561924934387,
      "learning_rate": 1.6128084779304923e-05,
      "loss": 1.282,
      "step": 5820
    },
    {
      "epoch": 0.9355692850838482,
      "grad_norm": 0.5202555060386658,
      "learning_rate": 1.61143838530789e-05,
      "loss": 1.4424,
      "step": 5830
    },
    {
      "epoch": 0.9371740351440263,
      "grad_norm": 0.666973888874054,
      "learning_rate": 1.6100664571577018e-05,
      "loss": 1.3073,
      "step": 5840
    },
    {
      "epoch": 0.9387787852042044,
      "grad_norm": 0.825140118598938,
      "learning_rate": 1.608692697598434e-05,
      "loss": 1.3351,
      "step": 5850
    },
    {
      "epoch": 0.9403835352643826,
      "grad_norm": 0.4914003610610962,
      "learning_rate": 1.6073171107540883e-05,
      "loss": 1.2839,
      "step": 5860
    },
    {
      "epoch": 0.9419882853245607,
      "grad_norm": 0.40694382786750793,
      "learning_rate": 1.6059397007541533e-05,
      "loss": 1.3518,
      "step": 5870
    },
    {
      "epoch": 0.9435930353847388,
      "grad_norm": 0.621853232383728,
      "learning_rate": 1.60456047173359e-05,
      "loss": 1.3419,
      "step": 5880
    },
    {
      "epoch": 0.945197785444917,
      "grad_norm": 0.40042200684547424,
      "learning_rate": 1.603179427832821e-05,
      "loss": 1.4809,
      "step": 5890
    },
    {
      "epoch": 0.9468025355050951,
      "grad_norm": 0.5344259142875671,
      "learning_rate": 1.6017965731977158e-05,
      "loss": 1.3183,
      "step": 5900
    },
    {
      "epoch": 0.9484072855652732,
      "grad_norm": 0.816536545753479,
      "learning_rate": 1.600411911979581e-05,
      "loss": 1.3356,
      "step": 5910
    },
    {
      "epoch": 0.9500120356254513,
      "grad_norm": 0.48372316360473633,
      "learning_rate": 1.5990254483351453e-05,
      "loss": 1.3854,
      "step": 5920
    },
    {
      "epoch": 0.9516167856856295,
      "grad_norm": 0.49060237407684326,
      "learning_rate": 1.5976371864265493e-05,
      "loss": 1.4454,
      "step": 5930
    },
    {
      "epoch": 0.9532215357458076,
      "grad_norm": 0.4114634394645691,
      "learning_rate": 1.5962471304213315e-05,
      "loss": 1.2264,
      "step": 5940
    },
    {
      "epoch": 0.9548262858059857,
      "grad_norm": 0.4883602559566498,
      "learning_rate": 1.5948552844924158e-05,
      "loss": 1.2849,
      "step": 5950
    },
    {
      "epoch": 0.9564310358661638,
      "grad_norm": 0.393923819065094,
      "learning_rate": 1.593461652818101e-05,
      "loss": 1.2245,
      "step": 5960
    },
    {
      "epoch": 0.958035785926342,
      "grad_norm": 0.4913346767425537,
      "learning_rate": 1.5920662395820442e-05,
      "loss": 1.0894,
      "step": 5970
    },
    {
      "epoch": 0.9596405359865201,
      "grad_norm": 0.3558640778064728,
      "learning_rate": 1.590669048973253e-05,
      "loss": 1.3691,
      "step": 5980
    },
    {
      "epoch": 0.9612452860466982,
      "grad_norm": 0.39837709069252014,
      "learning_rate": 1.5892700851860694e-05,
      "loss": 1.2236,
      "step": 5990
    },
    {
      "epoch": 0.9628500361068764,
      "grad_norm": 0.40076902508735657,
      "learning_rate": 1.5878693524201588e-05,
      "loss": 1.2526,
      "step": 6000
    },
    {
      "epoch": 0.9644547861670545,
      "grad_norm": 0.4735957384109497,
      "learning_rate": 1.5864668548804972e-05,
      "loss": 1.4731,
      "step": 6010
    },
    {
      "epoch": 0.9660595362272326,
      "grad_norm": 0.473957359790802,
      "learning_rate": 1.585062596777358e-05,
      "loss": 1.5207,
      "step": 6020
    },
    {
      "epoch": 0.9676642862874107,
      "grad_norm": 0.4437260925769806,
      "learning_rate": 1.5836565823263e-05,
      "loss": 1.2809,
      "step": 6030
    },
    {
      "epoch": 0.9692690363475889,
      "grad_norm": 0.3869938552379608,
      "learning_rate": 1.582248815748155e-05,
      "loss": 1.4852,
      "step": 6040
    },
    {
      "epoch": 0.970873786407767,
      "grad_norm": 0.35249489545822144,
      "learning_rate": 1.5808393012690143e-05,
      "loss": 1.2395,
      "step": 6050
    },
    {
      "epoch": 0.9724785364679451,
      "grad_norm": 0.5415266752243042,
      "learning_rate": 1.5794280431202153e-05,
      "loss": 1.2244,
      "step": 6060
    },
    {
      "epoch": 0.9740832865281233,
      "grad_norm": 0.450879842042923,
      "learning_rate": 1.5780150455383315e-05,
      "loss": 1.2263,
      "step": 6070
    },
    {
      "epoch": 0.9756880365883014,
      "grad_norm": 0.37794679403305054,
      "learning_rate": 1.5766003127651578e-05,
      "loss": 1.4547,
      "step": 6080
    },
    {
      "epoch": 0.9772927866484795,
      "grad_norm": 0.42578089237213135,
      "learning_rate": 1.5751838490476977e-05,
      "loss": 1.2277,
      "step": 6090
    },
    {
      "epoch": 0.9788975367086576,
      "grad_norm": 0.3842075765132904,
      "learning_rate": 1.5737656586381502e-05,
      "loss": 1.2639,
      "step": 6100
    },
    {
      "epoch": 0.9805022867688358,
      "grad_norm": 0.8705730438232422,
      "learning_rate": 1.5723457457938997e-05,
      "loss": 1.4355,
      "step": 6110
    },
    {
      "epoch": 0.9821070368290139,
      "grad_norm": 0.3839168846607208,
      "learning_rate": 1.5709241147775e-05,
      "loss": 1.2519,
      "step": 6120
    },
    {
      "epoch": 0.983711786889192,
      "grad_norm": 0.6457141637802124,
      "learning_rate": 1.5695007698566625e-05,
      "loss": 1.3103,
      "step": 6130
    },
    {
      "epoch": 0.9853165369493702,
      "grad_norm": 0.44989705085754395,
      "learning_rate": 1.5680757153042455e-05,
      "loss": 1.2612,
      "step": 6140
    },
    {
      "epoch": 0.9869212870095483,
      "grad_norm": 0.3752959072589874,
      "learning_rate": 1.5666489553982376e-05,
      "loss": 1.2201,
      "step": 6150
    },
    {
      "epoch": 0.9885260370697264,
      "grad_norm": 0.3515862226486206,
      "learning_rate": 1.565220494421748e-05,
      "loss": 1.2803,
      "step": 6160
    },
    {
      "epoch": 0.9901307871299045,
      "grad_norm": 0.3068527579307556,
      "learning_rate": 1.563790336662992e-05,
      "loss": 1.1936,
      "step": 6170
    },
    {
      "epoch": 0.9917355371900827,
      "grad_norm": 0.4431750178337097,
      "learning_rate": 1.5623584864152784e-05,
      "loss": 1.2306,
      "step": 6180
    },
    {
      "epoch": 0.9933402872502608,
      "grad_norm": 0.6194785833358765,
      "learning_rate": 1.560924947976998e-05,
      "loss": 1.3348,
      "step": 6190
    },
    {
      "epoch": 0.9949450373104389,
      "grad_norm": 0.5039888620376587,
      "learning_rate": 1.5594897256516075e-05,
      "loss": 1.3855,
      "step": 6200
    },
    {
      "epoch": 0.9965497873706171,
      "grad_norm": 0.6017631888389587,
      "learning_rate": 1.5580528237476208e-05,
      "loss": 1.2783,
      "step": 6210
    },
    {
      "epoch": 0.9981545374307952,
      "grad_norm": 0.574985146522522,
      "learning_rate": 1.556614246578593e-05,
      "loss": 1.2288,
      "step": 6220
    },
    {
      "epoch": 0.9997592874909733,
      "grad_norm": 0.4361003637313843,
      "learning_rate": 1.5551739984631073e-05,
      "loss": 1.3075,
      "step": 6230
    }
  ],
  "logging_steps": 10,
  "max_steps": 18693,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 8444693583005184.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
